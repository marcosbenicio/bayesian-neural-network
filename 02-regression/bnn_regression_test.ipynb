{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 12:47:40.715935: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-16 12:47:40.743737: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-16 12:47:40.743776: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-16 12:47:40.743806: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-16 12:47:40.749885: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-16 12:47:40.750616: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-16 12:47:41.834465: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import sklearn\n",
    "import os\n",
    "import duckdb\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Layer, Dropout, BatchNormalization, LeakyReLU, Lambda, ReLU\n",
    "\n",
    "from keras.losses import Loss, mse, MeanSquaredError\n",
    "from keras.optimizers import Optimizer, Adam\n",
    "from keras.regularizers import L2\n",
    "from keras.metrics import Mean, MeanAbsoluteError\n",
    "from keras.utils import to_categorical, plot_model, load_img, img_to_array\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, mean_squared_error\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import distributions as tfd\n",
    "\n",
    "# Geospatial \n",
    "from geopy import distance\n",
    "import geopandas as gpd\n",
    "\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi = pd.read_parquet(\"data/processed/yellow_taxi_2023.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xavier initializer\n",
    "def xavier(shape):\n",
    "    return tf.random.truncated_normal(\n",
    "        shape, \n",
    "        mean=0.0,\n",
    "        stddev=np.sqrt(2/sum(shape)))\n",
    "\n",
    "\n",
    "\n",
    "class BayesianDenseLayer(tf.keras.Model):\n",
    "    \"\"\"A fully-connected Bayesian neural network layer\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    d_in : int\n",
    "        Dimensionality of the input (# input features)\n",
    "    d_out : int\n",
    "        Output dimensionality (# units in the layer)\n",
    "    name : str\n",
    "        Name for the layer\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    losses : tensorflow.Tensor\n",
    "        Sum of the Kullback–Leibler divergences between\n",
    "        the posterior distributions and their priors\n",
    "        \n",
    "    Methods\n",
    "    -------\n",
    "    call : tensorflow.Tensor\n",
    "        Perform the forward pass of the data through\n",
    "        the layer\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, d_in, d_out, name=None):\n",
    "        \n",
    "        super(BayesianDenseLayer, self).__init__(name=name)\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        \n",
    "        self.w_loc = tf.Variable(xavier([d_in, d_out]), name='w_loc')\n",
    "        self.w_std = tf.Variable(xavier([d_in, d_out])-6.0, name='w_std')\n",
    "        self.b_loc = tf.Variable(xavier([1, d_out]), name='b_loc')\n",
    "        self.b_std = tf.Variable(xavier([1, d_out])-6.0, name='b_std')\n",
    "    \n",
    "    \n",
    "    def call(self, x, sampling=True):\n",
    "        \"\"\"Perform the forward pass\"\"\"\n",
    "        \n",
    "        if sampling:\n",
    "        \n",
    "            # Flipout-estimated weight samples\n",
    "            s = tfp.random.rademacher(tf.shape(x))\n",
    "            r = tfp.random.rademacher([x.shape[0], self.d_out])\n",
    "            w_samples = tf.nn.softplus(self.w_std)*tf.random.normal([self.d_in, self.d_out])\n",
    "            w_perturbations = r*tf.matmul(x*s, w_samples)\n",
    "            w_outputs = tf.matmul(x, self.w_loc) + w_perturbations\n",
    "            \n",
    "            # Flipout-estimated bias samples\n",
    "            r = tfp.random.rademacher([x.shape[0], self.d_out])\n",
    "            b_samples = tf.nn.softplus(self.b_std)*tf.random.normal([self.d_out])\n",
    "            b_outputs = self.b_loc + r*b_samples\n",
    "            \n",
    "            return w_outputs + b_outputs\n",
    "        \n",
    "        else:\n",
    "            return x @ self.w_loc + self.b_loc\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def losses(self):\n",
    "        \"\"\"Sum of the KL divergences between priors + posteriors\"\"\"\n",
    "        weight = tfd.Normal(self.w_loc, tf.nn.softplus(self.w_std))\n",
    "        bias = tfd.Normal(self.b_loc, tf.nn.softplus(self.b_std))\n",
    "        prior = tfd.Normal(0, 1)\n",
    "        return (tf.reduce_sum(tfd.kl_divergence(weight, prior)) +\n",
    "                tf.reduce_sum(tfd.kl_divergence(bias, prior)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianDenseNetwork(tf.keras.Model):\n",
    "    \"\"\"A multilayer fully-connected Bayesian neural network\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dims : List[int]\n",
    "        List of units in each layer\n",
    "    name : str\n",
    "        Name for the network\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    losses : tensorflow.Tensor\n",
    "        Sum of the Kullback–Leibler divergences between\n",
    "        the posterior distributions and their priors, \n",
    "        over all layers in the network\n",
    "        \n",
    "    Methods\n",
    "    -------\n",
    "    call : tensorflow.Tensor\n",
    "        Perform the forward pass of the data through\n",
    "        the network\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dims, name=None):\n",
    "        \n",
    "        super(BayesianDenseNetwork, self).__init__(name=name)\n",
    "        \n",
    "        self.steps = []\n",
    "        self.acts = []\n",
    "        for i in range(len(dims)-1):\n",
    "            self.steps += [BayesianDenseLayer(dims[i], dims[i+1])]\n",
    "            self.acts += [tf.nn.relu]\n",
    "            \n",
    "        self.acts[-1] = lambda x: x\n",
    "        \n",
    "    \n",
    "    def call(self, x, sampling=True):\n",
    "        \"\"\"Perform the forward pass\"\"\"\n",
    "\n",
    "        for i in range(len(self.steps)):\n",
    "            x = self.steps[i](x, sampling=sampling)\n",
    "            x = self.acts[i](x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def losses(self):\n",
    "        \"\"\"Sum of the KL divergences between priors + posteriors\"\"\"\n",
    "        return tf.reduce_sum([s.losses for s in self.steps])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianDensityNetwork(tf.keras.Model):\n",
    "    \"\"\"Multilayer fully-connected Bayesian neural network, with\n",
    "    two heads to predict both the mean and the standard deviation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    units : List[int]\n",
    "        Number of output dimensions for each layer\n",
    "        in the core network.\n",
    "    units : List[int]\n",
    "        Number of output dimensions for each layer\n",
    "        in the head networks.\n",
    "    name : None or str\n",
    "        Name for the layer\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, units, head_units, name=None):\n",
    "        \n",
    "        # Initialize\n",
    "        super(BayesianDensityNetwork, self).__init__(name=name)\n",
    "        \n",
    "        # Create sub-networks\n",
    "        self.core_net = BayesianDenseNetwork(units)\n",
    "        self.loc_net = BayesianDenseNetwork([units[-1]]+head_units)\n",
    "        self.std_net = BayesianDenseNetwork([units[-1]]+head_units)\n",
    "\n",
    "    \n",
    "    def call(self, x, sampling=True):\n",
    "        \"\"\"Pass data through the model\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : tf.Tensor\n",
    "            Input data\n",
    "        sampling : bool\n",
    "            Whether to sample parameter values from their \n",
    "            variational distributions (if True, the default), or\n",
    "            just use the Maximum a Posteriori parameter value\n",
    "            estimates (if False).\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        preds : tf.Tensor of shape (Nsamples, 2)\n",
    "            Output of this model, the predictions.  First column is\n",
    "            the mean predictions, and second column is the standard\n",
    "            deviation predictions.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Pass data through core network\n",
    "        x = self.core_net(x, sampling=sampling)\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        # Make predictions with each head network\n",
    "        loc_preds = self.loc_net(x, sampling=sampling)\n",
    "        std_preds = self.std_net(x, sampling=sampling)\n",
    "        std_preds = tf.nn.softplus(std_preds)\n",
    "        \n",
    "        # Return mean and std predictions\n",
    "        return tf.concat([loc_preds, std_preds], 1)\n",
    "    \n",
    "    \n",
    "    def log_likelihood(self, x, y, sampling=True):\n",
    "        \"\"\"Compute the log likelihood of y given x\"\"\"\n",
    "        \n",
    "        # Compute mean and std predictions\n",
    "        preds = self.call(x, sampling=sampling)\n",
    "        \n",
    "        # Ensure consistent dtypes\n",
    "        loc = tf.cast(preds[:, 0], dtype=tf.float32)\n",
    "        scale = tf.cast(preds[:, 1], dtype=tf.float32)\n",
    "        y = tf.cast(y[:, 0], dtype=tf.float32)\n",
    "        \n",
    "        # Return log likelihood of true data given predictions\n",
    "        return tfd.Normal(loc, scale).log_prob(y)\n",
    "        \n",
    "        \n",
    "    @tf.function\n",
    "    def sample(self, x):\n",
    "        \"\"\"Draw one sample from the predictive distribution\"\"\"\n",
    "        preds = self.call(x)\n",
    "        return tfd.Normal(preds[:,0], preds[:,1]).sample()\n",
    "    \n",
    "    \n",
    "    def samples(self, x, n_samples=1):\n",
    "        \"\"\"Draw multiple samples from predictive distributions\"\"\"\n",
    "        samples = np.zeros((x.shape[0], n_samples))\n",
    "        for i in range(n_samples):\n",
    "            samples[:,i] = self.sample(x)\n",
    "        return samples\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def losses(self):\n",
    "        \"\"\"Sum of the KL divergences between priors + posteriors\"\"\"\n",
    "        return (self.core_net.losses +\n",
    "                self.loc_net.losses +\n",
    "                self.std_net.losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-10 11:10:11.449104: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 65562504 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "# Number of training epochs\n",
    "EPOCHS = 100\n",
    "\n",
    "# Learning rate\n",
    "L_RATE = 1e-4\n",
    "\n",
    "# Proportion of samples to hold out\n",
    "VAL_SPLIT = 0.2\n",
    "\n",
    "# Split the dataframe into dependent abd independent columns\n",
    "Y_taxi = df_taxi['trip_duration'].copy()\n",
    "X_taxi = df_taxi.drop('trip_duration', axis=1)\n",
    "\n",
    "# Split data randomly into training + validation\n",
    "tr_ind = np.random.choice([False, True],\n",
    "                          size=X_taxi.shape[0],\n",
    "                          p=[VAL_SPLIT, 1.0-VAL_SPLIT])\n",
    "x_train = X_taxi[tr_ind].values\n",
    "y_train = Y_taxi[tr_ind].values\n",
    "x_val = X_taxi[~tr_ind].values\n",
    "y_val = Y_taxi[~tr_ind].values\n",
    "N_train = x_train.shape[0]\n",
    "N_val = x_val.shape[0]\n",
    "\n",
    "# Make y 2d\n",
    "y_train = np.expand_dims(y_train, 1)\n",
    "y_val = np.expand_dims(y_val, 1)\n",
    "\n",
    "# Make a TensorFlow Dataset from training data\n",
    "data_train = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(BATCH_SIZE)\n",
    "\n",
    "# Make a TensorFlow Dataset from validation data\n",
    "data_val = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(N_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-10 11:10:13.964646: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 65562504 exceeds 10% of free system memory.\n",
      "2024-05-10 11:10:35.896227: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 299719680 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Instantiate the model\n",
    "model2 = BayesianDensityNetwork([7, 256, 128], [64, 32, 1])\n",
    "# Use the Adam optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=L_RATE)\n",
    "\n",
    "N = x_train.shape[0]\n",
    "\n",
    "@tf.function\n",
    "def train_step(x_data, y_data):\n",
    "    with tf.GradientTape() as tape:\n",
    "        log_likelihoods = model2.log_likelihood(x_data, y_data)\n",
    "        kl_loss = model2.losses\n",
    "        elbo_loss = kl_loss/N - tf.reduce_mean(log_likelihoods)\n",
    "    gradients = tape.gradient(elbo_loss, model2.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model2.trainable_variables))\n",
    "    return elbo_loss\n",
    "\n",
    "# Fit the model\n",
    "elbo2 = np.zeros(EPOCHS)\n",
    "mae2 = np.zeros(EPOCHS)\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    # Update weights each batch\n",
    "    for x_data, y_data in data_train:\n",
    "        elbo2[epoch] += train_step(x_data, y_data)\n",
    "        \n",
    "    # Evaluate performance on validation data\n",
    "    for x_data, y_data in data_val:\n",
    "        y_pred = model2(x_data, sampling=False)[:, 0]\n",
    "        mae2[epoch] = mean_absolute_error(y_pred, y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elbo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the ELBO Loss over training\n",
    "plt.plot(elbo2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('ELBO Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot error over training\n",
    "plt.plot(mae2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Absolue Error')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseFlipout(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, units, name=None):\n",
    "        \n",
    "        super(DenseFlipout, self).__init__(name=name)\n",
    "        self.units = units\n",
    "    \n",
    "    # Xavier initializer\n",
    "    def xavier(self, shape):\n",
    "        return tf.random.truncated_normal(\n",
    "            shape, \n",
    "            mean=0.0,\n",
    "            stddev=np.sqrt(2/sum(shape)))\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.d_in = input_shape[-1]\n",
    "        # Initializing mean and standard deviation for weights and biases to represent their posterior distributions.\n",
    "        self.w_loc = tf.Variable(self.xavier((self.d_in, self.units)), name='w_loc')\n",
    "        self.w_std = tf.Variable(self.xavier((self.d_in, self.units)) - 6.0, name='w_std')\n",
    "        self.b_loc = tf.Variable(self.xavier((1, self.units)), name='b_loc')\n",
    "        self.b_std = tf.Variable(self.xavier((1, self.units)) - 6.0, name='b_std')\n",
    "    \n",
    "    def call(self, x, sampling=True):\n",
    "        \n",
    "        if sampling:\n",
    "        \n",
    "            # Flipout-estimated weight samples\n",
    "            s = tfp.random.rademacher(tf.shape(x))\n",
    "            r = tfp.random.rademacher([tf.shape(x)[0], self.units])\n",
    "            w_samples = tf.nn.softplus(self.w_std)*tf.random.normal([self.d_in, self.units])\n",
    "            w_perturbations = r*tf.matmul(x*s, w_samples)\n",
    "            w_outputs = tf.matmul(x, self.w_loc) + w_perturbations\n",
    "            \n",
    "            # Flipout-estimated bias samples\n",
    "            r = tfp.random.rademacher([tf.shape(x)[0], self.units])\n",
    "            b_samples = tf.nn.softplus(self.b_std)*tf.random.normal([self.units])\n",
    "            b_outputs = self.b_loc + r*b_samples\n",
    "            \n",
    "            return w_outputs + b_outputs\n",
    "        \n",
    "        else:\n",
    "            return x @ self.w_loc + self.b_loc\n",
    "    \n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def layer_loss(self):\n",
    "        \n",
    "        weight = tfd.Normal(self.w_loc, tf.nn.softplus(self.w_std))\n",
    "        bias = tfd.Normal(self.b_loc, tf.nn.softplus(self.b_std))\n",
    "        prior = tfd.Normal(0, 1)\n",
    "        return (tf.reduce_sum(tfd.kl_divergence(weight, prior)) +\n",
    "                tf.reduce_sum(tfd.kl_divergence(bias, prior)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianNN(tf.keras.Model):\n",
    "\n",
    "    def __init__(self,\n",
    "                 layer_units: list = [5, 5],\n",
    "                 output_unit: int = 1,\n",
    "                 name = \"BayesianNN\"):\n",
    "        \n",
    "        super(BayesianNN, self).__init__(name=name)\n",
    "        \n",
    "        self.layer_units = layer_units\n",
    "        self.output_unit = output_unit\n",
    "\n",
    "        self.custom_layers = []\n",
    "        self.activations = []\n",
    "        for i in range(len(layer_units)):\n",
    "            self.custom_layers += [ DenseFlipout( units=layer_units[i],\n",
    "                                               name='DenseVariational_{}'.format(i)\n",
    "                                               )]\n",
    "            self.activations.append(tf.nn.relu)\n",
    "            \n",
    "        self.custom_layers += [ DenseFlipout(  units = self.output_unit,\n",
    "                                            name = 'OutputLayer'\n",
    "                                            )]\n",
    "        self.activations.append(lambda x: x)\n",
    "    \n",
    "    def call(self, x, sampling=True):\n",
    "        \"\"\"Perform the forward pass\"\"\"\n",
    "\n",
    "        for i in range(len(self.custom_layers)):\n",
    "            x = self.custom_layers[i](x, sampling=sampling)\n",
    "            x = self.activations[i](x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def network_loss(self):\n",
    "        \"\"\"Sum of the KL divergences between priors + posteriors\"\"\"\n",
    "        return tf.reduce_sum([layer.layer_loss for layer in self.custom_layers])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianNN2Heads(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, core_units, head_units, name=None):\n",
    "        \n",
    "        # Initialize\n",
    "        super(BayesianNN2Heads, self).__init__(name=name)\n",
    "        \n",
    "        # Trackers for training metrics\n",
    "        self.train_elbo_tracker = Mean(name='train_elbo')\n",
    "        self.train_mae_tracker = MeanAbsoluteError(name='train_mae')\n",
    "\n",
    "        # Trackers for validation metrics\n",
    "        self.val_elbo_tracker = Mean(name='val_elbo')\n",
    "        self.val_mae_tracker = MeanAbsoluteError(name='val_mae')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Create the core network using BayesianNN\n",
    "        self.core_net = BayesianNN( layer_units = core_units[:-1], \n",
    "                                    output_unit = core_units[-1]) \n",
    "        \n",
    "        # Create the loc(mean) head network\n",
    "        self.loc_net = BayesianNN(  layer_units = [core_units[-1]] + head_units[:-1], \n",
    "                                    output_unit = head_units[-1])    \n",
    "\n",
    "        # Create the scale (standard deviation) head network\n",
    "        self.std_net = BayesianNN(  layer_units = [core_units[-1]] + head_units[:-1], \n",
    "                                    output_unit = head_units[-1])\n",
    "        \n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4) \n",
    "    \n",
    "    def call(self, x, sampling=True):\n",
    "        \n",
    "        # Pass data through core network\n",
    "        x = self.core_net(x, sampling=sampling)\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        # Make predictions with each head network\n",
    "        loc_preds = self.loc_net(x, sampling=sampling)\n",
    "        std_preds = self.std_net(x, sampling=sampling)\n",
    "        std_preds = tf.nn.softplus(std_preds)\n",
    "        \n",
    "        # Return mean and std predictions\n",
    "        return tf.concat([loc_preds, std_preds], 1)\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        elbo_loss = self._train_evaluate(x, y)\n",
    "        self.train_elbo_tracker.update_state(elbo_loss) \n",
    "\n",
    "        dict_losses = {  \"train_elbo\":self.train_elbo_tracker.result()}\n",
    "        return dict_losses\n",
    "    \n",
    "    @tf.function\n",
    "    def _train_evaluate(self, x, y):\n",
    "        N = tf.shape(x)[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            log_likelihoods  = self.log_likelihood(x, y)\n",
    "            # List of losses\n",
    "            total_kl_loss = self.losses\n",
    "            elbo_loss = total_kl_loss/tf.cast(N, tf.float32)  - tf.reduce_mean(log_likelihoods)\n",
    "\n",
    "        grads = tape.gradient(elbo_loss, self.trainable_weights) \n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))       \n",
    "             \n",
    "        return elbo_loss\n",
    "    \n",
    "    @tf.function\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        preds = self.call(x, sampling = False)    \n",
    "        y_loc_pred = preds[:, 0]\n",
    "        \n",
    "        self.val_mae_tracker.update_state(y, y_loc_pred)\n",
    "        dict_losses = { \"mae\": self.val_mae_tracker.result()}\n",
    "        return dict_losses\n",
    "    \n",
    "    \n",
    "    def log_likelihood(self, x, y, sampling=True):\n",
    "        \"\"\"Compute the log likelihood of y given x\"\"\"\n",
    "        \n",
    "        # Compute mean and std predictions\n",
    "        preds = self.call(x, sampling=sampling)\n",
    "        \n",
    "        # Ensure consistent dtypes\n",
    "        loc = tf.cast(preds[:, 0], dtype=tf.float32)\n",
    "        scale = tf.cast(preds[:, 1], dtype=tf.float32)\n",
    "        y = tf.cast(y[:, 0], dtype=tf.float32)\n",
    "        \n",
    "        log_likelihood = tfd.Normal(loc, scale).log_prob(y)\n",
    "        # Return log likelihood of true data given predictions\n",
    "        return log_likelihood\n",
    "    \n",
    "    @property\n",
    "    def losses(self):\n",
    "        \"\"\"Sum of the KL divergences between priors + posteriors\"\"\"\n",
    "        return (self.core_net.losses +\n",
    "                self.loc_net.losses +\n",
    "                self.std_net.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianNN2Heads(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, core_units, head_units, name=None):\n",
    "        \n",
    "        # Initialize\n",
    "        super(BayesianNN2Heads, self).__init__(name=name)\n",
    "            \n",
    "        # Create the core network using BayesianNN\n",
    "        self.core_net = BayesianNN( layer_units = core_units[:-1], \n",
    "                                    output_unit = core_units[-1]) \n",
    "        \n",
    "        # Create the loc(mean) head network\n",
    "        self.loc_net = BayesianNN(  layer_units = [core_units[-1]] + head_units[:-1], \n",
    "                                    output_unit = head_units[-1])    \n",
    "\n",
    "        # Create the scale (standard deviation) head network\n",
    "        self.std_net = BayesianNN(  layer_units = [core_units[-1]] + head_units[:-1], \n",
    "                                    output_unit = head_units[-1])\n",
    "    \n",
    "    def call(self, x, sampling=True):\n",
    "        \n",
    "        # Pass data through core network\n",
    "        x = self.core_net(x, sampling=sampling)\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        # Make predictions with each head network\n",
    "        loc_preds = self.loc_net(x, sampling=sampling)\n",
    "        std_preds = self.std_net(x, sampling=sampling)\n",
    "        std_preds = tf.nn.softplus(std_preds)\n",
    "        \n",
    "        # Return mean and std predictions\n",
    "        return tf.concat([loc_preds, std_preds], 1)\n",
    "    \n",
    "    @tf.function\n",
    "    def _train_evaluate(self, x, y, optimizer, N):\n",
    "        #N = tf.cast(tf.shape(x)[0], tf.float32)\n",
    "        with tf.GradientTape() as tape:\n",
    "            log_likelihoods  = self.log_likelihood(x, y)\n",
    "            total_kl_loss = self.kl_loss\n",
    "            elbo_loss = total_kl_loss/N  - tf.reduce_mean(log_likelihoods)\n",
    "            tf.print(\"\\n elbo:\", elbo_loss)\n",
    "            tf.print(\"\\n log_likelihoods reduce:\", tf.reduce_mean(log_likelihoods))\n",
    "\n",
    "        grads = tape.gradient(elbo_loss, self.trainable_weights) \n",
    "        optimizer.apply_gradients(zip(grads, self.trainable_weights))       \n",
    "             \n",
    "        return elbo_loss  \n",
    "    \n",
    "    def log_likelihood(self, x, y, sampling=True):\n",
    "        \"\"\"Compute the log likelihood of y given x\"\"\"\n",
    "        \n",
    "        # Compute mean and std predictions\n",
    "        preds = self.call(x, sampling=sampling)\n",
    "        \n",
    "        # Ensure consistent dtypes\n",
    "        loc = tf.cast(preds[:, 0], dtype=tf.float32)\n",
    "        scale = tf.cast(preds[:, 1], dtype=tf.float32)\n",
    "        y = tf.cast(y[:, 0], dtype=tf.float32)\n",
    "        \n",
    "        log_likelihood = tfd.Normal(loc, scale).log_prob(y)\n",
    "        # Return log likelihood of true data given predictions\n",
    "        return log_likelihood\n",
    "    \n",
    "    @property\n",
    "    def kl_loss(self):\n",
    "        \"\"\"Sum of the KL divergences between priors + posteriors\"\"\"\n",
    "        return (self.core_net.network_loss +\n",
    "                self.loc_net.network_loss +\n",
    "                self.std_net.network_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi = pd.read_parquet(\"data/processed/yellow_taxi_2023.parquet\")\n",
    "\n",
    "# Batch size\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "# Number of training epochs\n",
    "EPOCHS = 100\n",
    "\n",
    "# Learning rate\n",
    "L_RATE = 1e-4\n",
    "\n",
    "# Proportion of samples to hold out\n",
    "VAL_SPLIT = 0.2\n",
    "\n",
    "# Split the dataframe into dependent abd independent columns\n",
    "Y_taxi = df_taxi['trip_duration'].copy()\n",
    "X_taxi = df_taxi.drop('trip_duration', axis=1)\n",
    "\n",
    "# Split data randomly into training + validation\n",
    "tr_ind = np.random.choice([False, True],\n",
    "                          size=X_taxi.shape[0],\n",
    "                          p=[VAL_SPLIT, 1.0-VAL_SPLIT])\n",
    "x_train = X_taxi[tr_ind].values\n",
    "y_train = Y_taxi[tr_ind].values\n",
    "x_val = X_taxi[~tr_ind].values\n",
    "y_val = Y_taxi[~tr_ind].values\n",
    "N_train = x_train.shape[0]\n",
    "N_val = x_val.shape[0]\n",
    "\n",
    "# Make y 2d\n",
    "y_train = np.expand_dims(y_train, 1)\n",
    "y_val = np.expand_dims(y_val, 1)\n",
    "\n",
    "# Make a TensorFlow Dataset from training data\n",
    "data_train = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(BATCH_SIZE)\n",
    "\n",
    "# Make a TensorFlow Dataset from validation data\n",
    "data_val = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(N_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kl loss: 0.417276859\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41727531\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417273313\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417271\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417268425\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417265713\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417262822\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417259783\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417256624\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417253405\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417250127\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41724667\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417243183\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417239606\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41723597\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417232335\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41722849\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417224675\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417220831\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417216957\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417212963\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41720894\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417204916\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417200863\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417196751\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417192549\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417188406\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417184114\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417179883\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417175621\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41717127\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417166948\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417162597\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417158157\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417153686\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417149246\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417144805\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417140305\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417135745\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417131186\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417126656\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417122066\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417117476\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417112827\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417108208\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417103559\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41709882\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417094141\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417089403\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417084664\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417079896\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417075157\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417070389\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417065531\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417060733\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417055875\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417051017\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417046219\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417041361\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417036504\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417031556\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417026699\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417021781\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417016804\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417011887\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41700694\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.417001963\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416997045\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416991979\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416987032\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416982025\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416977018\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416971982\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416966975\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416961938\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416956872\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416951865\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416946799\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416941673\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416936636\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41693154\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416926414\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416921318\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416916251\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416911125\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416906\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416900873\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416895717\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416890591\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416885436\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41688031\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416875154\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416869968\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416864783\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416859627\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416854411\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416849256\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41684407\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416838855\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416833729\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416828483\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416823268\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416818082\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416812867\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416807681\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416802466\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416797221\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416791975\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41678676\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416781574\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416776329\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416771054\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416765839\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416760623\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416755378\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416750133\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416744977\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416739672\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416734457\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416729242\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416724056\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416718751\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416713536\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416708261\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416703016\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41669777\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416692615\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41668734\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416682094\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416676849\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416671604\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416666359\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416661173\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416655928\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416650712\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416645467\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416640222\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416635066\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416629791\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416624576\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416619331\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416614145\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.4166089\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416603744\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416598469\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416593283\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416588038\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416582793\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416577637\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416572422\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416567206\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416562\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416556746\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41655153\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416546285\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416541129\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416535884\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416530669\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416525453\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416520238\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416514963\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416509777\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416504562\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416499346\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416494131\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416488916\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41648373\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416478515\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416473329\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416468114\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416462868\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416457683\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416452527\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416447282\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416442096\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416436881\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416431665\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41642648\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416421294\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416416049\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416410893\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416405648\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416400433\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416395247\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41639\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416384846\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41637966\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416374445\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416369289\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416364163\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416358948\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416353822\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416348696\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41634351\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416338325\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416333228\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416328073\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416322917\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416317791\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416312635\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416307509\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416302323\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416297197\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416292042\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416286886\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.4162817\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416276604\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416271448\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416266322\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416261166\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41625604\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416250885\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416245788\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416240633\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416235477\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416230351\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416225225\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416220099\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416214943\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416209877\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41620478\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416199565\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416194499\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416189313\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416184306\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416179121\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416174\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416168898\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416163772\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416158646\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416153491\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416148365\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416143239\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416138113\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416133016\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41612789\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416122794\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416117668\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416112572\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416107476\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41610235\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416097254\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416092128\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416087031\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416081905\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416076809\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416071713\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416066587\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416061521\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416056454\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416051388\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416046292\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416041225\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416036129\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416031063\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416026\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.4160209\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416015804\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416010737\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416005701\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.416000634\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415995568\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415990472\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415985405\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415980369\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415975332\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415970266\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415965199\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415960133\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415955096\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41595003\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415945023\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41594\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41593498\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415929914\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415924877\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.4159199\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415914893\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415909886\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415904909\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415899843\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415894866\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415889829\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415884823\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415879816\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415874779\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415869802\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415864795\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415859759\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415854782\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415849775\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415844798\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415839791\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415834814\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415829867\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41582486\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415819854\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415814877\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.4158099\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415804952\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415799975\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415795028\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415790051\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415785044\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415780097\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41577515\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415770143\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415765196\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415760279\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415755302\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415750384\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415745437\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41574046\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415735513\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415730596\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415725619\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415720761\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415715814\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415710837\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415705979\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415701061\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415696174\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415691286\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415686399\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415681452\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415676564\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415671647\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415666789\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415661901\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415656924\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415652066\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415647209\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415642351\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415637404\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415632576\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415627688\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415622771\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415617913\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415613085\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415608197\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415603369\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415598541\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415593684\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415588826\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415584028\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41557923\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415574402\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415569574\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415564716\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415559947\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41555512\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415550292\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415545493\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415540665\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415535867\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415531\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415526271\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415521413\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415516615\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415511817\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415507019\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41550225\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415497422\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415492654\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415487885\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415483147\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415478319\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41547358\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415468782\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415464044\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415459275\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415454566\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415449828\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41544506\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415440321\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415435582\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415430844\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415426135\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415421396\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415416688\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415411949\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415407181\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415402502\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415397793\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415393084\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415388405\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415383697\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415379018\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415374339\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.4153696\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415364951\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415360272\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415355563\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415350884\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415346265\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415341586\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415336937\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415332258\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415327579\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.4153229\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415318251\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415313601\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415308923\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415304273\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415299624\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415294975\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415290356\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415285707\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415281087\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415276438\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415271819\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415267169\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41526258\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415258\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415253371\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415248752\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415244162\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415239543\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415234953\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415230364\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415225744\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415221155\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415216565\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415211976\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415207386\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415202796\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415198177\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415193588\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415189028\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415184438\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415179908\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415175319\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415170729\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415166199\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415161639\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415157169\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41515258\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415148109\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415143549\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415139019\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415134549\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.41513\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415125519\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415121\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415116459\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415111959\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415107489\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415103\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415098488\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415093958\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415089488\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415085\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415080458\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415076017\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415071487\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415067\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415062547\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415058047\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415053606\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415049136\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415044665\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415040165\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415035725\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415031195\n",
      "\n",
      " N: 1170924\n",
      "kl loss: 0.415026784\n",
      "\n",
      " N: 1170924\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[154], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[1;32m     24\u001b[0m     \n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# Update weights each batch\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x_data, y_data \u001b[38;5;129;01min\u001b[39;00m data_train:\n\u001b[0;32m---> 27\u001b[0m         elbo2[epoch] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# Evaluate performance on validation data\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x_data, y_data \u001b[38;5;129;01min\u001b[39;00m data_val:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:806\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;129m@traceback_utils\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_traceback\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m    805\u001b[0m   \u001b[38;5;66;03m# Implements GenericFunction.__call__.\u001b[39;00m\n\u001b[0;32m--> 806\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_functions_eagerly\u001b[49m:\n\u001b[1;32m    807\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, tf_function_call\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    808\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:799\u001b[0m, in \u001b[0;36mFunction._run_functions_eagerly\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the number of times the function has been traced.\u001b[39;00m\n\u001b[1;32m    770\u001b[0m \n\u001b[1;32m    771\u001b[0m \u001b[38;5;124;03m  For more information on when a function is traced and when it is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    795\u001b[0m \n\u001b[1;32m    796\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m    797\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache)\n\u001b[0;32m--> 799\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_functions_eagerly\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    801\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m eager_function_run\u001b[38;5;241m.\u001b[39mRUN_FUNCTIONS_EAGERLY\n\u001b[1;32m    803\u001b[0m \u001b[38;5;129m@traceback_utils\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_traceback\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m    805\u001b[0m   \u001b[38;5;66;03m# Implements GenericFunction.__call__.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model2 = BayesianNN2Heads([7, 256, 128], [64, 32, 1])\n",
    "# Use the Adam optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=L_RATE)\n",
    "\n",
    "N = x_train.shape[0]\n",
    "\n",
    "@tf.function\n",
    "def train_step(x_data, y_data):\n",
    "    with tf.GradientTape() as tape:\n",
    "        log_likelihoods = model2.log_likelihood(x_data, y_data)\n",
    "        kl_loss = model2.kl_loss\n",
    "        tf.print(\"kl loss:\", kl_loss/N)\n",
    "        tf.print(\"\\n N:\", N)\n",
    "        elbo_loss = kl_loss/N - tf.reduce_mean(log_likelihoods)\n",
    "    gradients = tape.gradient(elbo_loss, model2.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model2.trainable_variables))\n",
    "    return elbo_loss\n",
    "\n",
    "# Fit the model\n",
    "elbo2 = np.zeros(EPOCHS)\n",
    "mae2 = np.zeros(EPOCHS)\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    # Update weights each batch\n",
    "    for x_data, y_data in data_train:\n",
    "        elbo2[epoch] += train_step(x_data, y_data)\n",
    "        \n",
    "        \n",
    "    # Evaluate performance on validation data\n",
    "    for x_data, y_data in data_val:\n",
    "        y_pred = model2(x_data, sampling=False)[:, 0]\n",
    "        mae2[epoch] = mean_absolute_error(y_pred, y_data)\n",
    "       \n",
    "    # Print ELBO and MAE for each epoch\n",
    "    print(f\"Epoch {epoch+1}: Train_ELBO = {elbo2[epoch]}, Val_MAE = {mae2[epoch]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " elbo: 2.33704448\n",
      "\n",
      " log_likelihoods reduce: -1.91963148\n",
      "\n",
      " elbo: 2.28942728\n",
      "\n",
      " log_likelihoods reduce: -1.87201571\n",
      "\n",
      " elbo: 2.31246471\n",
      "\n",
      " log_likelihoods reduce: -1.89505517\n",
      "\n",
      " elbo: 2.11130643\n",
      "\n",
      " log_likelihoods reduce: -1.69389915\n",
      "\n",
      " elbo: 2.0923183\n",
      "\n",
      " log_likelihoods reduce: -1.67491364\n",
      "\n",
      " elbo: 2.17898321\n",
      "\n",
      " log_likelihoods reduce: -1.76158118\n",
      "\n",
      " elbo: 2.20346546\n",
      "\n",
      " log_likelihoods reduce: -1.78606606\n",
      "\n",
      " elbo: 2.16098809\n",
      "\n",
      " log_likelihoods reduce: -1.74359167\n",
      "\n",
      " elbo: 2.13025331\n",
      "\n",
      " log_likelihoods reduce: -1.71286\n",
      "\n",
      " elbo: 2.20319104\n",
      "\n",
      " log_likelihoods reduce: -1.78580081\n",
      "\n",
      " elbo: 2.10598397\n",
      "\n",
      " log_likelihoods reduce: -1.68859696\n",
      "\n",
      " elbo: 2.10148287\n",
      "\n",
      " log_likelihoods reduce: -1.68409896\n",
      "\n",
      " elbo: 2.00972152\n",
      "\n",
      " log_likelihoods reduce: -1.59234095\n",
      "\n",
      " elbo: 2.07222557\n",
      "\n",
      " log_likelihoods reduce: -1.65484846\n",
      "\n",
      " elbo: 2.05076456\n",
      "\n",
      " log_likelihoods reduce: -1.6333909\n",
      "\n",
      " elbo: 2.08856916\n",
      "\n",
      " log_likelihoods reduce: -1.6711992\n",
      "\n",
      " elbo: 2.14363194\n",
      "\n",
      " log_likelihoods reduce: -1.72626555\n",
      "\n",
      " elbo: 2.04586887\n",
      "\n",
      " log_likelihoods reduce: -1.62850595\n",
      "\n",
      " elbo: 1.98617423\n",
      "\n",
      " log_likelihoods reduce: -1.56881499\n",
      "\n",
      " elbo: 2.08506155\n",
      "\n",
      " log_likelihoods reduce: -1.66770601\n",
      "\n",
      " elbo: 2.08382869\n",
      "\n",
      " log_likelihoods reduce: -1.66647696\n",
      "\n",
      " elbo: 1.98197055\n",
      "\n",
      " log_likelihoods reduce: -1.56462264\n",
      "\n",
      " elbo: 1.98883581\n",
      "\n",
      " log_likelihoods reduce: -1.57149172\n",
      "\n",
      " elbo: 2.03906512\n",
      "\n",
      " log_likelihoods reduce: -1.62172484\n",
      "\n",
      " elbo: 1.93358231\n",
      "\n",
      " log_likelihoods reduce: -1.51624596\n",
      "\n",
      " elbo: 1.89195156\n",
      "\n",
      " log_likelihoods reduce: -1.47461915\n",
      "\n",
      " elbo: 1.84012437\n",
      "\n",
      " log_likelihoods reduce: -1.42279589\n",
      "\n",
      " elbo: 1.9445951\n",
      "\n",
      " log_likelihoods reduce: -1.52727067\n",
      "\n",
      " elbo: 1.97860515\n",
      "\n",
      " log_likelihoods reduce: -1.56128478\n",
      "\n",
      " elbo: 1.91296923\n",
      "\n",
      " log_likelihoods reduce: -1.49565291\n",
      "\n",
      " elbo: 1.97578096\n",
      "\n",
      " log_likelihoods reduce: -1.5584687\n",
      "\n",
      " elbo: 1.98692346\n",
      "\n",
      " log_likelihoods reduce: -1.56961536\n",
      "\n",
      " elbo: 1.96762753\n",
      "\n",
      " log_likelihoods reduce: -1.55032361\n",
      "\n",
      " elbo: 1.96113968\n",
      "\n",
      " log_likelihoods reduce: -1.54383981\n",
      "\n",
      " elbo: 1.87508917\n",
      "\n",
      " log_likelihoods reduce: -1.45779359\n",
      "\n",
      " elbo: 1.92367697\n",
      "\n",
      " log_likelihoods reduce: -1.50638556\n",
      "\n",
      " elbo: 1.87590384\n",
      "\n",
      " log_likelihoods reduce: -1.45861661\n",
      "\n",
      " elbo: 1.86528277\n",
      "\n",
      " log_likelihoods reduce: -1.448\n",
      "\n",
      " elbo: 1.87002313\n",
      "\n",
      " log_likelihoods reduce: -1.45274448\n",
      "\n",
      " elbo: 1.88183522\n",
      "\n",
      " log_likelihoods reduce: -1.46456099\n",
      "\n",
      " elbo: 1.85209465\n",
      "\n",
      " log_likelihoods reduce: -1.43482471\n",
      "\n",
      " elbo: 1.86173916\n",
      "\n",
      " log_likelihoods reduce: -1.44447351\n",
      "\n",
      " elbo: 1.89460671\n",
      "\n",
      " log_likelihoods reduce: -1.47734547\n",
      "\n",
      " elbo: 1.86004519\n",
      "\n",
      " log_likelihoods reduce: -1.44278836\n",
      "\n",
      " elbo: 1.82122231\n",
      "\n",
      " log_likelihoods reduce: -1.40396976\n",
      "\n",
      " elbo: 1.8576405\n",
      "\n",
      " log_likelihoods reduce: -1.44039237\n",
      "\n",
      " elbo: 1.82861531\n",
      "\n",
      " log_likelihoods reduce: -1.41137171\n",
      "\n",
      " elbo: 1.81889153\n",
      "\n",
      " log_likelihoods reduce: -1.40165234\n",
      "\n",
      " elbo: 1.77177382\n",
      "\n",
      " log_likelihoods reduce: -1.35453916\n",
      "\n",
      " elbo: 1.87579155\n",
      "\n",
      " log_likelihoods reduce: -1.45856142\n",
      "\n",
      " elbo: 1.85140431\n",
      "\n",
      " log_likelihoods reduce: -1.43417859\n",
      "\n",
      " elbo: 1.85588109\n",
      "\n",
      " log_likelihoods reduce: -1.43865991\n",
      "\n",
      " elbo: 1.78270209\n",
      "\n",
      " log_likelihoods reduce: -1.36548543\n",
      "\n",
      " elbo: 1.80275989\n",
      "\n",
      " log_likelihoods reduce: -1.38554776\n",
      "\n",
      " elbo: 1.82233214\n",
      "\n",
      " log_likelihoods reduce: -1.40512466\n",
      "\n",
      " elbo: 1.78971577\n",
      "\n",
      " log_likelihoods reduce: -1.37251282\n",
      "\n",
      " elbo: 1.83489668\n",
      "\n",
      " log_likelihoods reduce: -1.41769838\n",
      "\n",
      " elbo: 1.80471373\n",
      "\n",
      " log_likelihoods reduce: -1.38752007\n",
      "\n",
      " elbo: 1.79992151\n",
      "\n",
      " log_likelihoods reduce: -1.38273239\n",
      "\n",
      " elbo: 1.80393732\n",
      "\n",
      " log_likelihoods reduce: -1.38675284\n",
      "\n",
      " elbo: 1.77422\n",
      "\n",
      " log_likelihoods reduce: -1.35704017\n",
      "\n",
      " elbo: 1.794415\n",
      "\n",
      " log_likelihoods reduce: -1.37724\n",
      "\n",
      " elbo: 1.82375181\n",
      "\n",
      " log_likelihoods reduce: -1.4065814\n",
      "\n",
      " elbo: 1.79683924\n",
      "\n",
      " log_likelihoods reduce: -1.37967348\n",
      "\n",
      " elbo: 1.76751375\n",
      "\n",
      " log_likelihoods reduce: -1.35035264\n",
      "\n",
      " elbo: 1.79296541\n",
      "\n",
      " log_likelihoods reduce: -1.37580907\n",
      "\n",
      " elbo: 1.7861563\n",
      "\n",
      " log_likelihoods reduce: -1.36900473\n",
      "\n",
      " elbo: 1.82528186\n",
      "\n",
      " log_likelihoods reduce: -1.40813506\n",
      "\n",
      " elbo: 1.80792499\n",
      "\n",
      " log_likelihoods reduce: -1.39078295\n",
      "\n",
      " elbo: 1.76686275\n",
      "\n",
      " log_likelihoods reduce: -1.34972537\n",
      "\n",
      " elbo: 1.8145628\n",
      "\n",
      " log_likelihoods reduce: -1.39743018\n",
      "\n",
      " elbo: 1.78306079\n",
      "\n",
      " log_likelihoods reduce: -1.36593294\n",
      "\n",
      " elbo: 1.79435968\n",
      "\n",
      " log_likelihoods reduce: -1.3772366\n",
      "\n",
      " elbo: 1.77228761\n",
      "\n",
      " log_likelihoods reduce: -1.35516942\n",
      "\n",
      " elbo: 1.8266753\n",
      "\n",
      " log_likelihoods reduce: -1.40956187\n",
      "\n",
      " elbo: 1.79015565\n",
      "\n",
      " log_likelihoods reduce: -1.37304711\n",
      "\n",
      " elbo: 1.77355194\n",
      "\n",
      " log_likelihoods reduce: -1.35644817\n",
      "\n",
      " elbo: 1.7619983\n",
      "\n",
      " log_likelihoods reduce: -1.34489942\n",
      "\n",
      " elbo: 1.76511967\n",
      "\n",
      " log_likelihoods reduce: -1.34802568\n",
      "\n",
      " elbo: 1.79479408\n",
      "\n",
      " log_likelihoods reduce: -1.37770486\n",
      "\n",
      " elbo: 1.77136636\n",
      "\n",
      " log_likelihoods reduce: -1.35428202\n",
      "\n",
      " elbo: 1.7715795\n",
      "\n",
      " log_likelihoods reduce: -1.3545\n",
      "\n",
      " elbo: 1.79875636\n",
      "\n",
      " log_likelihoods reduce: -1.38168192\n",
      "\n",
      " elbo: 1.8006283\n",
      "\n",
      " log_likelihoods reduce: -1.38355863\n",
      "\n",
      " elbo: 1.78135157\n",
      "\n",
      " log_likelihoods reduce: -1.3642869\n",
      "\n",
      " elbo: 1.79507792\n",
      "\n",
      " log_likelihoods reduce: -1.37801814\n",
      "\n",
      " elbo: 1.82562733\n",
      "\n",
      " log_likelihoods reduce: -1.40857244\n",
      "\n",
      " elbo: 1.7967124\n",
      "\n",
      " log_likelihoods reduce: -1.37966239\n",
      "\n",
      " elbo: 1.80398715\n",
      "\n",
      " log_likelihoods reduce: -1.38694215\n",
      "\n",
      " elbo: 1.77821743\n",
      "\n",
      " log_likelihoods reduce: -1.36117733\n",
      "\n",
      " elbo: 1.78746116\n",
      "\n",
      " log_likelihoods reduce: -1.37042606\n",
      "\n",
      " elbo: 1.77260041\n",
      "\n",
      " log_likelihoods reduce: -1.35557032\n",
      "\n",
      " elbo: 1.79841602\n",
      "\n",
      " log_likelihoods reduce: -1.38139081\n",
      "\n",
      " elbo: 1.77166474\n",
      "\n",
      " log_likelihoods reduce: -1.35464454\n",
      "\n",
      " elbo: 1.78202951\n",
      "\n",
      " log_likelihoods reduce: -1.36501431\n",
      "\n",
      " elbo: 1.76480138\n",
      "\n",
      " log_likelihoods reduce: -1.34779119\n",
      "\n",
      " elbo: 1.77277529\n",
      "\n",
      " log_likelihoods reduce: -1.35577011\n",
      "\n",
      " elbo: 1.74914467\n",
      "\n",
      " log_likelihoods reduce: -1.3321445\n",
      "\n",
      " elbo: 1.74549496\n",
      "\n",
      " log_likelihoods reduce: -1.32849979\n",
      "\n",
      " elbo: 1.78176975\n",
      "\n",
      " log_likelihoods reduce: -1.36477959\n",
      "\n",
      " elbo: 1.7551806\n",
      "\n",
      " log_likelihoods reduce: -1.33819556\n",
      "\n",
      " elbo: 1.75602937\n",
      "\n",
      " log_likelihoods reduce: -1.33904934\n",
      "\n",
      " elbo: 1.77141404\n",
      "\n",
      " log_likelihoods reduce: -1.35443902\n",
      "\n",
      " elbo: 1.73849225\n",
      "\n",
      " log_likelihoods reduce: -1.32152224\n",
      "\n",
      " elbo: 1.78027153\n",
      "\n",
      " log_likelihoods reduce: -1.36330664\n",
      "\n",
      " elbo: 1.76377106\n",
      "\n",
      " log_likelihoods reduce: -1.34681129\n",
      "\n",
      " elbo: 1.77812481\n",
      "\n",
      " log_likelihoods reduce: -1.36117\n",
      "\n",
      " elbo: 1.76621366\n",
      "\n",
      " log_likelihoods reduce: -1.34926391\n",
      "\n",
      " elbo: 1.77057099\n",
      "\n",
      " log_likelihoods reduce: -1.35362637\n",
      "\n",
      " elbo: 1.7701869\n",
      "\n",
      " log_likelihoods reduce: -1.3532474\n",
      "\n",
      " elbo: 1.78030872\n",
      "\n",
      " log_likelihoods reduce: -1.36337423\n",
      "\n",
      " elbo: 1.78969491\n",
      "\n",
      " log_likelihoods reduce: -1.37276554\n",
      "\n",
      " elbo: 1.72160411\n",
      "\n",
      " log_likelihoods reduce: -1.30467987\n",
      "\n",
      " elbo: 1.78131151\n",
      "\n",
      " log_likelihoods reduce: -1.36439228\n",
      "\n",
      " elbo: 1.78655434\n",
      "\n",
      " log_likelihoods reduce: -1.36964035\n",
      "\n",
      " elbo: 1.77312613\n",
      "\n",
      " log_likelihoods reduce: -1.35621715\n",
      "\n",
      " elbo: 1.74963641\n",
      "\n",
      " log_likelihoods reduce: -1.33273268\n",
      "\n",
      " elbo: 1.73393071\n",
      "\n",
      " log_likelihoods reduce: -1.31703198\n",
      "\n",
      " elbo: 1.73012388\n",
      "\n",
      " log_likelihoods reduce: -1.31323028\n",
      "\n",
      " elbo: 1.78542328\n",
      "\n",
      " log_likelihoods reduce: -1.3685348\n",
      "\n",
      " elbo: 1.78678489\n",
      "\n",
      " log_likelihoods reduce: -1.36990154\n",
      "\n",
      " elbo: 1.76756024\n",
      "\n",
      " log_likelihoods reduce: -1.35068214\n",
      "\n",
      " elbo: 1.73840261\n",
      "\n",
      " log_likelihoods reduce: -1.32152963\n",
      "\n",
      " elbo: 1.76507616\n",
      "\n",
      " log_likelihoods reduce: -1.34820831\n",
      "\n",
      " elbo: 1.73185241\n",
      "\n",
      " log_likelihoods reduce: -1.31498969\n",
      "\n",
      " elbo: 1.78515422\n",
      "\n",
      " log_likelihoods reduce: -1.36829662\n",
      "\n",
      " elbo: 1.73506272\n",
      "\n",
      " log_likelihoods reduce: -1.31821036\n",
      "\n",
      " elbo: 1.72074199\n",
      "\n",
      " log_likelihoods reduce: -1.30389476\n",
      "\n",
      " elbo: 1.72515917\n",
      "\n",
      " log_likelihoods reduce: -1.30831707\n",
      "\n",
      " elbo: 1.7430867\n",
      "\n",
      " log_likelihoods reduce: -1.32624984\n",
      "\n",
      " elbo: 1.71762276\n",
      "\n",
      " log_likelihoods reduce: -1.30079103\n",
      "\n",
      " elbo: 1.71686935\n",
      "\n",
      " log_likelihoods reduce: -1.30004287\n",
      "\n",
      " elbo: 1.74824238\n",
      "\n",
      " log_likelihoods reduce: -1.33142102\n",
      "\n",
      " elbo: 1.76296508\n",
      "\n",
      " log_likelihoods reduce: -1.34614897\n",
      "\n",
      " elbo: 1.77233648\n",
      "\n",
      " log_likelihoods reduce: -1.35552561\n",
      "\n",
      " elbo: 1.76323009\n",
      "\n",
      " log_likelihoods reduce: -1.34642446\n",
      "\n",
      " elbo: 1.70943666\n",
      "\n",
      " log_likelihoods reduce: -1.29263616\n",
      "\n",
      " elbo: 1.71713495\n",
      "\n",
      " log_likelihoods reduce: -1.3003397\n",
      "\n",
      " elbo: 1.71028507\n",
      "\n",
      " log_likelihoods reduce: -1.29349494\n",
      "\n",
      " elbo: 1.68376946\n",
      "\n",
      " log_likelihoods reduce: -1.2669847\n",
      "\n",
      " elbo: 1.73861778\n",
      "\n",
      " log_likelihoods reduce: -1.32183814\n",
      "\n",
      " elbo: 1.72821176\n",
      "\n",
      " log_likelihoods reduce: -1.31143737\n",
      "\n",
      " elbo: 1.76586664\n",
      "\n",
      " log_likelihoods reduce: -1.34909749\n",
      "\n",
      " elbo: 1.73687804\n",
      "\n",
      " log_likelihoods reduce: -1.32011414\n",
      "\n",
      " elbo: 1.74109578\n",
      "\n",
      " log_likelihoods reduce: -1.32433712\n",
      "\n",
      " elbo: 1.73822498\n",
      "\n",
      " log_likelihoods reduce: -1.32147157\n",
      "\n",
      " elbo: 1.72616482\n",
      "\n",
      " log_likelihoods reduce: -1.30941665\n",
      "\n",
      " elbo: 1.75563574\n",
      "\n",
      " log_likelihoods reduce: -1.3388927\n",
      "\n",
      " elbo: 1.70288754\n",
      "\n",
      " log_likelihoods reduce: -1.28614974\n",
      "\n",
      " elbo: 1.73532891\n",
      "\n",
      " log_likelihoods reduce: -1.31859648\n",
      "\n",
      " elbo: 1.66504431\n",
      "\n",
      " log_likelihoods reduce: -1.24831712\n",
      "\n",
      " elbo: 1.72485268\n",
      "\n",
      " log_likelihoods reduce: -1.30813074\n",
      "\n",
      " elbo: 1.80665565\n",
      "\n",
      " log_likelihoods reduce: -1.38993883\n",
      "\n",
      " elbo: 1.69745445\n",
      "\n",
      " log_likelihoods reduce: -1.28074288\n",
      "\n",
      " elbo: 1.73046649\n",
      "\n",
      " log_likelihoods reduce: -1.31376028\n",
      "\n",
      " elbo: 1.67686641\n",
      "\n",
      " log_likelihoods reduce: -1.26016545\n",
      "\n",
      " elbo: 1.74570954\n",
      "\n",
      " log_likelihoods reduce: -1.32901382\n",
      "\n",
      " elbo: 1.69967914\n",
      "\n",
      " log_likelihoods reduce: -1.28298879\n",
      "\n",
      " elbo: 1.75306642\n",
      "\n",
      " log_likelihoods reduce: -1.3363812\n",
      "\n",
      " elbo: 1.77778864\n",
      "\n",
      " log_likelihoods reduce: -1.36110878\n",
      "\n",
      " elbo: 1.68538678\n",
      "\n",
      " log_likelihoods reduce: -1.26871216\n",
      "\n",
      " elbo: 1.71494043\n",
      "\n",
      " log_likelihoods reduce: -1.29827106\n",
      "\n",
      " elbo: 1.69667482\n",
      "\n",
      " log_likelihoods reduce: -1.28001082\n",
      "\n",
      " elbo: 1.71275675\n",
      "\n",
      " log_likelihoods reduce: -1.29609799\n",
      "\n",
      " elbo: 1.73081\n",
      "\n",
      " log_likelihoods reduce: -1.31415653\n",
      "\n",
      " elbo: 1.70496809\n",
      "\n",
      " log_likelihoods reduce: -1.28832\n",
      "\n",
      " elbo: 1.69138885\n",
      "\n",
      " log_likelihoods reduce: -1.27474582\n",
      "\n",
      " elbo: 1.7168622\n",
      "\n",
      " log_likelihoods reduce: -1.30022454\n",
      "\n",
      " elbo: 1.71636033\n",
      "\n",
      " log_likelihoods reduce: -1.29972792\n",
      "\n",
      " elbo: 1.71192718\n",
      "\n",
      " log_likelihoods reduce: -1.29530013\n",
      "\n",
      " elbo: 1.71515429\n",
      "\n",
      " log_likelihoods reduce: -1.29853249\n",
      "\n",
      " elbo: 1.67752528\n",
      "\n",
      " log_likelihoods reduce: -1.26090884\n",
      "\n",
      " elbo: 1.73934555\n",
      "\n",
      " log_likelihoods reduce: -1.32273436\n",
      "\n",
      " elbo: 1.73557544\n",
      "\n",
      " log_likelihoods reduce: -1.31896949\n",
      "\n",
      " elbo: 1.68085134\n",
      "\n",
      " log_likelihoods reduce: -1.26425076\n",
      "\n",
      " elbo: 1.67201865\n",
      "\n",
      " log_likelihoods reduce: -1.25542331\n",
      "\n",
      " elbo: 1.74332798\n",
      "\n",
      " log_likelihoods reduce: -1.326738\n",
      "\n",
      " elbo: 1.69947195\n",
      "\n",
      " log_likelihoods reduce: -1.28288722\n",
      "\n",
      " elbo: 1.68301356\n",
      "\n",
      " log_likelihoods reduce: -1.26643419\n",
      "\n",
      " elbo: 1.72285283\n",
      "\n",
      " log_likelihoods reduce: -1.30627871\n",
      "\n",
      " elbo: 1.74942446\n",
      "\n",
      " log_likelihoods reduce: -1.3328557\n",
      "\n",
      " elbo: 1.75376654\n",
      "\n",
      " log_likelihoods reduce: -1.33720303\n",
      "\n",
      " elbo: 1.71277213\n",
      "\n",
      " log_likelihoods reduce: -1.29621398\n",
      "\n",
      " elbo: 1.71363068\n",
      "\n",
      " log_likelihoods reduce: -1.29707789\n",
      "\n",
      " elbo: 1.69925559\n",
      "\n",
      " log_likelihoods reduce: -1.28270805\n",
      "\n",
      " elbo: 1.67275262\n",
      "\n",
      " log_likelihoods reduce: -1.25621045\n",
      "\n",
      " elbo: 1.72140253\n",
      "\n",
      " log_likelihoods reduce: -1.3048656\n",
      "\n",
      " elbo: 1.73147702\n",
      "\n",
      " log_likelihoods reduce: -1.31494534\n",
      "\n",
      " elbo: 1.73478782\n",
      "\n",
      " log_likelihoods reduce: -1.3182615\n",
      "\n",
      " elbo: 1.65446341\n",
      "\n",
      " log_likelihoods reduce: -1.23794246\n",
      "\n",
      " elbo: 1.71312129\n",
      "\n",
      " log_likelihoods reduce: -1.29660559\n",
      "\n",
      " elbo: 1.75541782\n",
      "\n",
      " log_likelihoods reduce: -1.33890748\n",
      "\n",
      " elbo: 1.6950115\n",
      "\n",
      " log_likelihoods reduce: -1.27850652\n",
      "\n",
      " elbo: 1.68184423\n",
      "\n",
      " log_likelihoods reduce: -1.26534462\n",
      "\n",
      " elbo: 1.69061589\n",
      "\n",
      " log_likelihoods reduce: -1.2741214\n",
      "\n",
      " elbo: 1.71550417\n",
      "\n",
      " log_likelihoods reduce: -1.29901505\n",
      "\n",
      " elbo: 1.73436987\n",
      "\n",
      " log_likelihoods reduce: -1.31788611\n",
      "\n",
      " elbo: 1.70152104\n",
      "\n",
      " log_likelihoods reduce: -1.28504252\n",
      "\n",
      " elbo: 1.70913076\n",
      "\n",
      " log_likelihoods reduce: -1.29265761\n",
      "\n",
      " elbo: 1.65498888\n",
      "\n",
      " log_likelihoods reduce: -1.2385211\n",
      "\n",
      " elbo: 1.67339444\n",
      "\n",
      " log_likelihoods reduce: -1.25693202\n",
      "\n",
      " elbo: 1.69604588\n",
      "\n",
      " log_likelihoods reduce: -1.2795887\n",
      "\n",
      " elbo: 1.69420826\n",
      "\n",
      " log_likelihoods reduce: -1.27775645\n",
      "\n",
      " elbo: 1.73117924\n",
      "\n",
      " log_likelihoods reduce: -1.31473267\n",
      "\n",
      " elbo: 1.74164474\n",
      "\n",
      " log_likelihoods reduce: -1.32520354\n",
      "\n",
      " elbo: 1.724033\n",
      "\n",
      " log_likelihoods reduce: -1.30759716\n",
      "\n",
      " elbo: 1.69099712\n",
      "\n",
      " log_likelihoods reduce: -1.27456665\n",
      "\n",
      " elbo: 1.71990466\n",
      "\n",
      " log_likelihoods reduce: -1.30347943\n",
      "\n",
      " elbo: 1.64764106\n",
      "\n",
      " log_likelihoods reduce: -1.2312212\n",
      "\n",
      " elbo: 1.66372228\n",
      "\n",
      " log_likelihoods reduce: -1.24730766\n",
      "\n",
      " elbo: 1.65015197\n",
      "\n",
      " log_likelihoods reduce: -1.23374271\n",
      "\n",
      " elbo: 1.66336799\n",
      "\n",
      " log_likelihoods reduce: -1.2469641\n",
      "\n",
      " elbo: 1.70215845\n",
      "\n",
      " log_likelihoods reduce: -1.28575993\n",
      "\n",
      " elbo: 1.67310858\n",
      "\n",
      " log_likelihoods reduce: -1.2567153\n",
      "\n",
      " elbo: 1.64173448\n",
      "\n",
      " log_likelihoods reduce: -1.22534657\n",
      "\n",
      " elbo: 1.6826812\n",
      "\n",
      " log_likelihoods reduce: -1.26629865\n",
      "\n",
      " elbo: 1.70216823\n",
      "\n",
      " log_likelihoods reduce: -1.28579092\n",
      "\n",
      " elbo: 1.68193328\n",
      "\n",
      " log_likelihoods reduce: -1.26556134\n",
      "\n",
      " elbo: 1.66645396\n",
      "\n",
      " log_likelihoods reduce: -1.25008738\n",
      "\n",
      " elbo: 1.71088076\n",
      "\n",
      " log_likelihoods reduce: -1.29451954\n",
      "\n",
      " elbo: 1.65271652\n",
      "\n",
      " log_likelihoods reduce: -1.23636055\n",
      "\n",
      " elbo: 1.68852794\n",
      "\n",
      " log_likelihoods reduce: -1.27217734\n",
      "\n",
      " elbo: 1.67337275\n",
      "\n",
      " log_likelihoods reduce: -1.25702739\n",
      "\n",
      " elbo: 1.74025643\n",
      "\n",
      " log_likelihoods reduce: -1.32391644\n",
      "\n",
      " elbo: 1.69367051\n",
      "\n",
      " log_likelihoods reduce: -1.27733588\n",
      "\n",
      " elbo: 1.68464518\n",
      "\n",
      " log_likelihoods reduce: -1.26831579\n",
      "\n",
      " elbo: 1.67181015\n",
      "\n",
      " log_likelihoods reduce: -1.25548613\n",
      "\n",
      " elbo: 1.66778302\n",
      "\n",
      " log_likelihoods reduce: -1.25146437\n",
      "\n",
      " elbo: 1.69095576\n",
      "\n",
      " log_likelihoods reduce: -1.27464247\n",
      "\n",
      " elbo: 1.70303369\n",
      "\n",
      " log_likelihoods reduce: -1.28672576\n",
      "\n",
      " elbo: 1.70919442\n",
      "\n",
      " log_likelihoods reduce: -1.29289174\n",
      "\n",
      " elbo: 1.65025222\n",
      "\n",
      " log_likelihoods reduce: -1.23395491\n",
      "\n",
      " elbo: 1.6498847\n",
      "\n",
      " log_likelihoods reduce: -1.23359275\n",
      "\n",
      " elbo: 1.70347774\n",
      "\n",
      " log_likelihoods reduce: -1.28719115\n",
      "\n",
      " elbo: 1.65044856\n",
      "\n",
      " log_likelihoods reduce: -1.23416734\n",
      "\n",
      " elbo: 1.69065285\n",
      "\n",
      " log_likelihoods reduce: -1.27437687\n",
      "\n",
      " elbo: 1.7011584\n",
      "\n",
      " log_likelihoods reduce: -1.28488767\n",
      "\n",
      " elbo: 1.6429193\n",
      "\n",
      " log_likelihoods reduce: -1.22665405\n",
      "\n",
      " elbo: 1.67086959\n",
      "\n",
      " log_likelihoods reduce: -1.25460958\n",
      "\n",
      " elbo: 1.69610047\n",
      "\n",
      " log_likelihoods reduce: -1.27984583\n",
      "\n",
      " elbo: 1.70306301\n",
      "\n",
      " log_likelihoods reduce: -1.28681374\n",
      "\n",
      " elbo: 1.70149493\n",
      "\n",
      " log_likelihoods reduce: -1.2852509\n",
      "\n",
      " elbo: 1.63562596\n",
      "\n",
      " log_likelihoods reduce: -1.21938729\n",
      "\n",
      " elbo: 1.66497362\n",
      "\n",
      " log_likelihoods reduce: -1.2487402\n",
      "\n",
      " elbo: 1.68047166\n",
      "\n",
      " log_likelihoods reduce: -1.2642436\n",
      "\n",
      " elbo: 1.68870354\n",
      "\n",
      " log_likelihoods reduce: -1.27248085\n",
      "\n",
      " elbo: 1.65542674\n",
      "\n",
      " log_likelihoods reduce: -1.23920941\n",
      "\n",
      " elbo: 1.64163756\n",
      "\n",
      " log_likelihoods reduce: -1.22542548\n",
      "\n",
      " elbo: 1.67185354\n",
      "\n",
      " log_likelihoods reduce: -1.25564682\n",
      "\n",
      " elbo: 1.68354607\n",
      "\n",
      " log_likelihoods reduce: -1.26734471\n",
      "\n",
      " elbo: 1.69486749\n",
      "\n",
      " log_likelihoods reduce: -1.2786715\n",
      "\n",
      " elbo: 1.74615943\n",
      "\n",
      " log_likelihoods reduce: -1.32996869\n",
      "\n",
      " elbo: 1.64820361\n",
      "\n",
      " log_likelihoods reduce: -1.23201823\n",
      "\n",
      " elbo: 1.67754686\n",
      "\n",
      " log_likelihoods reduce: -1.26136684\n",
      "\n",
      " elbo: 1.64808393\n",
      "\n",
      " log_likelihoods reduce: -1.23190916\n",
      "\n",
      " elbo: 1.64959073\n",
      "\n",
      " log_likelihoods reduce: -1.23342133\n",
      "\n",
      " elbo: 1.66823971\n",
      "\n",
      " log_likelihoods reduce: -1.25207567\n",
      "\n",
      " elbo: 1.66007185\n",
      "\n",
      " log_likelihoods reduce: -1.24391317\n",
      "\n",
      " elbo: 1.66949058\n",
      "\n",
      " log_likelihoods reduce: -1.25333714\n",
      "\n",
      " elbo: 1.67338336\n",
      "\n",
      " log_likelihoods reduce: -1.25723529\n",
      "\n",
      " elbo: 1.7097367\n",
      "\n",
      " log_likelihoods reduce: -1.293594\n",
      "\n",
      " elbo: 1.69944191\n",
      "\n",
      " log_likelihoods reduce: -1.28330445\n",
      "\n",
      " elbo: 1.69343948\n",
      "\n",
      " log_likelihoods reduce: -1.27730727\n",
      "\n",
      " elbo: 1.5848825\n",
      "\n",
      " log_likelihoods reduce: -1.16875565\n",
      "\n",
      " elbo: 1.66478825\n",
      "\n",
      " log_likelihoods reduce: -1.24866676\n",
      "\n",
      " elbo: 1.62541127\n",
      "\n",
      " log_likelihoods reduce: -1.20929503\n",
      "\n",
      " elbo: 1.65817344\n",
      "\n",
      " log_likelihoods reduce: -1.24206257\n",
      "\n",
      " elbo: 1.63861537\n",
      "\n",
      " log_likelihoods reduce: -1.22250986\n",
      "\n",
      " elbo: 1.69814038\n",
      "\n",
      " log_likelihoods reduce: -1.28204012\n",
      "\n",
      " elbo: 1.68503654\n",
      "\n",
      " log_likelihoods reduce: -1.26894164\n",
      "\n",
      " elbo: 1.63408172\n",
      "\n",
      " log_likelihoods reduce: -1.21799219\n",
      "\n",
      " elbo: 1.66635919\n",
      "\n",
      " log_likelihoods reduce: -1.2502749\n",
      "\n",
      " elbo: 1.63577151\n",
      "\n",
      " log_likelihoods reduce: -1.21969259\n",
      "\n",
      " elbo: 1.66322088\n",
      "\n",
      " log_likelihoods reduce: -1.2471472\n",
      "\n",
      " elbo: 1.72029543\n",
      "\n",
      " log_likelihoods reduce: -1.30422711\n",
      "\n",
      " elbo: 1.65899265\n",
      "\n",
      " log_likelihoods reduce: -1.2429297\n",
      "\n",
      " elbo: 1.65559328\n",
      "\n",
      " log_likelihoods reduce: -1.23953557\n",
      "\n",
      " elbo: 1.62720597\n",
      "\n",
      " log_likelihoods reduce: -1.21115363\n",
      "\n",
      " elbo: 1.64744747\n",
      "\n",
      " log_likelihoods reduce: -1.23140037\n",
      "\n",
      " elbo: 1.6485436\n",
      "\n",
      " log_likelihoods reduce: -1.23250186\n",
      "\n",
      " elbo: 1.6209228\n",
      "\n",
      " log_likelihoods reduce: -1.20488644\n",
      "\n",
      " elbo: 1.65491939\n",
      "\n",
      " log_likelihoods reduce: -1.23888826\n",
      "\n",
      " elbo: 1.60796046\n",
      "\n",
      " log_likelihoods reduce: -1.1919347\n",
      "\n",
      " elbo: 1.68121135\n",
      "\n",
      " log_likelihoods reduce: -1.26519084\n",
      "\n",
      " elbo: 1.64384198\n",
      "\n",
      " log_likelihoods reduce: -1.22782683\n",
      "\n",
      " elbo: 1.69949698\n",
      "\n",
      " log_likelihoods reduce: -1.2834872\n",
      "\n",
      " elbo: 1.64703977\n",
      "\n",
      " log_likelihoods reduce: -1.23103523\n",
      "\n",
      " elbo: 1.63233757\n",
      "\n",
      " log_likelihoods reduce: -1.2163384\n",
      "\n",
      " elbo: 1.67327404\n",
      "\n",
      " log_likelihoods reduce: -1.25728011\n",
      "\n",
      " elbo: 1.62861919\n",
      "\n",
      " log_likelihoods reduce: -1.21263063\n",
      "\n",
      " elbo: 1.66690576\n",
      "\n",
      " log_likelihoods reduce: -1.25092244\n",
      "\n",
      " elbo: 1.66519785\n",
      "\n",
      " log_likelihoods reduce: -1.24921978\n",
      "\n",
      " elbo: 1.64970016\n",
      "\n",
      " log_likelihoods reduce: -1.23372746\n",
      "\n",
      " elbo: 1.63811684\n",
      "\n",
      " log_likelihoods reduce: -1.22214949\n",
      "\n",
      " elbo: 1.63827491\n",
      "\n",
      " log_likelihoods reduce: -1.22231281\n",
      "\n",
      " elbo: 1.64550209\n",
      "\n",
      " log_likelihoods reduce: -1.22954535\n",
      "\n",
      " elbo: 1.69645071\n",
      "\n",
      " log_likelihoods reduce: -1.28049922\n",
      "\n",
      " elbo: 1.64426565\n",
      "\n",
      " log_likelihoods reduce: -1.22831941\n",
      "\n",
      " elbo: 1.6861335\n",
      "\n",
      " log_likelihoods reduce: -1.27019262\n",
      "\n",
      " elbo: 1.59844422\n",
      "\n",
      " log_likelihoods reduce: -1.18250859\n",
      "\n",
      " elbo: 1.61438966\n",
      "\n",
      " log_likelihoods reduce: -1.19845939\n",
      "\n",
      " elbo: 1.61695743\n",
      "\n",
      " log_likelihoods reduce: -1.2010324\n",
      "\n",
      " elbo: 1.68212163\n",
      "\n",
      " log_likelihoods reduce: -1.26620197\n",
      "\n",
      " elbo: 1.66082227\n",
      "\n",
      " log_likelihoods reduce: -1.24490786\n",
      "\n",
      " elbo: 1.61472833\n",
      "\n",
      " log_likelihoods reduce: -1.19881928\n",
      "\n",
      " elbo: 1.62386918\n",
      "\n",
      " log_likelihoods reduce: -1.20796537\n",
      "\n",
      " elbo: 1.63475215\n",
      "\n",
      " log_likelihoods reduce: -1.21885371\n",
      "\n",
      " elbo: 1.57164025\n",
      "\n",
      " log_likelihoods reduce: -1.15574718\n",
      "\n",
      " elbo: 1.60009146\n",
      "\n",
      " log_likelihoods reduce: -1.18420362\n",
      "\n",
      " elbo: 1.62881029\n",
      "\n",
      " log_likelihoods reduce: -1.21292782\n",
      "\n",
      " elbo: 1.64186776\n",
      "\n",
      " log_likelihoods reduce: -1.22599053\n",
      "\n",
      " elbo: 1.63111925\n",
      "\n",
      " log_likelihoods reduce: -1.21524739\n",
      "\n",
      " elbo: 1.61262238\n",
      "\n",
      " log_likelihoods reduce: -1.19675577\n",
      "\n",
      " elbo: 1.64691424\n",
      "\n",
      " log_likelihoods reduce: -1.23105288\n",
      "\n",
      " elbo: 1.65204549\n",
      "\n",
      " log_likelihoods reduce: -1.23618948\n",
      "\n",
      " elbo: 1.62976503\n",
      "\n",
      " log_likelihoods reduce: -1.21391439\n",
      "\n",
      " elbo: 1.59440231\n",
      "\n",
      " log_likelihoods reduce: -1.17855692\n",
      "\n",
      " elbo: 1.64924788\n",
      "\n",
      " log_likelihoods reduce: -1.23340774\n",
      "\n",
      " elbo: 1.65696\n",
      "\n",
      " log_likelihoods reduce: -1.24112511\n",
      "\n",
      " elbo: 1.63120329\n",
      "\n",
      " log_likelihoods reduce: -1.21537375\n",
      "\n",
      " elbo: 1.64056361\n",
      "\n",
      " log_likelihoods reduce: -1.22473931\n",
      "\n",
      " elbo: 1.69489491\n",
      "\n",
      " log_likelihoods reduce: -1.27907586\n",
      "\n",
      " elbo: 1.67170942\n",
      "\n",
      " log_likelihoods reduce: -1.25589561\n",
      "\n",
      " elbo: 1.68826318\n",
      "\n",
      " log_likelihoods reduce: -1.27245462\n",
      "\n",
      " elbo: 1.60583591\n",
      "\n",
      " log_likelihoods reduce: -1.19003272\n",
      "\n",
      " elbo: 1.59686685\n",
      "\n",
      " log_likelihoods reduce: -1.1810689\n",
      "\n",
      " elbo: 1.70174289\n",
      "\n",
      " log_likelihoods reduce: -1.28595018\n",
      "\n",
      " elbo: 1.64264321\n",
      "\n",
      " log_likelihoods reduce: -1.22685575\n",
      "\n",
      " elbo: 1.6308248\n",
      "\n",
      " log_likelihoods reduce: -1.21504259\n",
      "\n",
      " elbo: 1.63014698\n",
      "\n",
      " log_likelihoods reduce: -1.21437\n",
      "\n",
      " elbo: 1.65342915\n",
      "\n",
      " log_likelihoods reduce: -1.23765755\n",
      "\n",
      " elbo: 1.63663721\n",
      "\n",
      " log_likelihoods reduce: -1.22087073\n",
      "\n",
      " elbo: 1.61893034\n",
      "\n",
      " log_likelihoods reduce: -1.20316923\n",
      "\n",
      " elbo: 1.62789285\n",
      "\n",
      " log_likelihoods reduce: -1.21213698\n",
      "\n",
      " elbo: 1.65445018\n",
      "\n",
      " log_likelihoods reduce: -1.23869967\n",
      "\n",
      " elbo: 1.6033535\n",
      "\n",
      " log_likelihoods reduce: -1.18760824\n",
      "\n",
      " elbo: 1.64216423\n",
      "\n",
      " log_likelihoods reduce: -1.22642422\n",
      "\n",
      " elbo: 1.62823105\n",
      "\n",
      " log_likelihoods reduce: -1.21249628\n",
      "\n",
      " elbo: 1.59944844\n",
      "\n",
      " log_likelihoods reduce: -1.18371892\n",
      "\n",
      " elbo: 1.63769436\n",
      "\n",
      " log_likelihoods reduce: -1.22197008\n",
      "\n",
      " elbo: 1.64531183\n",
      "\n",
      " log_likelihoods reduce: -1.2295928\n",
      "\n",
      " elbo: 1.63041341\n",
      "\n",
      " log_likelihoods reduce: -1.21469975\n",
      "\n",
      " elbo: 1.62100601\n",
      "\n",
      " log_likelihoods reduce: -1.20529747\n",
      "\n",
      " elbo: 1.647506\n",
      "\n",
      " log_likelihoods reduce: -1.2318027\n",
      "\n",
      " elbo: 1.63772821\n",
      "\n",
      " log_likelihoods reduce: -1.22203016\n",
      "\n",
      " elbo: 1.63634324\n",
      "\n",
      " log_likelihoods reduce: -1.22065043\n",
      "\n",
      " elbo: 1.66496217\n",
      "\n",
      " log_likelihoods reduce: -1.24927473\n",
      "\n",
      " elbo: 1.66126275\n",
      "\n",
      " log_likelihoods reduce: -1.24558043\n",
      "\n",
      " elbo: 1.62577534\n",
      "\n",
      " log_likelihoods reduce: -1.21009839\n",
      "\n",
      " elbo: 1.65429211\n",
      "\n",
      " log_likelihoods reduce: -1.23862028\n",
      "\n",
      " elbo: 1.64896894\n",
      "\n",
      " log_likelihoods reduce: -1.23330235\n",
      "\n",
      " elbo: 1.68445182\n",
      "\n",
      " log_likelihoods reduce: -1.26879048\n",
      "\n",
      " elbo: 1.60525501\n",
      "\n",
      " log_likelihoods reduce: -1.18959892\n",
      "\n",
      " elbo: 1.60965729\n",
      "\n",
      " log_likelihoods reduce: -1.19400656\n",
      "\n",
      " elbo: 1.61798763\n",
      "\n",
      " log_likelihoods reduce: -1.20234203\n",
      "\n",
      " elbo: 1.65584826\n",
      "\n",
      " log_likelihoods reduce: -1.24020791\n",
      "\n",
      " elbo: 1.62973237\n",
      "\n",
      " log_likelihoods reduce: -1.21409726\n",
      "\n",
      " elbo: 1.64326155\n",
      "\n",
      " log_likelihoods reduce: -1.22763169\n",
      "\n",
      " elbo: 1.58238077\n",
      "\n",
      " log_likelihoods reduce: -1.16675615\n",
      "\n",
      " elbo: 1.60082734\n",
      "\n",
      " log_likelihoods reduce: -1.18520784\n",
      "\n",
      " elbo: 1.64158809\n",
      "\n",
      " log_likelihoods reduce: -1.22597384\n",
      "\n",
      " elbo: 1.61840737\n",
      "\n",
      " log_likelihoods reduce: -1.20279837\n",
      "\n",
      " elbo: 1.60933506\n",
      "\n",
      " log_likelihoods reduce: -1.19373131\n",
      "\n",
      " elbo: 1.58776367\n",
      "\n",
      " log_likelihoods reduce: -1.17216516\n",
      "\n",
      " elbo: 1.61667407\n",
      "\n",
      " log_likelihoods reduce: -1.2010808\n",
      "\n",
      " elbo: 1.61924207\n",
      "\n",
      " log_likelihoods reduce: -1.20365405\n",
      "\n",
      " elbo: 1.61107254\n",
      "\n",
      " log_likelihoods reduce: -1.19548965\n",
      "\n",
      " elbo: 1.54432178\n",
      "\n",
      " log_likelihoods reduce: -1.12874413\n",
      "\n",
      " elbo: 1.60433078\n",
      "\n",
      " log_likelihoods reduce: -1.18875837\n",
      "\n",
      " elbo: 1.63767231\n",
      "\n",
      " log_likelihoods reduce: -1.22210503\n",
      "\n",
      " elbo: 1.61855924\n",
      "\n",
      " log_likelihoods reduce: -1.20299721\n",
      "\n",
      " elbo: 1.62650955\n",
      "\n",
      " log_likelihoods reduce: -1.21095276\n",
      "\n",
      " elbo: 1.60379505\n",
      "\n",
      " log_likelihoods reduce: -1.18824339\n",
      "\n",
      " elbo: 1.63955569\n",
      "\n",
      " log_likelihoods reduce: -1.22400928\n",
      "\n",
      " elbo: 1.59904563\n",
      "\n",
      " log_likelihoods reduce: -1.18350434\n",
      "\n",
      " elbo: 1.62256265\n",
      "\n",
      " log_likelihoods reduce: -1.2070266\n",
      "\n",
      " elbo: 1.58827186\n",
      "\n",
      " log_likelihoods reduce: -1.17274094\n",
      "\n",
      " elbo: 1.59638536\n",
      "\n",
      " log_likelihoods reduce: -1.18085968\n",
      "\n",
      " elbo: 1.60606146\n",
      "\n",
      " log_likelihoods reduce: -1.19054103\n",
      "\n",
      " elbo: 1.57641566\n",
      "\n",
      " log_likelihoods reduce: -1.16090035\n",
      "\n",
      " elbo: 1.60430849\n",
      "\n",
      " log_likelihoods reduce: -1.18879843\n",
      "\n",
      " elbo: 1.65966153\n",
      "\n",
      " log_likelihoods reduce: -1.2441566\n",
      "\n",
      " elbo: 1.62760508\n",
      "\n",
      " log_likelihoods reduce: -1.21210539\n",
      "\n",
      " elbo: 1.58475661\n",
      "\n",
      " log_likelihoods reduce: -1.16926205\n",
      "\n",
      " elbo: 1.59072268\n",
      "\n",
      " log_likelihoods reduce: -1.17523336\n",
      "\n",
      " elbo: 1.60060883\n",
      "\n",
      " log_likelihoods reduce: -1.18512464\n",
      "\n",
      " elbo: 1.62465024\n",
      "\n",
      " log_likelihoods reduce: -1.2091713\n",
      "\n",
      " elbo: 1.61624944\n",
      "\n",
      " log_likelihoods reduce: -1.20077562\n",
      "\n",
      " elbo: 1.60896266\n",
      "\n",
      " log_likelihoods reduce: -1.19349408\n",
      "\n",
      " elbo: 1.5961442\n",
      "\n",
      " log_likelihoods reduce: -1.18068075\n",
      "\n",
      " elbo: 1.62261629\n",
      "\n",
      " log_likelihoods reduce: -1.20715809\n",
      "\n",
      " elbo: 1.59824908\n",
      "\n",
      " log_likelihoods reduce: -1.182796\n",
      "\n",
      " elbo: 1.65722489\n",
      "\n",
      " log_likelihoods reduce: -1.24177694\n",
      "\n",
      " elbo: 1.61466885\n",
      "\n",
      " log_likelihoods reduce: -1.19922614\n",
      "\n",
      " elbo: 1.59107792\n",
      "\n",
      " log_likelihoods reduce: -1.17564034\n",
      "\n",
      " elbo: 1.5792377\n",
      "\n",
      " log_likelihoods reduce: -1.16380525\n",
      "\n",
      " elbo: 1.61197\n",
      "\n",
      " log_likelihoods reduce: -1.19654274\n",
      "\n",
      " elbo: 1.61779177\n",
      "\n",
      " log_likelihoods reduce: -1.20236969\n",
      "\n",
      " elbo: 1.59980202\n",
      "\n",
      " log_likelihoods reduce: -1.18438506\n",
      "\n",
      " elbo: 1.60284805\n",
      "\n",
      " log_likelihoods reduce: -1.18743634\n",
      "\n",
      " elbo: 1.64890099\n",
      "\n",
      " log_likelihoods reduce: -1.2334944\n",
      "\n",
      " elbo: 1.62546039\n",
      "\n",
      " log_likelihoods reduce: -1.21005893\n",
      "\n",
      " elbo: 1.60703921\n",
      "\n",
      " log_likelihoods reduce: -1.191643\n",
      "\n",
      " elbo: 1.58195055\n",
      "\n",
      " log_likelihoods reduce: -1.16655946\n",
      "\n",
      " elbo: 1.6886642\n",
      "\n",
      " log_likelihoods reduce: -1.27327824\n",
      "\n",
      " elbo: 1.61169672\n",
      "\n",
      " log_likelihoods reduce: -1.19631588\n",
      "\n",
      " elbo: 1.61271894\n",
      "\n",
      " log_likelihoods reduce: -1.19734335\n",
      "\n",
      " elbo: 1.64658785\n",
      "\n",
      " log_likelihoods reduce: -1.23121738\n",
      "\n",
      " elbo: 1.58708644\n",
      "\n",
      " log_likelihoods reduce: -1.1717211\n",
      "\n",
      " elbo: 1.63458192\n",
      "\n",
      " log_likelihoods reduce: -1.21922183\n",
      "\n",
      " elbo: 1.60495877\n",
      "\n",
      " log_likelihoods reduce: -1.18960381\n",
      "\n",
      " elbo: 1.64097524\n",
      "\n",
      " log_likelihoods reduce: -1.22562551\n",
      "\n",
      " elbo: 1.55667782\n",
      "\n",
      " log_likelihoods reduce: -1.1413331\n",
      "\n",
      " elbo: 1.63353503\n",
      "\n",
      " log_likelihoods reduce: -1.21819556\n",
      "\n",
      " elbo: 1.61685145\n",
      "\n",
      " log_likelihoods reduce: -1.20151711\n",
      "\n",
      " elbo: 1.57977271\n",
      "\n",
      " log_likelihoods reduce: -1.16444349\n",
      "\n",
      " elbo: 1.62105632\n",
      "\n",
      " log_likelihoods reduce: -1.20573235\n",
      "\n",
      " elbo: 1.62377346\n",
      "\n",
      " log_likelihoods reduce: -1.20845461\n",
      "\n",
      " elbo: 1.64540815\n",
      "\n",
      " log_likelihoods reduce: -1.23009443\n",
      "\n",
      " elbo: 1.64023936\n",
      "\n",
      " log_likelihoods reduce: -1.22493076\n",
      "\n",
      " elbo: 1.55930948\n",
      "\n",
      " log_likelihoods reduce: -1.14400601\n",
      "\n",
      " elbo: 1.59002817\n",
      "\n",
      " log_likelihoods reduce: -1.17472982\n",
      "\n",
      " elbo: 1.65354705\n",
      "\n",
      " log_likelihoods reduce: -1.23825383\n",
      "\n",
      " elbo: 1.62682545\n",
      "\n",
      " log_likelihoods reduce: -1.21153736\n",
      "\n",
      " elbo: 1.62919545\n",
      "\n",
      " log_likelihoods reduce: -1.21391249\n",
      "\n",
      " elbo: 1.60066569\n",
      "\n",
      " log_likelihoods reduce: -1.18538785\n",
      "\n",
      " elbo: 1.5990119\n",
      "\n",
      " log_likelihoods reduce: -1.18373919\n",
      "\n",
      " elbo: 1.58730137\n",
      "\n",
      " log_likelihoods reduce: -1.17203379\n",
      "\n",
      " elbo: 1.64270067\n",
      "\n",
      " log_likelihoods reduce: -1.22743833\n",
      "\n",
      " elbo: 1.62273741\n",
      "\n",
      " log_likelihoods reduce: -1.20748019\n",
      "\n",
      " elbo: 1.56329322\n",
      "\n",
      " log_likelihoods reduce: -1.14804101\n",
      "\n",
      " elbo: 1.55215192\n",
      "\n",
      " log_likelihoods reduce: -1.13690484\n",
      "\n",
      " elbo: 1.58981121\n",
      "\n",
      " log_likelihoods reduce: -1.17456925\n",
      "\n",
      " elbo: 1.60109723\n",
      "\n",
      " log_likelihoods reduce: -1.1858604\n",
      "\n",
      " elbo: 1.63286495\n",
      "\n",
      " log_likelihoods reduce: -1.21763337\n",
      "\n",
      " elbo: 1.5642482\n",
      "\n",
      " log_likelihoods reduce: -1.14902163\n",
      "\n",
      " elbo: 1.59999776\n",
      "\n",
      " log_likelihoods reduce: -1.18477631\n",
      "\n",
      " elbo: 1.55803704\n",
      "\n",
      " log_likelihoods reduce: -1.14282084\n",
      "\n",
      " elbo: 1.61038589\n",
      "\n",
      " log_likelihoods reduce: -1.19517469\n",
      "\n",
      " elbo: 1.6420747\n",
      "\n",
      " log_likelihoods reduce: -1.22686863\n",
      "\n",
      " elbo: 1.64305019\n",
      "\n",
      " log_likelihoods reduce: -1.22784913\n",
      "\n",
      " elbo: 1.58046162\n",
      "\n",
      " log_likelihoods reduce: -1.1652658\n",
      "\n",
      " elbo: 1.59102225\n",
      "\n",
      " log_likelihoods reduce: -1.17583156\n",
      "\n",
      " elbo: 1.58183432\n",
      "\n",
      " log_likelihoods reduce: -1.16664875\n",
      "\n",
      " elbo: 1.59456885\n",
      "\n",
      " log_likelihoods reduce: -1.17938828\n",
      "\n",
      " elbo: 1.56339574\n",
      "\n",
      " log_likelihoods reduce: -1.1482203\n",
      "\n",
      " elbo: 1.58546829\n",
      "\n",
      " log_likelihoods reduce: -1.17029786\n",
      "\n",
      " elbo: 1.60630727\n",
      "\n",
      " log_likelihoods reduce: -1.19114196\n",
      "\n",
      " elbo: 1.59808707\n",
      "\n",
      " log_likelihoods reduce: -1.18292689\n",
      "\n",
      " elbo: 1.60000575\n",
      "\n",
      " log_likelihoods reduce: -1.18485069\n",
      "\n",
      " elbo: 1.61318922\n",
      "\n",
      " log_likelihoods reduce: -1.19803929\n",
      "\n",
      " elbo: 1.59376073\n",
      "\n",
      " log_likelihoods reduce: -1.17861581\n",
      "\n",
      " elbo: 1.65131891\n",
      "\n",
      " log_likelihoods reduce: -1.23617911\n",
      "\n",
      " elbo: 1.57942379\n",
      "\n",
      " log_likelihoods reduce: -1.16428912\n",
      "\n",
      " elbo: 1.57548368\n",
      "\n",
      " log_likelihoods reduce: -1.16035414\n",
      "\n",
      " elbo: 1.59937203\n",
      "\n",
      " log_likelihoods reduce: -1.18424749\n",
      "\n",
      " elbo: 1.62370491\n",
      "\n",
      " log_likelihoods reduce: -1.2085855\n",
      "\n",
      " elbo: 1.61324012\n",
      "\n",
      " log_likelihoods reduce: -1.19812584\n",
      "\n",
      " elbo: 1.62088633\n",
      "\n",
      " log_likelihoods reduce: -1.20577717\n",
      "\n",
      " elbo: 1.64565086\n",
      "\n",
      " log_likelihoods reduce: -1.23054671\n",
      "\n",
      " elbo: 1.63611746\n",
      "\n",
      " log_likelihoods reduce: -1.22101843\n",
      "\n",
      " elbo: 1.59798181\n",
      "\n",
      " log_likelihoods reduce: -1.18288779\n",
      "\n",
      " elbo: 1.62453055\n",
      "\n",
      " log_likelihoods reduce: -1.20944166\n",
      "\n",
      " elbo: 1.63088727\n",
      "\n",
      " log_likelihoods reduce: -1.21580338\n",
      "\n",
      " elbo: 1.60524094\n",
      "\n",
      " log_likelihoods reduce: -1.19016218\n",
      "\n",
      " elbo: 1.64862323\n",
      "\n",
      " log_likelihoods reduce: -1.23354948\n",
      "\n",
      " elbo: 1.56865811\n",
      "\n",
      " log_likelihoods reduce: -1.15358949\n",
      "\n",
      " elbo: 1.64957106\n",
      "\n",
      " log_likelihoods reduce: -1.23450744\n",
      "\n",
      " elbo: 1.59280372\n",
      "\n",
      " log_likelihoods reduce: -1.17774522\n",
      "\n",
      " elbo: 1.61455059\n",
      "\n",
      " log_likelihoods reduce: -1.1994971\n",
      "\n",
      " elbo: 1.62218809\n",
      "\n",
      " log_likelihoods reduce: -1.20713973\n",
      "\n",
      " elbo: 1.61413121\n",
      "\n",
      " log_likelihoods reduce: -1.19908786\n",
      "\n",
      " elbo: 1.66325033\n",
      "\n",
      " log_likelihoods reduce: -1.2482121\n",
      "\n",
      " elbo: 1.58529532\n",
      "\n",
      " log_likelihoods reduce: -1.1702621\n",
      "\n",
      " elbo: 1.64997637\n",
      "\n",
      " log_likelihoods reduce: -1.23494816\n",
      "\n",
      " elbo: 1.5889796\n",
      "\n",
      " log_likelihoods reduce: -1.17395651\n",
      "\n",
      " elbo: 1.60321045\n",
      "\n",
      " log_likelihoods reduce: -1.18819237\n",
      "\n",
      " elbo: 1.65581822\n",
      "\n",
      " log_likelihoods reduce: -1.24080515\n",
      "\n",
      " elbo: 1.52697599\n",
      "\n",
      " log_likelihoods reduce: -1.11196804\n",
      "\n",
      " elbo: 1.59156847\n",
      "\n",
      " log_likelihoods reduce: -1.17656553\n",
      "\n",
      " elbo: 1.61651981\n",
      "\n",
      " log_likelihoods reduce: -1.20152199\n",
      "\n",
      " elbo: 1.62537694\n",
      "\n",
      " log_likelihoods reduce: -1.21038413\n",
      "\n",
      " elbo: 1.60859048\n",
      "\n",
      " log_likelihoods reduce: -1.19360268\n",
      "\n",
      " elbo: 1.59536755\n",
      "\n",
      " log_likelihoods reduce: -1.18038487\n",
      "\n",
      " elbo: 1.58116329\n",
      "\n",
      " log_likelihoods reduce: -1.16618562\n",
      "\n",
      " elbo: 1.62359822\n",
      "\n",
      " log_likelihoods reduce: -1.20862556\n",
      "\n",
      " elbo: 1.58631158\n",
      "\n",
      " log_likelihoods reduce: -1.17134404\n",
      "\n",
      " elbo: 1.56748223\n",
      "\n",
      " log_likelihoods reduce: -1.1525197\n",
      "\n",
      " elbo: 1.61287749\n",
      "\n",
      " log_likelihoods reduce: -1.19792\n",
      "\n",
      " elbo: 1.59563243\n",
      "\n",
      " log_likelihoods reduce: -1.18067992\n",
      "\n",
      " elbo: 1.57865632\n",
      "\n",
      " log_likelihoods reduce: -1.16370893\n",
      "\n",
      " elbo: 1.63758588\n",
      "\n",
      " log_likelihoods reduce: -1.22264349\n",
      "\n",
      " elbo: 1.59648454\n",
      "\n",
      " log_likelihoods reduce: -1.18154716\n",
      "\n",
      " elbo: 1.57211399\n",
      "\n",
      " log_likelihoods reduce: -1.15718162\n",
      "\n",
      " elbo: 1.62149656\n",
      "\n",
      " log_likelihoods reduce: -1.20656931\n",
      "\n",
      " elbo: 1.57921958\n",
      "\n",
      " log_likelihoods reduce: -1.16429734\n",
      "\n",
      " elbo: 1.58001685\n",
      "\n",
      " log_likelihoods reduce: -1.16509962\n",
      "\n",
      " elbo: 1.59445977\n",
      "\n",
      " log_likelihoods reduce: -1.17954755\n",
      "\n",
      " elbo: 1.55421185\n",
      "\n",
      " log_likelihoods reduce: -1.13930476\n",
      "\n",
      " elbo: 1.60276556\n",
      "\n",
      " log_likelihoods reduce: -1.18786335\n",
      "\n",
      " elbo: 1.58509791\n",
      "\n",
      " log_likelihoods reduce: -1.17020071\n",
      "\n",
      " elbo: 1.60105681\n",
      "\n",
      " log_likelihoods reduce: -1.18616462\n",
      "\n",
      " elbo: 1.60309076\n",
      "\n",
      " log_likelihoods reduce: -1.18820357\n",
      "\n",
      " elbo: 1.56299424\n",
      "\n",
      " log_likelihoods reduce: -1.14811218\n",
      "\n",
      " elbo: 1.61510861\n",
      "\n",
      " log_likelihoods reduce: -1.20023155\n",
      "\n",
      " elbo: 1.58817971\n",
      "\n",
      " log_likelihoods reduce: -1.17330766\n",
      "\n",
      " elbo: 1.5840646\n",
      "\n",
      " log_likelihoods reduce: -1.16919756\n",
      "\n",
      " elbo: 1.59781349\n",
      "\n",
      " log_likelihoods reduce: -1.18295145\n",
      "\n",
      " elbo: 1.59536386\n",
      "\n",
      " log_likelihoods reduce: -1.18050683\n",
      "\n",
      " elbo: 1.60441458\n",
      "\n",
      " log_likelihoods reduce: -1.18956256\n",
      "\n",
      " elbo: 1.6086694\n",
      "\n",
      " log_likelihoods reduce: -1.19382238\n",
      "\n",
      " elbo: 1.62660444\n",
      "\n",
      " log_likelihoods reduce: -1.21176243\n",
      "\n",
      " elbo: 1.56142783\n",
      "\n",
      " log_likelihoods reduce: -1.14659071\n",
      "\n",
      " elbo: 1.58241904\n",
      "\n",
      " log_likelihoods reduce: -1.16758704\n",
      "\n",
      " elbo: 1.58235371\n",
      "\n",
      " log_likelihoods reduce: -1.16752672\n",
      "\n",
      " elbo: 1.58535504\n",
      "\n",
      " log_likelihoods reduce: -1.17053294\n",
      "\n",
      " elbo: 1.61090422\n",
      "\n",
      " log_likelihoods reduce: -1.19608712\n",
      "\n",
      " elbo: 1.64778638\n",
      "\n",
      " log_likelihoods reduce: -1.23297429\n",
      "\n",
      " elbo: 1.58414304\n",
      "\n",
      " log_likelihoods reduce: -1.16933596\n",
      "\n",
      " elbo: 1.59363854\n",
      "\n",
      " log_likelihoods reduce: -1.17883646\n",
      "\n",
      " elbo: 1.57651389\n",
      "\n",
      " log_likelihoods reduce: -1.16171682\n",
      "\n",
      " elbo: 1.61594725\n",
      "\n",
      " log_likelihoods reduce: -1.20115519\n",
      "\n",
      " elbo: 1.60299766\n",
      "\n",
      " log_likelihoods reduce: -1.18821049\n",
      "\n",
      " elbo: 1.58395195\n",
      "\n",
      " log_likelihoods reduce: -1.16916966\n",
      "\n",
      " elbo: 1.58506882\n",
      "\n",
      " log_likelihoods reduce: -1.17029166\n",
      "\n",
      " elbo: 1.64631128\n",
      "\n",
      " log_likelihoods reduce: -1.23153913\n",
      "\n",
      " elbo: 1.57208645\n",
      "\n",
      " log_likelihoods reduce: -1.15731919\n",
      "\n",
      " elbo: 1.58377314\n",
      "\n",
      " log_likelihoods reduce: -1.16901088\n",
      "\n",
      " elbo: 1.61997843\n",
      "\n",
      " log_likelihoods reduce: -1.20522118\n",
      "\n",
      " elbo: 1.5925889\n",
      "\n",
      " log_likelihoods reduce: -1.17783666\n",
      "\n",
      " elbo: 1.57517946\n",
      "\n",
      " log_likelihoods reduce: -1.1604321\n",
      "\n",
      " elbo: 1.56476569\n",
      "\n",
      " log_likelihoods reduce: -1.15002334\n",
      "\n",
      " elbo: 1.5924592\n",
      "\n",
      " log_likelihoods reduce: -1.17772174\n",
      "\n",
      " elbo: 1.60627365\n",
      "\n",
      " log_likelihoods reduce: -1.19154119\n",
      "\n",
      " elbo: 1.64035642\n",
      "\n",
      " log_likelihoods reduce: -1.22562885\n",
      "\n",
      " elbo: 1.54494679\n",
      "\n",
      " log_likelihoods reduce: -1.13022423\n",
      "\n",
      " elbo: 1.55977714\n",
      "\n",
      " log_likelihoods reduce: -1.14505959\n",
      "\n",
      " elbo: 1.55726993\n",
      "\n",
      " log_likelihoods reduce: -1.14255738\n",
      "\n",
      " elbo: 1.55230832\n",
      "\n",
      " log_likelihoods reduce: -1.13760066\n",
      "\n",
      " elbo: 1.56614232\n",
      "\n",
      " log_likelihoods reduce: -1.15143967\n",
      "\n",
      " elbo: 1.55962944\n",
      "\n",
      " log_likelihoods reduce: -1.14493179\n",
      "\n",
      " elbo: 1.52158689\n",
      "\n",
      " log_likelihoods reduce: -1.10689414\n",
      "\n",
      " elbo: 1.57710087\n",
      "\n",
      " log_likelihoods reduce: -1.16241312\n",
      "\n",
      " elbo: 1.54637575\n",
      "\n",
      " log_likelihoods reduce: -1.13169289\n",
      "\n",
      " elbo: 1.63320398\n",
      "\n",
      " log_likelihoods reduce: -1.21852612\n",
      "\n",
      " elbo: 1.56916857\n",
      "\n",
      " log_likelihoods reduce: -1.15449572\n",
      "\n",
      " elbo: 1.60205007\n",
      "\n",
      " log_likelihoods reduce: -1.18738222\n",
      "\n",
      " elbo: 1.58309078\n",
      "\n",
      " log_likelihoods reduce: -1.16842771\n",
      "\n",
      " elbo: 1.52519774\n",
      "\n",
      " log_likelihoods reduce: -1.11053967\n",
      "\n",
      " elbo: 1.54957032\n",
      "\n",
      " log_likelihoods reduce: -1.13491714\n",
      "\n",
      " elbo: 1.66344619\n",
      "\n",
      " log_likelihoods reduce: -1.24879801\n",
      "\n",
      " elbo: 1.58498919\n",
      "\n",
      " log_likelihoods reduce: -1.1703459\n",
      "\n",
      " elbo: 1.55263877\n",
      "\n",
      " log_likelihoods reduce: -1.13800037\n",
      "\n",
      " elbo: 1.56804645\n",
      "\n",
      " log_likelihoods reduce: -1.15341306\n",
      "\n",
      " elbo: 1.60759985\n",
      "\n",
      " log_likelihoods reduce: -1.19297135\n",
      "\n",
      " elbo: 1.54465079\n",
      "\n",
      " log_likelihoods reduce: -1.13002729\n",
      "\n",
      " elbo: 1.5945195\n",
      "\n",
      " log_likelihoods reduce: -1.17990088\n",
      "\n",
      " elbo: 1.59706116\n",
      "\n",
      " log_likelihoods reduce: -1.18244743\n",
      "\n",
      " elbo: 1.57534337\n",
      "\n",
      " log_likelihoods reduce: -1.16073453\n",
      "\n",
      " elbo: 1.57743835\n",
      "\n",
      " log_likelihoods reduce: -1.16283441\n",
      "\n",
      " elbo: 1.58238149\n",
      "\n",
      " log_likelihoods reduce: -1.16778255\n",
      "\n",
      " elbo: 1.58869696\n",
      "\n",
      " log_likelihoods reduce: -1.1741029\n",
      "\n",
      " elbo: 1.54682922\n",
      "\n",
      " log_likelihoods reduce: -1.13224\n",
      "\n",
      " elbo: 1.55771971\n",
      "\n",
      " log_likelihoods reduce: -1.14313555\n",
      "\n",
      " elbo: 1.58379006\n",
      "\n",
      " log_likelihoods reduce: -1.16921067\n",
      "\n",
      " elbo: 1.57813263\n",
      "\n",
      " log_likelihoods reduce: -1.16355813\n",
      "\n",
      " elbo: 1.51539302\n",
      "\n",
      " log_likelihoods reduce: -1.10082352\n",
      "\n",
      " elbo: 1.60316634\n",
      "\n",
      " log_likelihoods reduce: -1.18860173\n",
      "\n",
      " elbo: 1.59135199\n",
      "\n",
      " log_likelihoods reduce: -1.17679226\n",
      "\n",
      " elbo: 1.589463\n",
      "\n",
      " log_likelihoods reduce: -1.17490816\n",
      "\n",
      " elbo: 1.51983297\n",
      "\n",
      " log_likelihoods reduce: -1.10528302\n",
      "\n",
      " elbo: 1.58054399\n",
      "\n",
      " log_likelihoods reduce: -1.16599894\n",
      "\n",
      " elbo: 1.6023488\n",
      "\n",
      " log_likelihoods reduce: -1.18780863\n",
      "\n",
      " elbo: 1.57357144\n",
      "\n",
      " log_likelihoods reduce: -1.15903616\n",
      "\n",
      " elbo: 1.57787049\n",
      "\n",
      " log_likelihoods reduce: -1.16334009\n",
      "\n",
      " elbo: 1.60413039\n",
      "\n",
      " log_likelihoods reduce: -1.18960488\n",
      "\n",
      " elbo: 1.5795933\n",
      "\n",
      " log_likelihoods reduce: -1.16507268\n",
      "\n",
      " elbo: 1.60380268\n",
      "\n",
      " log_likelihoods reduce: -1.18928695\n",
      "\n",
      " elbo: 1.58500218\n",
      "\n",
      " log_likelihoods reduce: -1.17049134\n",
      "\n",
      " elbo: 1.53838575\n",
      "\n",
      " log_likelihoods reduce: -1.12387979\n",
      "\n",
      " elbo: 1.59184563\n",
      "\n",
      " log_likelihoods reduce: -1.17734456\n",
      "\n",
      " elbo: 1.55487823\n",
      "\n",
      " log_likelihoods reduce: -1.14038205\n",
      "\n",
      " elbo: 1.54705453\n",
      "\n",
      " log_likelihoods reduce: -1.13256311\n",
      "\n",
      " elbo: 1.54483604\n",
      "\n",
      " log_likelihoods reduce: -1.13034964\n",
      "\n",
      " elbo: 1.59801507\n",
      "\n",
      " log_likelihoods reduce: -1.18353343\n",
      "\n",
      " elbo: 1.61098373\n",
      "\n",
      " log_likelihoods reduce: -1.19650698\n",
      "\n",
      " elbo: 1.54298365\n",
      "\n",
      " log_likelihoods reduce: -1.12851179\n",
      "\n",
      " elbo: 1.59873927\n",
      "\n",
      " log_likelihoods reduce: -1.18427229\n",
      "\n",
      " elbo: 1.55675697\n",
      "\n",
      " log_likelihoods reduce: -1.14229488\n",
      "\n",
      " elbo: 1.56410563\n",
      "\n",
      " log_likelihoods reduce: -1.14964843\n",
      "\n",
      " elbo: 1.59420812\n",
      "\n",
      " log_likelihoods reduce: -1.17975569\n",
      "\n",
      " elbo: 1.59655118\n",
      "\n",
      " log_likelihoods reduce: -1.18210363\n",
      "\n",
      " elbo: 1.5739038\n",
      "\n",
      " log_likelihoods reduce: -1.15946114\n",
      "\n",
      " elbo: 1.55750895\n",
      "\n",
      " log_likelihoods reduce: -1.14307117\n",
      "\n",
      " elbo: 1.56732798\n",
      "\n",
      " log_likelihoods reduce: -1.15289509\n",
      "\n",
      " elbo: 1.57997739\n",
      "\n",
      " log_likelihoods reduce: -1.16554928\n",
      "\n",
      " elbo: 1.62160158\n",
      "\n",
      " log_likelihoods reduce: -1.20717835\n",
      "\n",
      " elbo: 1.55720723\n",
      "\n",
      " log_likelihoods reduce: -1.14278889\n",
      "\n",
      " elbo: 1.56691217\n",
      "\n",
      " log_likelihoods reduce: -1.15249872\n",
      "\n",
      " elbo: 1.57351363\n",
      "\n",
      " log_likelihoods reduce: -1.15910506\n",
      "\n",
      " elbo: 1.55597627\n",
      "\n",
      " log_likelihoods reduce: -1.14157248\n",
      "\n",
      " elbo: 1.58045149\n",
      "\n",
      " log_likelihoods reduce: -1.16605258\n",
      "\n",
      " elbo: 1.59456432\n",
      "\n",
      " log_likelihoods reduce: -1.1801703\n",
      "\n",
      " elbo: 1.54052424\n",
      "\n",
      " log_likelihoods reduce: -1.12613511\n",
      "\n",
      " elbo: 1.5741117\n",
      "\n",
      " log_likelihoods reduce: -1.15972745\n",
      "\n",
      " elbo: 1.55371761\n",
      "\n",
      " log_likelihoods reduce: -1.13933814\n",
      "\n",
      " elbo: 1.5815711\n",
      "\n",
      " log_likelihoods reduce: -1.16719651\n",
      "\n",
      " elbo: 1.59562492\n",
      "\n",
      " log_likelihoods reduce: -1.1812551\n",
      "\n",
      " elbo: 1.66363096\n",
      "\n",
      " log_likelihoods reduce: -1.24926615\n",
      "\n",
      " elbo: 1.55473626\n",
      "\n",
      " log_likelihoods reduce: -1.14037621\n",
      "\n",
      " elbo: 1.56660402\n",
      "\n",
      " log_likelihoods reduce: -1.15224886\n",
      "\n",
      " elbo: 1.52489781\n",
      "\n",
      " log_likelihoods reduce: -1.11054742\n",
      "\n",
      " elbo: 1.56988859\n",
      "\n",
      " log_likelihoods reduce: -1.15554309\n",
      "\n",
      " elbo: 1.64125633\n",
      "\n",
      " log_likelihoods reduce: -1.2269156\n",
      "\n",
      " elbo: 1.57796061\n",
      "\n",
      " log_likelihoods reduce: -1.16362476\n",
      "\n",
      " elbo: 1.54134357\n",
      "\n",
      " log_likelihoods reduce: -1.12701249\n",
      "\n",
      " elbo: 1.63382173\n",
      "\n",
      " log_likelihoods reduce: -1.21949553\n",
      "\n",
      " elbo: 1.57217538\n",
      "\n",
      " log_likelihoods reduce: -1.15785396\n",
      "\n",
      " elbo: 1.5663805\n",
      "\n",
      " log_likelihoods reduce: -1.15206397\n",
      "\n",
      " elbo: 1.52402043\n",
      "\n",
      " log_likelihoods reduce: -1.10970867\n",
      "\n",
      " elbo: 1.60885429\n",
      "\n",
      " log_likelihoods reduce: -1.19454741\n",
      "\n",
      " elbo: 1.52287602\n",
      "\n",
      " log_likelihoods reduce: -1.10857391\n",
      "\n",
      " elbo: 1.59844089\n",
      "\n",
      " log_likelihoods reduce: -1.18414366\n",
      "\n",
      " elbo: 1.58237445\n",
      "\n",
      " log_likelihoods reduce: -1.168082\n",
      "\n",
      " elbo: 1.50527048\n",
      "\n",
      " log_likelihoods reduce: -1.09098291\n",
      "\n",
      " elbo: 1.5621227\n",
      "\n",
      " log_likelihoods reduce: -1.1478399\n",
      "\n",
      " elbo: 1.55428267\n",
      "\n",
      " log_likelihoods reduce: -1.14000463\n",
      "\n",
      " elbo: 1.62917101\n",
      "\n",
      " log_likelihoods reduce: -1.21489787\n",
      "\n",
      " elbo: 1.54582214\n",
      "\n",
      " log_likelihoods reduce: -1.13155377\n",
      "\n",
      " elbo: 1.54527557\n",
      "\n",
      " log_likelihoods reduce: -1.13101208\n",
      "\n",
      " elbo: 1.60981143\n",
      "\n",
      " log_likelihoods reduce: -1.19555271\n",
      "\n",
      " elbo: 1.55637503\n",
      "\n",
      " log_likelihoods reduce: -1.14212108\n",
      "\n",
      " elbo: 1.56093121\n",
      "\n",
      " log_likelihoods reduce: -1.14668202\n",
      "\n",
      " elbo: 1.56856811\n",
      "\n",
      " log_likelihoods reduce: -1.15432382\n",
      "\n",
      " elbo: 1.54974759\n",
      "\n",
      " log_likelihoods reduce: -1.13550806\n",
      "\n",
      " elbo: 1.55210221\n",
      "\n",
      " log_likelihoods reduce: -1.13786745\n",
      "\n",
      " elbo: 1.57275105\n",
      "\n",
      " log_likelihoods reduce: -1.15852118\n",
      "\n",
      " elbo: 1.58153629\n",
      "\n",
      " log_likelihoods reduce: -1.16731119\n",
      "\n",
      " elbo: 1.64373291\n",
      "\n",
      " log_likelihoods reduce: -1.22951257\n",
      "\n",
      " elbo: 1.53113067\n",
      "\n",
      " log_likelihoods reduce: -1.11691511\n",
      "\n",
      " elbo: 1.56900144\n",
      "\n",
      " log_likelihoods reduce: -1.15479076\n",
      "\n",
      " elbo: 1.52396178\n",
      "\n",
      " log_likelihoods reduce: -1.10975575\n",
      "\n",
      " elbo: 1.56335163\n",
      "\n",
      " log_likelihoods reduce: -1.14915037\n",
      "\n",
      " elbo: 1.57883859\n",
      "\n",
      " log_likelihoods reduce: -1.1646421\n",
      "\n",
      " elbo: 1.5614171\n",
      "\n",
      " log_likelihoods reduce: -1.14722538\n",
      "\n",
      " elbo: 1.55752277\n",
      "\n",
      " log_likelihoods reduce: -1.14333582\n",
      "\n",
      " elbo: 1.58481991\n",
      "\n",
      " log_likelihoods reduce: -1.17063773\n",
      "\n",
      " elbo: 1.55906463\n",
      "\n",
      " log_likelihoods reduce: -1.14488721\n",
      "\n",
      " elbo: 1.5761764\n",
      "\n",
      " log_likelihoods reduce: -1.16200364\n",
      "\n",
      " elbo: 1.51490664\n",
      "\n",
      " log_likelihoods reduce: -1.10073864\n",
      "\n",
      " elbo: 1.54700935\n",
      "\n",
      " log_likelihoods reduce: -1.13284612\n",
      "\n",
      " elbo: 1.51597643\n",
      "\n",
      " log_likelihoods reduce: -1.10181808\n",
      "\n",
      " elbo: 1.57368648\n",
      "\n",
      " log_likelihoods reduce: -1.15953279\n",
      "\n",
      " elbo: 1.56906331\n",
      "\n",
      " log_likelihoods reduce: -1.15491438\n",
      "\n",
      " elbo: 1.54536152\n",
      "\n",
      " log_likelihoods reduce: -1.13121736\n",
      "\n",
      " elbo: 1.51519918\n",
      "\n",
      " log_likelihoods reduce: -1.10105968\n",
      "\n",
      " elbo: 1.55435276\n",
      "\n",
      " log_likelihoods reduce: -1.14021802\n",
      "\n",
      " elbo: 1.58442974\n",
      "\n",
      " log_likelihoods reduce: -1.17029977\n",
      "\n",
      " elbo: 1.56010067\n",
      "\n",
      " log_likelihoods reduce: -1.14597547\n",
      "\n",
      " elbo: 1.57825208\n",
      "\n",
      " log_likelihoods reduce: -1.16413164\n",
      "\n",
      " elbo: 1.54174161\n",
      "\n",
      " log_likelihoods reduce: -1.12762594\n",
      "\n",
      " elbo: 1.51053596\n",
      "\n",
      " log_likelihoods reduce: -1.09642506\n",
      "\n",
      " elbo: 1.54041851\n",
      "\n",
      " log_likelihoods reduce: -1.12631226\n",
      "\n",
      " elbo: 1.54822457\n",
      "\n",
      " log_likelihoods reduce: -1.13412309\n",
      "\n",
      " elbo: 1.54824078\n",
      "\n",
      " log_likelihoods reduce: -1.13414407\n",
      "\n",
      " elbo: 1.51382232\n",
      "\n",
      " log_likelihoods reduce: -1.09973037\n",
      "\n",
      " elbo: 1.52510715\n",
      "\n",
      " log_likelihoods reduce: -1.11101985\n",
      "\n",
      " elbo: 1.56972337\n",
      "\n",
      " log_likelihoods reduce: -1.15564084\n",
      "\n",
      " elbo: 1.51550698\n",
      "\n",
      " log_likelihoods reduce: -1.1014291\n",
      "\n",
      " elbo: 1.62697101\n",
      "\n",
      " log_likelihoods reduce: -1.2128979\n",
      "\n",
      " elbo: 1.54813695\n",
      "\n",
      " log_likelihoods reduce: -1.13406861\n",
      "\n",
      " elbo: 1.54342914\n",
      "\n",
      " log_likelihoods reduce: -1.12936544\n",
      "\n",
      " elbo: 1.56500471\n",
      "\n",
      " log_likelihoods reduce: -1.15094578\n",
      "\n",
      " elbo: 1.5626421\n",
      "\n",
      " log_likelihoods reduce: -1.14858794\n",
      "\n",
      " elbo: 1.59459043\n",
      "\n",
      " log_likelihoods reduce: -1.18054104\n",
      "\n",
      " elbo: 1.56425226\n",
      "\n",
      " log_likelihoods reduce: -1.15020752\n",
      "\n",
      " elbo: 1.49375129\n",
      "\n",
      " log_likelihoods reduce: -1.07971132\n",
      "\n",
      " elbo: 1.61073518\n",
      "\n",
      " log_likelihoods reduce: -1.1967\n",
      "\n",
      " elbo: 1.54519773\n",
      "\n",
      " log_likelihoods reduce: -1.13116717\n",
      "\n",
      " elbo: 1.53689456\n",
      "\n",
      " log_likelihoods reduce: -1.12286878\n",
      "\n",
      " elbo: 1.51654565\n",
      "\n",
      " log_likelihoods reduce: -1.10252452\n",
      "\n",
      " elbo: 1.55793858\n",
      "\n",
      " log_likelihoods reduce: -1.14392221\n",
      "\n",
      " elbo: 1.50787473\n",
      "\n",
      " log_likelihoods reduce: -1.09386301\n",
      "\n",
      " elbo: 1.56497335\n",
      "\n",
      " log_likelihoods reduce: -1.15096641\n",
      "\n",
      " elbo: 1.59052992\n",
      "\n",
      " log_likelihoods reduce: -1.17652774\n",
      "\n",
      " elbo: 1.57157707\n",
      "\n",
      " log_likelihoods reduce: -1.15757954\n",
      "\n",
      " elbo: 1.57532406\n",
      "\n",
      " log_likelihoods reduce: -1.1613313\n",
      "\n",
      " elbo: 1.58496141\n",
      "\n",
      " log_likelihoods reduce: -1.1709733\n",
      "\n",
      " elbo: 1.54921532\n",
      "\n",
      " log_likelihoods reduce: -1.13523197\n",
      "\n",
      " elbo: 1.48236299\n",
      "\n",
      " log_likelihoods reduce: -1.06838429\n",
      "\n",
      " elbo: 1.52016079\n",
      "\n",
      " log_likelihoods reduce: -1.10618687\n",
      "\n",
      " elbo: 1.58306372\n",
      "\n",
      " log_likelihoods reduce: -1.16909444\n",
      "\n",
      " elbo: 1.54453182\n",
      "\n",
      " log_likelihoods reduce: -1.13056731\n",
      "\n",
      " elbo: 1.55123115\n",
      "\n",
      " log_likelihoods reduce: -1.13727129\n",
      "\n",
      " elbo: 1.55633259\n",
      "\n",
      " log_likelihoods reduce: -1.14237738\n",
      "\n",
      " elbo: 1.57332242\n",
      "\n",
      " log_likelihoods reduce: -1.15937197\n",
      "\n",
      " elbo: 1.57440865\n",
      "\n",
      " log_likelihoods reduce: -1.16046286\n",
      "\n",
      " elbo: 1.54605913\n",
      "\n",
      " log_likelihoods reduce: -1.13211799\n",
      "\n",
      " elbo: 1.50347316\n",
      "\n",
      " log_likelihoods reduce: -1.08953679\n",
      "\n",
      " elbo: 1.55988908\n",
      "\n",
      " log_likelihoods reduce: -1.14595747\n",
      "\n",
      " elbo: 1.63928\n",
      "\n",
      " log_likelihoods reduce: -1.225353\n",
      "\n",
      " elbo: 1.54360092\n",
      "\n",
      " log_likelihoods reduce: -1.12967861\n",
      "\n",
      " elbo: 1.58243346\n",
      "\n",
      " log_likelihoods reduce: -1.16851592\n",
      "\n",
      " elbo: 1.52722704\n",
      "\n",
      " log_likelihoods reduce: -1.11331415\n",
      "\n",
      " elbo: 1.58054662\n",
      "\n",
      " log_likelihoods reduce: -1.16663849\n",
      "\n",
      " elbo: 1.55263531\n",
      "\n",
      " log_likelihoods reduce: -1.13873184\n",
      "\n",
      " elbo: 1.5719105\n",
      "\n",
      " log_likelihoods reduce: -1.15801167\n",
      "\n",
      " elbo: 1.53660464\n",
      "\n",
      " log_likelihoods reduce: -1.12271047\n",
      "\n",
      " elbo: 1.53740919\n",
      "\n",
      " log_likelihoods reduce: -1.12351978\n",
      "\n",
      " elbo: 1.51762319\n",
      "\n",
      " log_likelihoods reduce: -1.10373843\n",
      "\n",
      " elbo: 1.55871248\n",
      "\n",
      " log_likelihoods reduce: -1.14483237\n",
      "\n",
      " elbo: 1.52747321\n",
      "\n",
      " log_likelihoods reduce: -1.11359787\n",
      "\n",
      " elbo: 1.57923293\n",
      "\n",
      " log_likelihoods reduce: -1.16536224\n",
      "\n",
      " elbo: 1.52817297\n",
      "\n",
      " log_likelihoods reduce: -1.11430693\n",
      "\n",
      " elbo: 1.53430438\n",
      "\n",
      " log_likelihoods reduce: -1.12044299\n",
      "\n",
      " elbo: 1.51823425\n",
      "\n",
      " log_likelihoods reduce: -1.10437751\n",
      "\n",
      " elbo: 1.54964733\n",
      "\n",
      " log_likelihoods reduce: -1.13579524\n",
      "\n",
      " elbo: 1.54182577\n",
      "\n",
      " log_likelihoods reduce: -1.12797832\n",
      "\n",
      " elbo: 1.54069459\n",
      "\n",
      " log_likelihoods reduce: -1.1268518\n",
      "\n",
      " elbo: 1.59076381\n",
      "\n",
      " log_likelihoods reduce: -1.17692578\n",
      "\n",
      " elbo: 1.54567504\n",
      "\n",
      " log_likelihoods reduce: -1.13184166\n",
      "\n",
      " elbo: 1.5084492\n",
      "\n",
      " log_likelihoods reduce: -1.09462047\n",
      "\n",
      " elbo: 1.52693713\n",
      "\n",
      " log_likelihoods reduce: -1.11311305\n",
      "\n",
      " elbo: 1.53971064\n",
      "\n",
      " log_likelihoods reduce: -1.12589121\n",
      "\n",
      " elbo: 1.54279828\n",
      "\n",
      " log_likelihoods reduce: -1.12898362\n",
      "\n",
      " elbo: 1.56368303\n",
      "\n",
      " log_likelihoods reduce: -1.1498729\n",
      "\n",
      " elbo: 1.50648069\n",
      "\n",
      " log_likelihoods reduce: -1.09267521\n",
      "\n",
      " elbo: 1.60381687\n",
      "\n",
      " log_likelihoods reduce: -1.19001603\n",
      "\n",
      " elbo: 1.53271067\n",
      "\n",
      " log_likelihoods reduce: -1.1189146\n",
      "\n",
      " elbo: 1.59206414\n",
      "\n",
      " log_likelihoods reduce: -1.17827272\n",
      "\n",
      " elbo: 1.50127149\n",
      "\n",
      " log_likelihoods reduce: -1.0874846\n",
      "\n",
      " elbo: 1.53005552\n",
      "\n",
      " log_likelihoods reduce: -1.1162734\n",
      "\n",
      " elbo: 1.52776766\n",
      "\n",
      " log_likelihoods reduce: -1.11399007\n",
      "\n",
      " elbo: 1.55637813\n",
      "\n",
      " log_likelihoods reduce: -1.1426053\n",
      "\n",
      " elbo: 1.54730248\n",
      "\n",
      " log_likelihoods reduce: -1.13353419\n",
      "\n",
      " elbo: 1.59817541\n",
      "\n",
      " log_likelihoods reduce: -1.18441176\n",
      "\n",
      " elbo: 1.53971612\n",
      "\n",
      " log_likelihoods reduce: -1.12595713\n",
      "\n",
      " elbo: 1.54798222\n",
      "\n",
      " log_likelihoods reduce: -1.13422775\n",
      "\n",
      " elbo: 1.6244173\n",
      "\n",
      " log_likelihoods reduce: -1.21066761\n",
      "\n",
      " elbo: 1.55241263\n",
      "\n",
      " log_likelihoods reduce: -1.13866758\n",
      "\n",
      " elbo: 1.53733921\n",
      "\n",
      " log_likelihoods reduce: -1.12359881\n",
      "\n",
      " elbo: 1.55146\n",
      "\n",
      " log_likelihoods reduce: -1.13772416\n",
      "\n",
      " elbo: 1.53065586\n",
      "\n",
      " log_likelihoods reduce: -1.11692476\n",
      "\n",
      " elbo: 1.52175903\n",
      "\n",
      " log_likelihoods reduce: -1.10803246\n",
      "\n",
      " elbo: 1.52787054\n",
      "\n",
      " log_likelihoods reduce: -1.11414862\n",
      "\n",
      " elbo: 1.47769785\n",
      "\n",
      " log_likelihoods reduce: -1.06398058\n",
      "\n",
      " elbo: 1.57568669\n",
      "\n",
      " log_likelihoods reduce: -1.16197407\n",
      "\n",
      " elbo: 1.52050281\n",
      "\n",
      " log_likelihoods reduce: -1.10679483\n",
      "\n",
      " elbo: 1.53819406\n",
      "\n",
      " log_likelihoods reduce: -1.12449074\n",
      "\n",
      " elbo: 1.50374866\n",
      "\n",
      " log_likelihoods reduce: -1.09005\n",
      "\n",
      " elbo: 1.54280496\n",
      "\n",
      " log_likelihoods reduce: -1.12911081\n",
      "\n",
      " elbo: 1.54237795\n",
      "\n",
      " log_likelihoods reduce: -1.12868845\n",
      "\n",
      " elbo: 1.58497775\n",
      "\n",
      " log_likelihoods reduce: -1.1712929\n",
      "\n",
      " elbo: 1.50751305\n",
      "\n",
      " log_likelihoods reduce: -1.09383273\n",
      "\n",
      " elbo: 1.57428467\n",
      "\n",
      " log_likelihoods reduce: -1.16060901\n",
      "\n",
      " elbo: 1.48160434\n",
      "\n",
      " log_likelihoods reduce: -1.06793332\n",
      "\n",
      " elbo: 1.54124677\n",
      "\n",
      " log_likelihoods reduce: -1.1275804\n",
      "\n",
      " elbo: 1.50091445\n",
      "\n",
      " log_likelihoods reduce: -1.08725274\n",
      "\n",
      " elbo: 1.55244803\n",
      "\n",
      " log_likelihoods reduce: -1.13879097\n",
      "\n",
      " elbo: 1.56379819\n",
      "\n",
      " log_likelihoods reduce: -1.15014577\n",
      "\n",
      " elbo: 1.5363493\n",
      "\n",
      " log_likelihoods reduce: -1.12270141\n",
      "\n",
      " elbo: 1.54242933\n",
      "\n",
      " log_likelihoods reduce: -1.12878609\n",
      "\n",
      " elbo: 1.55750513\n",
      "\n",
      " log_likelihoods reduce: -1.14386654\n",
      "\n",
      " elbo: 1.56315243\n",
      "\n",
      " log_likelihoods reduce: -1.14951837\n",
      "\n",
      " elbo: 1.5109545\n",
      "\n",
      " log_likelihoods reduce: -1.09732509\n",
      "\n",
      " elbo: 1.55760729\n",
      "\n",
      " log_likelihoods reduce: -1.14398253\n",
      "\n",
      " elbo: 1.53968549\n",
      "\n",
      " log_likelihoods reduce: -1.12606525\n",
      "\n",
      " elbo: 1.4826194\n",
      "\n",
      " log_likelihoods reduce: -1.06900382\n",
      "\n",
      " elbo: 1.55004978\n",
      "\n",
      " log_likelihoods reduce: -1.13643885\n",
      "\n",
      " elbo: 1.55872726\n",
      "\n",
      " log_likelihoods reduce: -1.14512086\n",
      "\n",
      " elbo: 1.48470235\n",
      "\n",
      " log_likelihoods reduce: -1.07110059\n",
      "\n",
      " elbo: 1.49662507\n",
      "\n",
      " log_likelihoods reduce: -1.08302784\n",
      "\n",
      " elbo: 1.54937935\n",
      "\n",
      " log_likelihoods reduce: -1.13578677\n",
      "\n",
      " elbo: 1.54175162\n",
      "\n",
      " log_likelihoods reduce: -1.1281637\n",
      "\n",
      " elbo: 1.52411318\n",
      "\n",
      " log_likelihoods reduce: -1.1105299\n",
      "\n",
      " elbo: 1.53195369\n",
      "\n",
      " log_likelihoods reduce: -1.11837494\n",
      "\n",
      " elbo: 1.52864397\n",
      "\n",
      " log_likelihoods reduce: -1.11506987\n",
      "\n",
      " elbo: 1.52946532\n",
      "\n",
      " log_likelihoods reduce: -1.11589575\n",
      "\n",
      " elbo: 1.55209398\n",
      "\n",
      " log_likelihoods reduce: -1.13852894\n",
      "\n",
      " elbo: 1.56967366\n",
      "\n",
      " log_likelihoods reduce: -1.15611327\n",
      "\n",
      " elbo: 1.53946447\n",
      "\n",
      " log_likelihoods reduce: -1.12590873\n",
      "\n",
      " elbo: 1.48852\n",
      "\n",
      " log_likelihoods reduce: -1.07496881\n",
      "\n",
      " elbo: 1.57060409\n",
      "\n",
      " log_likelihoods reduce: -1.1570574\n",
      "\n",
      " elbo: 1.52874863\n",
      "\n",
      " log_likelihoods reduce: -1.1152066\n",
      "\n",
      " elbo: 1.50704515\n",
      "\n",
      " log_likelihoods reduce: -1.09350765\n",
      "\n",
      " elbo: 1.49653172\n",
      "\n",
      " log_likelihoods reduce: -1.08299887\n",
      "\n",
      " elbo: 1.54148507\n",
      "\n",
      " log_likelihoods reduce: -1.12795675\n",
      "\n",
      " elbo: 1.51903987\n",
      "\n",
      " log_likelihoods reduce: -1.1055162\n",
      "\n",
      " elbo: 1.48878717\n",
      "\n",
      " log_likelihoods reduce: -1.07526803\n",
      "\n",
      " elbo: 1.50526679\n",
      "\n",
      " log_likelihoods reduce: -1.09175229\n",
      "\n",
      " elbo: 1.5277375\n",
      "\n",
      " log_likelihoods reduce: -1.11422753\n",
      "\n",
      " elbo: 1.52019477\n",
      "\n",
      " log_likelihoods reduce: -1.10668945\n",
      "\n",
      " elbo: 1.56027269\n",
      "\n",
      " log_likelihoods reduce: -1.14677191\n",
      "\n",
      " elbo: 1.5561595\n",
      "\n",
      " log_likelihoods reduce: -1.14266324\n",
      "\n",
      " elbo: 1.51910949\n",
      "\n",
      " log_likelihoods reduce: -1.10561776\n",
      "\n",
      " elbo: 1.52701581\n",
      "\n",
      " log_likelihoods reduce: -1.11352873\n",
      "\n",
      " elbo: 1.53811848\n",
      "\n",
      " log_likelihoods reduce: -1.12463593\n",
      "\n",
      " elbo: 1.54802227\n",
      "\n",
      " log_likelihoods reduce: -1.13454437\n",
      "\n",
      " elbo: 1.52833235\n",
      "\n",
      " log_likelihoods reduce: -1.11485898\n",
      "\n",
      " elbo: 1.56221509\n",
      "\n",
      " log_likelihoods reduce: -1.14874625\n",
      "\n",
      " elbo: 1.51923656\n",
      "\n",
      " log_likelihoods reduce: -1.10577226\n",
      "\n",
      " elbo: 1.49422038\n",
      "\n",
      " log_likelihoods reduce: -1.08076072\n",
      "\n",
      " elbo: 1.55645168\n",
      "\n",
      " log_likelihoods reduce: -1.14299655\n",
      "\n",
      " elbo: 1.56251287\n",
      "\n",
      " log_likelihoods reduce: -1.1490624\n",
      "\n",
      " elbo: 1.51886892\n",
      "\n",
      " log_likelihoods reduce: -1.10542297\n",
      "\n",
      " elbo: 1.48554385\n",
      "\n",
      " log_likelihoods reduce: -1.07210243\n",
      "\n",
      " elbo: 1.57197595\n",
      "\n",
      " log_likelihoods reduce: -1.15853906\n",
      "\n",
      " elbo: 1.51772094\n",
      "\n",
      " log_likelihoods reduce: -1.10428858\n",
      "\n",
      " elbo: 1.52496243\n",
      "\n",
      " log_likelihoods reduce: -1.11153471\n",
      "\n",
      " elbo: 1.50015318\n",
      "\n",
      " log_likelihoods reduce: -1.08673\n",
      "\n",
      " elbo: 1.55948758\n",
      "\n",
      " log_likelihoods reduce: -1.14606893\n",
      "\n",
      " elbo: 1.58109057\n",
      "\n",
      " log_likelihoods reduce: -1.16767645\n",
      "\n",
      " elbo: 1.54301572\n",
      "\n",
      " log_likelihoods reduce: -1.12960625\n",
      "\n",
      " elbo: 1.48879671\n",
      "\n",
      " log_likelihoods reduce: -1.07539177\n",
      "\n",
      " elbo: 1.49145174\n",
      "\n",
      " log_likelihoods reduce: -1.07805133\n",
      "\n",
      " elbo: 1.56051397\n",
      "\n",
      " log_likelihoods reduce: -1.14711809\n",
      "\n",
      " elbo: 1.49638867\n",
      "\n",
      " log_likelihoods reduce: -1.08299732\n",
      "\n",
      " elbo: 1.58200157\n",
      "\n",
      " log_likelihoods reduce: -1.16861475\n",
      "\n",
      " elbo: 1.46966267\n",
      "\n",
      " log_likelihoods reduce: -1.05628037\n",
      "\n",
      " elbo: 1.50328374\n",
      "\n",
      " log_likelihoods reduce: -1.08990598\n",
      "\n",
      " elbo: 1.49788332\n",
      "\n",
      " log_likelihoods reduce: -1.08451009\n",
      "\n",
      " elbo: 1.52528381\n",
      "\n",
      " log_likelihoods reduce: -1.11191511\n",
      "\n",
      " elbo: 1.51448572\n",
      "\n",
      " log_likelihoods reduce: -1.10112154\n",
      "\n",
      " elbo: 1.5446806\n",
      "\n",
      " log_likelihoods reduce: -1.13132095\n",
      "\n",
      " elbo: 1.5659678\n",
      "\n",
      " log_likelihoods reduce: -1.15261281\n",
      "\n",
      " elbo: 1.52006388\n",
      "\n",
      " log_likelihoods reduce: -1.10671329\n",
      "\n",
      " elbo: 1.52066445\n",
      "\n",
      " log_likelihoods reduce: -1.10731852\n",
      "\n",
      " elbo: 1.51977205\n",
      "\n",
      " log_likelihoods reduce: -1.10643053\n",
      "\n",
      " elbo: 1.51734436\n",
      "\n",
      " log_likelihoods reduce: -1.10400748\n",
      "\n",
      " elbo: 1.50415766\n",
      "\n",
      " log_likelihoods reduce: -1.0908252\n",
      "\n",
      " elbo: 1.51163363\n",
      "\n",
      " log_likelihoods reduce: -1.0983057\n",
      "\n",
      " elbo: 1.48942757\n",
      "\n",
      " log_likelihoods reduce: -1.07610428\n",
      "\n",
      " elbo: 1.53605437\n",
      "\n",
      " log_likelihoods reduce: -1.1227355\n",
      "\n",
      " elbo: 1.56747162\n",
      "\n",
      " log_likelihoods reduce: -1.15415728\n",
      "\n",
      " elbo: 1.52076721\n",
      "\n",
      " log_likelihoods reduce: -1.1074574\n",
      "\n",
      " elbo: 1.50744581\n",
      "\n",
      " log_likelihoods reduce: -1.09414053\n",
      "\n",
      " elbo: 1.50714493\n",
      "\n",
      " log_likelihoods reduce: -1.09384418\n",
      "\n",
      " elbo: 1.55965638\n",
      "\n",
      " log_likelihoods reduce: -1.14636016\n",
      "\n",
      " elbo: 1.52803922\n",
      "\n",
      " log_likelihoods reduce: -1.11474741\n",
      "\n",
      " elbo: 1.46663141\n",
      "\n",
      " log_likelihoods reduce: -1.05334425\n",
      "\n",
      " elbo: 1.52165329\n",
      "\n",
      " log_likelihoods reduce: -1.10837054\n",
      "\n",
      " elbo: 1.51094186\n",
      "\n",
      " log_likelihoods reduce: -1.09766364\n",
      "\n",
      " elbo: 1.484308\n",
      "\n",
      " log_likelihoods reduce: -1.07103443\n",
      "\n",
      " elbo: 1.54517388\n",
      "\n",
      " log_likelihoods reduce: -1.13190472\n",
      "\n",
      " elbo: 1.51829481\n",
      "\n",
      " log_likelihoods reduce: -1.10503018\n",
      "\n",
      " elbo: 1.56288624\n",
      "\n",
      " log_likelihoods reduce: -1.14962614\n",
      "\n",
      " elbo: 1.56628859\n",
      "\n",
      " log_likelihoods reduce: -1.15303302\n",
      "\n",
      " elbo: 1.49890649\n",
      "\n",
      " log_likelihoods reduce: -1.08565545\n",
      "\n",
      " elbo: 1.52051854\n",
      "\n",
      " log_likelihoods reduce: -1.10727203\n",
      "\n",
      " elbo: 1.5338707\n",
      "\n",
      " log_likelihoods reduce: -1.1206286\n",
      "\n",
      " elbo: 1.55060065\n",
      "\n",
      " log_likelihoods reduce: -1.13736308\n",
      "\n",
      " elbo: 1.49696803\n",
      "\n",
      " log_likelihoods reduce: -1.08373487\n",
      "\n",
      " elbo: 1.51706171\n",
      "\n",
      " log_likelihoods reduce: -1.10383308\n",
      "\n",
      " elbo: 1.53082716\n",
      "\n",
      " log_likelihoods reduce: -1.11760306\n",
      "\n",
      " elbo: 1.56239724\n",
      "\n",
      " log_likelihoods reduce: -1.14917767\n",
      "\n",
      " elbo: 1.5382421\n",
      "\n",
      " log_likelihoods reduce: -1.12502706\n",
      "\n",
      " elbo: 1.50934076\n",
      "\n",
      " log_likelihoods reduce: -1.09613025\n",
      "\n",
      " elbo: 1.51504493\n",
      "\n",
      " log_likelihoods reduce: -1.10183895\n",
      "\n",
      " elbo: 1.51697659\n",
      "\n",
      " log_likelihoods reduce: -1.10377502\n",
      "\n",
      " elbo: 1.4991411\n",
      "\n",
      " log_likelihoods reduce: -1.08594406\n",
      "\n",
      " elbo: 1.51240218\n",
      "\n",
      " log_likelihoods reduce: -1.09920967\n",
      "\n",
      " elbo: 1.59846103\n",
      "\n",
      " log_likelihoods reduce: -1.18527293\n",
      "\n",
      " elbo: 1.50787532\n",
      "\n",
      " log_likelihoods reduce: -1.09469175\n",
      "\n",
      " elbo: 1.50127268\n",
      "\n",
      " log_likelihoods reduce: -1.08809352\n",
      "\n",
      " elbo: 1.46758676\n",
      "\n",
      " log_likelihoods reduce: -1.05441213\n",
      "\n",
      " elbo: 1.52384591\n",
      "\n",
      " log_likelihoods reduce: -1.11067581\n",
      "\n",
      " elbo: 1.54456437\n",
      "\n",
      " log_likelihoods reduce: -1.13139868\n",
      "\n",
      " elbo: 1.493927\n",
      "\n",
      " log_likelihoods reduce: -1.08076584\n",
      "\n",
      " elbo: 1.50849116\n",
      "\n",
      " log_likelihoods reduce: -1.09533453\n",
      "\n",
      " elbo: 1.4915669\n",
      "\n",
      " log_likelihoods reduce: -1.07841468\n",
      "\n",
      " elbo: 1.52890348\n",
      "\n",
      " log_likelihoods reduce: -1.1157558\n",
      "\n",
      " elbo: 1.52214599\n",
      "\n",
      " log_likelihoods reduce: -1.10900271\n",
      "\n",
      " elbo: 1.55541325\n",
      "\n",
      " log_likelihoods reduce: -1.1422745\n",
      "\n",
      " elbo: 1.48537731\n",
      "\n",
      " log_likelihoods reduce: -1.07224309\n",
      "\n",
      " elbo: 1.53522205\n",
      "\n",
      " log_likelihoods reduce: -1.12209225\n",
      "\n",
      " elbo: 1.52951479\n",
      "\n",
      " log_likelihoods reduce: -1.11638951\n",
      "\n",
      " elbo: 1.47374749\n",
      "\n",
      " log_likelihoods reduce: -1.06062675\n",
      "\n",
      " elbo: 1.57440674\n",
      "\n",
      " log_likelihoods reduce: -1.16129041\n",
      "\n",
      " elbo: 1.50497758\n",
      "\n",
      " log_likelihoods reduce: -1.09186578\n",
      "\n",
      " elbo: 1.50652075\n",
      "\n",
      " log_likelihoods reduce: -1.09341335\n",
      "\n",
      " elbo: 1.50535131\n",
      "\n",
      " log_likelihoods reduce: -1.09224844\n",
      "\n",
      " elbo: 1.54812407\n",
      "\n",
      " log_likelihoods reduce: -1.13502562\n",
      "\n",
      " elbo: 1.5277828\n",
      "\n",
      " log_likelihoods reduce: -1.11468887\n",
      "\n",
      " elbo: 1.5633173\n",
      "\n",
      " log_likelihoods reduce: -1.15022779\n",
      "\n",
      " elbo: 1.51508403\n",
      "\n",
      " log_likelihoods reduce: -1.10199904\n",
      "\n",
      " elbo: 1.51419353\n",
      "\n",
      " log_likelihoods reduce: -1.10111296\n",
      "\n",
      " elbo: 1.52146471\n",
      "\n",
      " log_likelihoods reduce: -1.10838866\n",
      "\n",
      " elbo: 1.49097252\n",
      "\n",
      " log_likelihoods reduce: -1.07790089\n",
      "\n",
      " elbo: 1.49428916\n",
      "\n",
      " log_likelihoods reduce: -1.08122206\n",
      "\n",
      " elbo: 1.53278768\n",
      "\n",
      " log_likelihoods reduce: -1.11972499\n",
      "\n",
      " elbo: 1.49895811\n",
      "\n",
      " log_likelihoods reduce: -1.08589983\n",
      "\n",
      " elbo: 1.50398707\n",
      "\n",
      " log_likelihoods reduce: -1.09093332\n",
      "\n",
      " elbo: 1.53977692\n",
      "\n",
      " log_likelihoods reduce: -1.12672758\n",
      "\n",
      " elbo: 1.50775313\n",
      "\n",
      " log_likelihoods reduce: -1.09470832\n",
      "\n",
      " elbo: 1.53115463\n",
      "\n",
      " log_likelihoods reduce: -1.11811423\n",
      "\n",
      " elbo: 1.51425838\n",
      "\n",
      " log_likelihoods reduce: -1.10122252\n",
      "\n",
      " elbo: 1.48952281\n",
      "\n",
      " log_likelihoods reduce: -1.07649136\n",
      "\n",
      " elbo: 1.50419462\n",
      "\n",
      " log_likelihoods reduce: -1.09116757\n",
      "\n",
      " elbo: 1.53067505\n",
      "\n",
      " log_likelihoods reduce: -1.11765254\n",
      "\n",
      " elbo: 1.51278698\n",
      "\n",
      " log_likelihoods reduce: -1.09976888\n",
      "\n",
      " elbo: 1.51608253\n",
      "\n",
      " log_likelihoods reduce: -1.10306883\n",
      "\n",
      " elbo: 1.52708018\n",
      "\n",
      " log_likelihoods reduce: -1.11407101\n",
      "\n",
      " elbo: 1.51478529\n",
      "\n",
      " log_likelihoods reduce: -1.10178053\n",
      "\n",
      " elbo: 1.50877023\n",
      "\n",
      " log_likelihoods reduce: -1.09576988\n",
      "\n",
      " elbo: 1.54459667\n",
      "\n",
      " log_likelihoods reduce: -1.13160086\n",
      "\n",
      " elbo: 1.47195458\n",
      "\n",
      " log_likelihoods reduce: -1.05896318\n",
      "\n",
      " elbo: 1.52056837\n",
      "\n",
      " log_likelihoods reduce: -1.10758138\n",
      "\n",
      " elbo: 1.49831724\n",
      "\n",
      " log_likelihoods reduce: -1.08533478\n",
      "\n",
      " elbo: 1.51215267\n",
      "\n",
      " log_likelihoods reduce: -1.09917462\n",
      "\n",
      " elbo: 1.4921658\n",
      "\n",
      " log_likelihoods reduce: -1.07919216\n",
      "\n",
      " elbo: 1.48379707\n",
      "\n",
      " log_likelihoods reduce: -1.07082796\n",
      "\n",
      " elbo: 1.53044224\n",
      "\n",
      " log_likelihoods reduce: -1.11747754\n",
      "\n",
      " elbo: 1.46854126\n",
      "\n",
      " log_likelihoods reduce: -1.05558109\n",
      "\n",
      " elbo: 1.47931647\n",
      "\n",
      " log_likelihoods reduce: -1.06636059\n",
      "\n",
      " elbo: 1.50720239\n",
      "\n",
      " log_likelihoods reduce: -1.09425092\n",
      "\n",
      " elbo: 1.51216698\n",
      "\n",
      " log_likelihoods reduce: -1.09922\n",
      "\n",
      " elbo: 1.49578345\n",
      "\n",
      " log_likelihoods reduce: -1.08284092\n",
      "\n",
      " elbo: 1.51103723\n",
      "\n",
      " log_likelihoods reduce: -1.09809911\n",
      "\n",
      " elbo: 1.49955106\n",
      "\n",
      " log_likelihoods reduce: -1.08661735\n",
      "\n",
      " elbo: 1.50124288\n",
      "\n",
      " log_likelihoods reduce: -1.08831358\n",
      "\n",
      " elbo: 1.50550044\n",
      "\n",
      " log_likelihoods reduce: -1.09257555\n",
      "\n",
      " elbo: 1.52518415\n",
      "\n",
      " log_likelihoods reduce: -1.11226368\n",
      "\n",
      " elbo: 1.46688747\n",
      "\n",
      " log_likelihoods reduce: -1.05397153\n",
      "\n",
      " elbo: 1.45515871\n",
      "\n",
      " log_likelihoods reduce: -1.04224718\n",
      "\n",
      " elbo: 1.50458169\n",
      "\n",
      " log_likelihoods reduce: -1.09167457\n",
      "\n",
      " elbo: 1.52679801\n",
      "\n",
      " log_likelihoods reduce: -1.11389518\n",
      "\n",
      " elbo: 1.54643643\n",
      "\n",
      " log_likelihoods reduce: -1.13353813\n",
      "\n",
      " elbo: 1.51109242\n",
      "\n",
      " log_likelihoods reduce: -1.09819853\n",
      "\n",
      " elbo: 1.51096487\n",
      "\n",
      " log_likelihoods reduce: -1.09807539\n",
      "\n",
      " elbo: 1.49713433\n",
      "\n",
      " log_likelihoods reduce: -1.08424926\n",
      "\n",
      " elbo: 1.52110457\n",
      "\n",
      " log_likelihoods reduce: -1.10822392\n",
      "\n",
      " elbo: 1.4643302\n",
      "\n",
      " log_likelihoods reduce: -1.05145395\n",
      "\n",
      " elbo: 1.49852204\n",
      "\n",
      " log_likelihoods reduce: -1.08565021\n",
      "\n",
      " elbo: 1.50017047\n",
      "\n",
      " log_likelihoods reduce: -1.08730304\n",
      "\n",
      " elbo: 1.524948\n",
      "\n",
      " log_likelihoods reduce: -1.11208498\n",
      "\n",
      " elbo: 1.52039993\n",
      "\n",
      " log_likelihoods reduce: -1.10754132\n",
      "\n",
      " elbo: 1.47182691\n",
      "\n",
      " log_likelihoods reduce: -1.05897272\n",
      "\n",
      " elbo: 1.48350179\n",
      "\n",
      " log_likelihoods reduce: -1.07065201\n",
      "\n",
      " elbo: 1.51016164\n",
      "\n",
      " log_likelihoods reduce: -1.09731627\n",
      "\n",
      " elbo: 1.48772871\n",
      "\n",
      " log_likelihoods reduce: -1.07488775\n",
      "\n",
      " elbo: 1.52089405\n",
      "\n",
      " log_likelihoods reduce: -1.1080575\n",
      "\n",
      " elbo: 1.52378404\n",
      "\n",
      " log_likelihoods reduce: -1.1109519\n",
      "\n",
      " elbo: 1.53627551\n",
      "\n",
      " log_likelihoods reduce: -1.12344778\n",
      "\n",
      " elbo: 1.49921572\n",
      "\n",
      " log_likelihoods reduce: -1.0863924\n",
      "\n",
      " elbo: 1.4926548\n",
      "\n",
      " log_likelihoods reduce: -1.07983589\n",
      "\n",
      " elbo: 1.51041877\n",
      "\n",
      " log_likelihoods reduce: -1.09760427\n",
      "\n",
      " elbo: 1.48893511\n",
      "\n",
      " log_likelihoods reduce: -1.07612503\n",
      "\n",
      " elbo: 1.47152019\n",
      "\n",
      " log_likelihoods reduce: -1.05871451\n",
      "\n",
      " elbo: 1.4514991\n",
      "\n",
      " log_likelihoods reduce: -1.03869784\n",
      "\n",
      " elbo: 1.52086031\n",
      "\n",
      " log_likelihoods reduce: -1.10806346\n",
      "\n",
      " elbo: 1.51062369\n",
      "\n",
      " log_likelihoods reduce: -1.09783125\n",
      "\n",
      " elbo: 1.44133615\n",
      "\n",
      " log_likelihoods reduce: -1.02854812\n",
      "\n",
      " elbo: 1.49355626\n",
      "\n",
      " log_likelihoods reduce: -1.08077264\n",
      "\n",
      " elbo: 1.51547086\n",
      "\n",
      " log_likelihoods reduce: -1.10269165\n",
      "\n",
      " elbo: 1.49967551\n",
      "\n",
      " log_likelihoods reduce: -1.08690071\n",
      "\n",
      " elbo: 1.4953506\n",
      "\n",
      " log_likelihoods reduce: -1.08258021\n",
      "\n",
      " elbo: 1.52072549\n",
      "\n",
      " log_likelihoods reduce: -1.10795939\n",
      "\n",
      " elbo: 1.50292408\n",
      "\n",
      " log_likelihoods reduce: -1.0901624\n",
      "\n",
      " elbo: 1.48961079\n",
      "\n",
      " log_likelihoods reduce: -1.07685351\n",
      "\n",
      " elbo: 1.46199739\n",
      "\n",
      " log_likelihoods reduce: -1.0492444\n",
      "\n",
      " elbo: 1.53445864\n",
      "\n",
      " log_likelihoods reduce: -1.12171006\n",
      "\n",
      " elbo: 1.50191724\n",
      "\n",
      " log_likelihoods reduce: -1.08917308\n",
      "\n",
      " elbo: 1.51552927\n",
      "\n",
      " log_likelihoods reduce: -1.10278952\n",
      "\n",
      " elbo: 1.50521553\n",
      "\n",
      " log_likelihoods reduce: -1.09248018\n",
      "\n",
      " elbo: 1.47126913\n",
      "\n",
      " log_likelihoods reduce: -1.0585382\n",
      "\n",
      " elbo: 1.47495127\n",
      "\n",
      " log_likelihoods reduce: -1.06222463\n",
      "\n",
      " elbo: 1.52819979\n",
      "\n",
      " log_likelihoods reduce: -1.11547756\n",
      "\n",
      " elbo: 1.53257525\n",
      "\n",
      " log_likelihoods reduce: -1.11985743\n",
      "\n",
      " elbo: 1.47262216\n",
      "\n",
      " log_likelihoods reduce: -1.05990863\n",
      "\n",
      " elbo: 1.44998312\n",
      "\n",
      " log_likelihoods reduce: -1.03727412\n",
      "\n",
      " elbo: 1.50735164\n",
      "\n",
      " log_likelihoods reduce: -1.09464693\n",
      "\n",
      " elbo: 1.45462751\n",
      "\n",
      " log_likelihoods reduce: -1.04192734\n",
      "\n",
      " elbo: 1.54689145\n",
      "\n",
      " log_likelihoods reduce: -1.13419557\n",
      "\n",
      " elbo: 1.47956026\n",
      "\n",
      " log_likelihoods reduce: -1.06686878\n",
      "\n",
      " elbo: 1.50827551\n",
      "\n",
      " log_likelihoods reduce: -1.09558833\n",
      "\n",
      " elbo: 1.50362349\n",
      "\n",
      " log_likelihoods reduce: -1.09094071\n",
      "\n",
      " elbo: 1.53113365\n",
      "\n",
      " log_likelihoods reduce: -1.11845529\n",
      "\n",
      " elbo: 1.44433451\n",
      "\n",
      " log_likelihoods reduce: -1.03166056\n",
      "\n",
      " elbo: 1.53005385\n",
      "\n",
      " log_likelihoods reduce: -1.1173842\n",
      "\n",
      " elbo: 1.46825469\n",
      "\n",
      " log_likelihoods reduce: -1.05558944\n",
      "\n",
      " elbo: 1.52242923\n",
      "\n",
      " log_likelihoods reduce: -1.10976839\n",
      "\n",
      " elbo: 1.48404515\n",
      "\n",
      " log_likelihoods reduce: -1.07138872\n",
      "\n",
      " elbo: 1.46840262\n",
      "\n",
      " log_likelihoods reduce: -1.05575061\n",
      "\n",
      " elbo: 1.54415965\n",
      "\n",
      " log_likelihoods reduce: -1.13151193\n",
      "\n",
      " elbo: 1.5092169\n",
      "\n",
      " log_likelihoods reduce: -1.09657359\n",
      "\n",
      " elbo: 1.54338503\n",
      "\n",
      " log_likelihoods reduce: -1.13074601\n",
      "\n",
      " elbo: 1.50254607\n",
      "\n",
      " log_likelihoods reduce: -1.08991146\n",
      "\n",
      " elbo: 1.51814234\n",
      "\n",
      " log_likelihoods reduce: -1.10551214\n",
      "\n",
      " elbo: 1.47745538\n",
      "\n",
      " log_likelihoods reduce: -1.06482959\n",
      "\n",
      " elbo: 1.49984765\n",
      "\n",
      " log_likelihoods reduce: -1.08722615\n",
      "\n",
      " elbo: 1.49472952\n",
      "\n",
      " log_likelihoods reduce: -1.08211231\n",
      "\n",
      " elbo: 1.45928466\n",
      "\n",
      " log_likelihoods reduce: -1.04667187\n",
      "\n",
      " elbo: 1.51555586\n",
      "\n",
      " log_likelihoods reduce: -1.10294747\n",
      "\n",
      " elbo: 1.52408266\n",
      "\n",
      " log_likelihoods reduce: -1.11147869\n",
      "\n",
      " elbo: 1.51805675\n",
      "\n",
      " log_likelihoods reduce: -1.10545707\n",
      "\n",
      " elbo: 1.50330484\n",
      "\n",
      " log_likelihoods reduce: -1.09070957\n",
      "\n",
      " elbo: 1.50056279\n",
      "\n",
      " log_likelihoods reduce: -1.08797181\n",
      "\n",
      " elbo: 1.49288642\n",
      "\n",
      " log_likelihoods reduce: -1.08029985\n",
      "\n",
      " elbo: 1.48979247\n",
      "\n",
      " log_likelihoods reduce: -1.07721019\n",
      "\n",
      " elbo: 1.46477616\n",
      "\n",
      " log_likelihoods reduce: -1.05219829\n",
      "\n",
      " elbo: 1.486377\n",
      "\n",
      " log_likelihoods reduce: -1.07380342\n",
      "\n",
      " elbo: 1.50527549\n",
      "\n",
      " log_likelihoods reduce: -1.09270632\n",
      "\n",
      " elbo: 1.55146325\n",
      "\n",
      " log_likelihoods reduce: -1.13889837\n",
      "\n",
      " elbo: 1.51230264\n",
      "\n",
      " log_likelihoods reduce: -1.09974217\n",
      "\n",
      " elbo: 1.49430108\n",
      "\n",
      " log_likelihoods reduce: -1.08174491\n",
      "\n",
      " elbo: 1.48600841\n",
      "\n",
      " log_likelihoods reduce: -1.07345653\n",
      "\n",
      " elbo: 1.45880497\n",
      "\n",
      " log_likelihoods reduce: -1.0462575\n",
      "\n",
      " elbo: 1.48237169\n",
      "\n",
      " log_likelihoods reduce: -1.06982863\n",
      "\n",
      " elbo: 1.43433714\n",
      "\n",
      " log_likelihoods reduce: -1.02179837\n",
      "\n",
      " elbo: 1.50515366\n",
      "\n",
      " log_likelihoods reduce: -1.09261918\n",
      "\n",
      " elbo: 1.50427008\n",
      "\n",
      " log_likelihoods reduce: -1.09173989\n",
      "\n",
      " elbo: 1.47068071\n",
      "\n",
      " log_likelihoods reduce: -1.05815494\n",
      "\n",
      " elbo: 1.49137115\n",
      "\n",
      " log_likelihoods reduce: -1.07884979\n",
      "\n",
      " elbo: 1.46299362\n",
      "\n",
      " log_likelihoods reduce: -1.05047655\n",
      "\n",
      " elbo: 1.49877691\n",
      "\n",
      " log_likelihoods reduce: -1.08626413\n",
      "\n",
      " elbo: 1.46754801\n",
      "\n",
      " log_likelihoods reduce: -1.05503964\n",
      "\n",
      " elbo: 1.47751296\n",
      "\n",
      " log_likelihoods reduce: -1.06500888\n",
      "\n",
      " elbo: 1.45058727\n",
      "\n",
      " log_likelihoods reduce: -1.03808761\n",
      "\n",
      " elbo: 1.47144568\n",
      "\n",
      " log_likelihoods reduce: -1.0589503\n",
      "\n",
      " elbo: 1.51880884\n",
      "\n",
      " log_likelihoods reduce: -1.10631776\n",
      "\n",
      " elbo: 1.50026488\n",
      "\n",
      " log_likelihoods reduce: -1.08777809\n",
      "\n",
      " elbo: 1.48292446\n",
      "\n",
      " log_likelihoods reduce: -1.07044196\n",
      "\n",
      " elbo: 1.48860037\n",
      "\n",
      " log_likelihoods reduce: -1.07612228\n",
      "\n",
      " elbo: 1.44142318\n",
      "\n",
      " log_likelihoods reduce: -1.02894938\n",
      "\n",
      " elbo: 1.46883154\n",
      "\n",
      " log_likelihoods reduce: -1.05636215\n",
      "\n",
      " elbo: 1.43010414\n",
      "\n",
      " log_likelihoods reduce: -1.01763904\n",
      "\n",
      " elbo: 1.5148201\n",
      "\n",
      " log_likelihoods reduce: -1.10235929\n",
      "\n",
      " elbo: 1.51205862\n",
      "\n",
      " log_likelihoods reduce: -1.09960222\n",
      "\n",
      " elbo: 1.46585608\n",
      "\n",
      " log_likelihoods reduce: -1.05340397\n",
      "\n",
      " elbo: 1.46821678\n",
      "\n",
      " log_likelihoods reduce: -1.05576897\n",
      "\n",
      " elbo: 1.48442876\n",
      "\n",
      " log_likelihoods reduce: -1.07198524\n",
      "\n",
      " elbo: 1.49720311\n",
      "\n",
      " log_likelihoods reduce: -1.084764\n",
      "\n",
      " elbo: 1.50253475\n",
      "\n",
      " log_likelihoods reduce: -1.09009993\n",
      "\n",
      " elbo: 1.51386011\n",
      "\n",
      " log_likelihoods reduce: -1.10142958\n",
      "\n",
      " elbo: 1.45919955\n",
      "\n",
      " log_likelihoods reduce: -1.04677331\n",
      "\n",
      " elbo: 1.48490739\n",
      "\n",
      " log_likelihoods reduce: -1.07248545\n",
      "\n",
      " elbo: 1.48485875\n",
      "\n",
      " log_likelihoods reduce: -1.07244122\n",
      "\n",
      " elbo: 1.51797557\n",
      "\n",
      " log_likelihoods reduce: -1.10556245\n",
      "\n",
      " elbo: 1.45821118\n",
      "\n",
      " log_likelihoods reduce: -1.04580224\n",
      "\n",
      " elbo: 1.51700294\n",
      "\n",
      " log_likelihoods reduce: -1.1045984\n",
      "\n",
      " elbo: 1.47598147\n",
      "\n",
      " log_likelihoods reduce: -1.06358123\n",
      "\n",
      " elbo: 1.45435143\n",
      "\n",
      " log_likelihoods reduce: -1.04195547\n",
      "\n",
      " elbo: 1.49643898\n",
      "\n",
      " log_likelihoods reduce: -1.08404732\n",
      "\n",
      " elbo: 1.4620347\n",
      "\n",
      " log_likelihoods reduce: -1.04964733\n",
      "\n",
      " elbo: 1.47459\n",
      "\n",
      " log_likelihoods reduce: -1.06220698\n",
      "\n",
      " elbo: 1.52258933\n",
      "\n",
      " log_likelihoods reduce: -1.11021066\n",
      "\n",
      " elbo: 1.50477171\n",
      "\n",
      " log_likelihoods reduce: -1.09239733\n",
      "\n",
      " elbo: 1.49011362\n",
      "\n",
      " log_likelihoods reduce: -1.07774353\n",
      "\n",
      " elbo: 1.44955683\n",
      "\n",
      " log_likelihoods reduce: -1.03719103\n",
      "\n",
      " elbo: 1.43481946\n",
      "\n",
      " log_likelihoods reduce: -1.02245796\n",
      "\n",
      " elbo: 1.46022296\n",
      "\n",
      " log_likelihoods reduce: -1.04786575\n",
      "\n",
      " elbo: 1.41969252\n",
      "\n",
      " log_likelihoods reduce: -1.0073396\n",
      "\n",
      " elbo: 1.43050563\n",
      "\n",
      " log_likelihoods reduce: -1.01815701\n",
      "\n",
      " elbo: 1.53071642\n",
      "\n",
      " log_likelihoods reduce: -1.11837208\n",
      "\n",
      " elbo: 1.47738731\n",
      "\n",
      " log_likelihoods reduce: -1.06504726\n",
      "\n",
      " elbo: 1.47871566\n",
      "\n",
      " log_likelihoods reduce: -1.06638\n",
      "\n",
      " elbo: 1.46760559\n",
      "\n",
      " log_likelihoods reduce: -1.05527413\n",
      "\n",
      " elbo: 1.44823241\n",
      "\n",
      " log_likelihoods reduce: -1.03590524\n",
      "\n",
      " elbo: 1.56429887\n",
      "\n",
      " log_likelihoods reduce: -1.15197611\n",
      "\n",
      " elbo: 1.4039824\n",
      "\n",
      " log_likelihoods reduce: -0.991663933\n",
      "\n",
      " elbo: 1.42667794\n",
      "\n",
      " log_likelihoods reduce: -1.01436377\n",
      "\n",
      " elbo: 1.49123883\n",
      "\n",
      " log_likelihoods reduce: -1.07892883\n",
      "\n",
      " elbo: 1.46848035\n",
      "\n",
      " log_likelihoods reduce: -1.05617464\n",
      "\n",
      " elbo: 1.47629964\n",
      "\n",
      " log_likelihoods reduce: -1.06399822\n",
      "\n",
      " elbo: 1.48710716\n",
      "\n",
      " log_likelihoods reduce: -1.07481\n",
      "\n",
      " elbo: 1.49012887\n",
      "\n",
      " log_likelihoods reduce: -1.07783604\n",
      "\n",
      " elbo: 1.45801687\n",
      "\n",
      " log_likelihoods reduce: -1.04572833\n",
      "\n",
      " elbo: 1.48908007\n",
      "\n",
      " log_likelihoods reduce: -1.07679582\n",
      "\n",
      " elbo: 1.46389186\n",
      "\n",
      " log_likelihoods reduce: -1.0516119\n",
      "\n",
      " elbo: 1.4808054\n",
      "\n",
      " log_likelihoods reduce: -1.06852961\n",
      "\n",
      " elbo: 1.47313666\n",
      "\n",
      " log_likelihoods reduce: -1.06086528\n",
      "\n",
      " elbo: 1.48828256\n",
      "\n",
      " log_likelihoods reduce: -1.07601547\n",
      "\n",
      " elbo: 1.48811793\n",
      "\n",
      " log_likelihoods reduce: -1.07585502\n",
      "\n",
      " elbo: 1.40513921\n",
      "\n",
      " log_likelihoods reduce: -0.992880583\n",
      "\n",
      " elbo: 1.47211385\n",
      "\n",
      " log_likelihoods reduce: -1.05985963\n",
      "\n",
      " elbo: 1.44307351\n",
      "\n",
      " log_likelihoods reduce: -1.03082347\n",
      "\n",
      " elbo: 1.48736799\n",
      "\n",
      " log_likelihoods reduce: -1.07512224\n",
      "\n",
      " elbo: 1.45257306\n",
      "\n",
      " log_likelihoods reduce: -1.0403316\n",
      "\n",
      " elbo: 1.4490695\n",
      "\n",
      " log_likelihoods reduce: -1.03683233\n",
      "\n",
      " elbo: 1.46860874\n",
      "\n",
      " log_likelihoods reduce: -1.05637586\n",
      "\n",
      " elbo: 1.48308575\n",
      "\n",
      " log_likelihoods reduce: -1.07085705\n",
      "\n",
      " elbo: 1.51994669\n",
      "\n",
      " log_likelihoods reduce: -1.10772228\n",
      "\n",
      " elbo: 1.49446237\n",
      "\n",
      " log_likelihoods reduce: -1.08224225\n",
      "\n",
      " elbo: 1.48492253\n",
      "\n",
      " log_likelihoods reduce: -1.0727067\n",
      "\n",
      " elbo: 1.45626056\n",
      "\n",
      " log_likelihoods reduce: -1.04404891\n",
      "\n",
      " elbo: 1.50204873\n",
      "\n",
      " log_likelihoods reduce: -1.08984137\n",
      "\n",
      " elbo: 1.49452829\n",
      "\n",
      " log_likelihoods reduce: -1.08232522\n",
      "\n",
      " elbo: 1.45513427\n",
      "\n",
      " log_likelihoods reduce: -1.04293549\n",
      "\n",
      " elbo: 1.49223113\n",
      "\n",
      " log_likelihoods reduce: -1.08003664\n",
      "\n",
      " elbo: 1.48646104\n",
      "\n",
      " log_likelihoods reduce: -1.07427073\n",
      "\n",
      " elbo: 1.46812451\n",
      "\n",
      " log_likelihoods reduce: -1.05593848\n",
      "\n",
      " elbo: 1.43760419\n",
      "\n",
      " log_likelihoods reduce: -1.02542233\n",
      "\n",
      " elbo: 1.45321727\n",
      "\n",
      " log_likelihoods reduce: -1.04103971\n",
      "\n",
      " elbo: 1.51740313\n",
      "\n",
      " log_likelihoods reduce: -1.10522985\n",
      "\n",
      " elbo: 1.45960605\n",
      "\n",
      " log_likelihoods reduce: -1.04743695\n",
      "\n",
      " elbo: 1.47474313\n",
      "\n",
      " log_likelihoods reduce: -1.0625782\n",
      "\n",
      " elbo: 1.48605859\n",
      "\n",
      " log_likelihoods reduce: -1.07389796\n",
      "\n",
      " elbo: 1.47878575\n",
      "\n",
      " log_likelihoods reduce: -1.06662941\n",
      "\n",
      " elbo: 1.48335445\n",
      "\n",
      " log_likelihoods reduce: -1.07120228\n",
      "\n",
      " elbo: 1.48821819\n",
      "\n",
      " log_likelihoods reduce: -1.07607031\n",
      "\n",
      " elbo: 1.45166683\n",
      "\n",
      " log_likelihoods reduce: -1.03952312\n",
      "\n",
      " elbo: 1.4855895\n",
      "\n",
      " log_likelihoods reduce: -1.07345009\n",
      "\n",
      " elbo: 1.46398008\n",
      "\n",
      " log_likelihoods reduce: -1.05184484\n",
      "\n",
      " elbo: 1.4475621\n",
      "\n",
      " log_likelihoods reduce: -1.03543115\n",
      "\n",
      " elbo: 1.46559405\n",
      "\n",
      " log_likelihoods reduce: -1.05346727\n",
      "\n",
      " elbo: 1.46024728\n",
      "\n",
      " log_likelihoods reduce: -1.04812467\n",
      "\n",
      " elbo: 1.42030096\n",
      "\n",
      " log_likelihoods reduce: -1.00818264\n",
      "\n",
      " elbo: 1.44644547\n",
      "\n",
      " log_likelihoods reduce: -1.03433144\n",
      "\n",
      " elbo: 1.4635433\n",
      "\n",
      " log_likelihoods reduce: -1.05143344\n",
      "\n",
      " elbo: 1.45994687\n",
      "\n",
      " log_likelihoods reduce: -1.04784131\n",
      "\n",
      " elbo: 1.51138818\n",
      "\n",
      " log_likelihoods reduce: -1.09928679\n",
      "\n",
      " elbo: 1.44593096\n",
      "\n",
      " log_likelihoods reduce: -1.03383374\n",
      "\n",
      " elbo: 1.48295689\n",
      "\n",
      " log_likelihoods reduce: -1.07086396\n",
      "\n",
      " elbo: 1.51021838\n",
      "\n",
      " log_likelihoods reduce: -1.09812963\n",
      "\n",
      " elbo: 1.47727478\n",
      "\n",
      " log_likelihoods reduce: -1.06519032\n",
      "\n",
      " elbo: 1.46464133\n",
      "\n",
      " log_likelihoods reduce: -1.05256104\n",
      "\n",
      " elbo: 1.48877668\n",
      "\n",
      " log_likelihoods reduce: -1.07670057\n",
      "\n",
      " elbo: 1.48620629\n",
      "\n",
      " log_likelihoods reduce: -1.07413447\n",
      "\n",
      " elbo: 1.50338483\n",
      "\n",
      " log_likelihoods reduce: -1.09131718\n",
      "\n",
      " elbo: 1.45019317\n",
      "\n",
      " log_likelihoods reduce: -1.03812981\n",
      "\n",
      " elbo: 1.47457278\n",
      "\n",
      " log_likelihoods reduce: -1.06251359\n",
      "\n",
      " elbo: 1.47310627\n",
      "\n",
      " log_likelihoods reduce: -1.06105125\n",
      "\n",
      " elbo: 1.43266582\n",
      "\n",
      " log_likelihoods reduce: -1.0206151\n",
      "\n",
      " elbo: 1.4229995\n",
      "\n",
      " log_likelihoods reduce: -1.01095295\n",
      "\n",
      " elbo: 1.5095582\n",
      "\n",
      " log_likelihoods reduce: -1.09751594\n",
      "\n",
      " elbo: 1.46676397\n",
      "\n",
      " log_likelihoods reduce: -1.05472589\n",
      "\n",
      " elbo: 1.48583531\n",
      "\n",
      " log_likelihoods reduce: -1.07380152\n",
      "\n",
      " elbo: 1.50911772\n",
      "\n",
      " log_likelihoods reduce: -1.0970881\n",
      "\n",
      " elbo: 1.48029041\n",
      "\n",
      " log_likelihoods reduce: -1.06826496\n",
      "\n",
      " elbo: 1.50875211\n",
      "\n",
      " log_likelihoods reduce: -1.09673095\n",
      "\n",
      " elbo: 1.46609402\n",
      "\n",
      " log_likelihoods reduce: -1.05407703\n",
      "\n",
      " elbo: 1.46870637\n",
      "\n",
      " log_likelihoods reduce: -1.05669355\n",
      "\n",
      " elbo: 1.53348517\n",
      "\n",
      " log_likelihoods reduce: -1.12147665\n",
      "\n",
      " elbo: 1.44729733\n",
      "\n",
      " log_likelihoods reduce: -1.03529298\n",
      "\n",
      " elbo: 1.46137345\n",
      "\n",
      " log_likelihoods reduce: -1.04937339\n",
      "\n",
      " elbo: 1.46478808\n",
      "\n",
      " log_likelihoods reduce: -1.05279219\n",
      "\n",
      " elbo: 1.44770825\n",
      "\n",
      " log_likelihoods reduce: -1.03571653\n",
      "\n",
      " elbo: 1.43395221\n",
      "\n",
      " log_likelihoods reduce: -1.02196479\n",
      "\n",
      " elbo: 1.47855389\n",
      "\n",
      " log_likelihoods reduce: -1.06657064\n",
      "\n",
      " elbo: 1.48093152\n",
      "\n",
      " log_likelihoods reduce: -1.06895244\n",
      "\n",
      " elbo: 1.46610785\n",
      "\n",
      " log_likelihoods reduce: -1.05413294\n",
      "\n",
      " elbo: 1.44039464\n",
      "\n",
      " log_likelihoods reduce: -1.02842402\n",
      "\n",
      " elbo: 1.40644121\n",
      "\n",
      " log_likelihoods reduce: -0.994474709\n",
      "\n",
      " elbo: 1.8274796\n",
      "\n",
      " log_likelihoods reduce: -1.41551733\n",
      "Epoch 1: Train_ELBO = 1836.168212890625, Val_MAE = 0.5578809114685211\n",
      "\n",
      " elbo: 1.49127436\n",
      "\n",
      " log_likelihoods reduce: -1.0793159\n",
      "\n",
      " elbo: 1.49303746\n",
      "\n",
      " log_likelihoods reduce: -1.08108282\n",
      "\n",
      " elbo: 1.52382183\n",
      "\n",
      " log_likelihoods reduce: -1.11187088\n",
      "\n",
      " elbo: 1.56613314\n",
      "\n",
      " log_likelihoods reduce: -1.15418601\n",
      "\n",
      " elbo: 1.55722523\n",
      "\n",
      " log_likelihoods reduce: -1.14528179\n",
      "\n",
      " elbo: 1.48330927\n",
      "\n",
      " log_likelihoods reduce: -1.07136965\n",
      "\n",
      " elbo: 1.53313828\n",
      "\n",
      " log_likelihoods reduce: -1.12120247\n",
      "\n",
      " elbo: 1.51743233\n",
      "\n",
      " log_likelihoods reduce: -1.10550022\n",
      "\n",
      " elbo: 1.5567528\n",
      "\n",
      " log_likelihoods reduce: -1.1448245\n",
      "\n",
      " elbo: 1.55826139\n",
      "\n",
      " log_likelihoods reduce: -1.14633691\n",
      "\n",
      " elbo: 1.54356444\n",
      "\n",
      " log_likelihoods reduce: -1.13164365\n",
      "\n",
      " elbo: 1.56243205\n",
      "\n",
      " log_likelihoods reduce: -1.15051508\n",
      "\n",
      " elbo: 1.55953133\n",
      "\n",
      " log_likelihoods reduce: -1.14761806\n",
      "\n",
      " elbo: 1.51985073\n",
      "\n",
      " log_likelihoods reduce: -1.10794127\n",
      "\n",
      " elbo: 1.54625583\n",
      "\n",
      " log_likelihoods reduce: -1.13435018\n",
      "\n",
      " elbo: 1.52355373\n",
      "\n",
      " log_likelihoods reduce: -1.1116519\n",
      "\n",
      " elbo: 1.53248119\n",
      "\n",
      " log_likelihoods reduce: -1.12058306\n",
      "\n",
      " elbo: 1.47430062\n",
      "\n",
      " log_likelihoods reduce: -1.0624063\n",
      "\n",
      " elbo: 1.50050497\n",
      "\n",
      " log_likelihoods reduce: -1.08861446\n",
      "\n",
      " elbo: 1.51985109\n",
      "\n",
      " log_likelihoods reduce: -1.10796428\n",
      "\n",
      " elbo: 1.50345981\n",
      "\n",
      " log_likelihoods reduce: -1.09157681\n",
      "\n",
      " elbo: 1.52875578\n",
      "\n",
      " log_likelihoods reduce: -1.11687648\n",
      "\n",
      " elbo: 1.54426765\n",
      "\n",
      " log_likelihoods reduce: -1.13239217\n",
      "\n",
      " elbo: 1.49657297\n",
      "\n",
      " log_likelihoods reduce: -1.0847013\n",
      "\n",
      " elbo: 1.5023303\n",
      "\n",
      " log_likelihoods reduce: -1.09046245\n",
      "\n",
      " elbo: 1.46816742\n",
      "\n",
      " log_likelihoods reduce: -1.05630326\n",
      "\n",
      " elbo: 1.54177\n",
      "\n",
      " log_likelihoods reduce: -1.12990963\n",
      "\n",
      " elbo: 1.50147557\n",
      "\n",
      " log_likelihoods reduce: -1.08961892\n",
      "\n",
      " elbo: 1.49869108\n",
      "\n",
      " log_likelihoods reduce: -1.08683825\n",
      "\n",
      " elbo: 1.48505831\n",
      "\n",
      " log_likelihoods reduce: -1.07320929\n",
      "\n",
      " elbo: 1.49399781\n",
      "\n",
      " log_likelihoods reduce: -1.08215249\n",
      "\n",
      " elbo: 1.4827224\n",
      "\n",
      " log_likelihoods reduce: -1.07088089\n",
      "\n",
      " elbo: 1.45045829\n",
      "\n",
      " log_likelihoods reduce: -1.03862047\n",
      "\n",
      " elbo: 1.53127027\n",
      "\n",
      " log_likelihoods reduce: -1.11943626\n",
      "\n",
      " elbo: 1.45913899\n",
      "\n",
      " log_likelihoods reduce: -1.04730868\n",
      "\n",
      " elbo: 1.49608338\n",
      "\n",
      " log_likelihoods reduce: -1.08425689\n",
      "\n",
      " elbo: 1.47220683\n",
      "\n",
      " log_likelihoods reduce: -1.06038415\n",
      "\n",
      " elbo: 1.48581672\n",
      "\n",
      " log_likelihoods reduce: -1.07399774\n",
      "\n",
      " elbo: 1.47899294\n",
      "\n",
      " log_likelihoods reduce: -1.06717777\n",
      "\n",
      " elbo: 1.48370862\n",
      "\n",
      " log_likelihoods reduce: -1.07189727\n",
      "\n",
      " elbo: 1.43965197\n",
      "\n",
      " log_likelihoods reduce: -1.02784431\n",
      "\n",
      " elbo: 1.48512065\n",
      "\n",
      " log_likelihoods reduce: -1.07331669\n",
      "\n",
      " elbo: 1.50013423\n",
      "\n",
      " log_likelihoods reduce: -1.08833408\n",
      "\n",
      " elbo: 1.46758187\n",
      "\n",
      " log_likelihoods reduce: -1.05578542\n",
      "\n",
      " elbo: 1.47014487\n",
      "\n",
      " log_likelihoods reduce: -1.05835223\n",
      "\n",
      " elbo: 1.44866395\n",
      "\n",
      " log_likelihoods reduce: -1.03687501\n",
      "\n",
      " elbo: 1.48920155\n",
      "\n",
      " log_likelihoods reduce: -1.07741642\n",
      "\n",
      " elbo: 1.45753288\n",
      "\n",
      " log_likelihoods reduce: -1.04575157\n",
      "\n",
      " elbo: 1.47140121\n",
      "\n",
      " log_likelihoods reduce: -1.0596236\n",
      "\n",
      " elbo: 1.44862378\n",
      "\n",
      " log_likelihoods reduce: -1.03685\n",
      "\n",
      " elbo: 1.47693682\n",
      "\n",
      " log_likelihoods reduce: -1.06516671\n",
      "\n",
      " elbo: 1.44199467\n",
      "\n",
      " log_likelihoods reduce: -1.03022826\n",
      "\n",
      " elbo: 1.53637612\n",
      "\n",
      " log_likelihoods reduce: -1.12461352\n",
      "\n",
      " elbo: 1.48243868\n",
      "\n",
      " log_likelihoods reduce: -1.0706799\n",
      "\n",
      " elbo: 1.53519785\n",
      "\n",
      " log_likelihoods reduce: -1.12344277\n",
      "\n",
      " elbo: 1.45022464\n",
      "\n",
      " log_likelihoods reduce: -1.03847325\n",
      "\n",
      " elbo: 1.48416376\n",
      "\n",
      " log_likelihoods reduce: -1.07241619\n",
      "\n",
      " elbo: 1.47945285\n",
      "\n",
      " log_likelihoods reduce: -1.06770897\n",
      "\n",
      " elbo: 1.41131532\n",
      "\n",
      " log_likelihoods reduce: -0.999575257\n",
      "\n",
      " elbo: 1.49217832\n",
      "\n",
      " log_likelihoods reduce: -1.08044195\n",
      "\n",
      " elbo: 1.5023762\n",
      "\n",
      " log_likelihoods reduce: -1.09064364\n",
      "\n",
      " elbo: 1.50346661\n",
      "\n",
      " log_likelihoods reduce: -1.09173775\n",
      "\n",
      " elbo: 1.53752208\n",
      "\n",
      " log_likelihoods reduce: -1.12579703\n",
      "\n",
      " elbo: 1.48607266\n",
      "\n",
      " log_likelihoods reduce: -1.07435131\n",
      "\n",
      " elbo: 1.4798466\n",
      "\n",
      " log_likelihoods reduce: -1.06812894\n",
      "\n",
      " elbo: 1.47496867\n",
      "\n",
      " log_likelihoods reduce: -1.06325483\n",
      "\n",
      " elbo: 1.41289556\n",
      "\n",
      " log_likelihoods reduce: -1.00118542\n",
      "\n",
      " elbo: 1.45114064\n",
      "\n",
      " log_likelihoods reduce: -1.03943419\n",
      "\n",
      " elbo: 1.49116945\n",
      "\n",
      " log_likelihoods reduce: -1.07946682\n",
      "\n",
      " elbo: 1.44572246\n",
      "\n",
      " log_likelihoods reduce: -1.03402352\n",
      "\n",
      " elbo: 1.45107901\n",
      "\n",
      " log_likelihoods reduce: -1.03938389\n",
      "\n",
      " elbo: 1.4038465\n",
      "\n",
      " log_likelihoods reduce: -0.992155194\n",
      "\n",
      " elbo: 1.43603683\n",
      "\n",
      " log_likelihoods reduce: -1.02434921\n",
      "\n",
      " elbo: 1.40966177\n",
      "\n",
      " log_likelihoods reduce: -0.997977853\n",
      "\n",
      " elbo: 1.47944498\n",
      "\n",
      " log_likelihoods reduce: -1.06776488\n",
      "\n",
      " elbo: 1.45174193\n",
      "\n",
      " log_likelihoods reduce: -1.04006553\n",
      "\n",
      " elbo: 1.49567056\n",
      "\n",
      " log_likelihoods reduce: -1.08399785\n",
      "\n",
      " elbo: 1.46422243\n",
      "\n",
      " log_likelihoods reduce: -1.05255342\n",
      "\n",
      " elbo: 1.50051785\n",
      "\n",
      " log_likelihoods reduce: -1.08885264\n",
      "\n",
      " elbo: 1.48447335\n",
      "\n",
      " log_likelihoods reduce: -1.07281184\n",
      "\n",
      " elbo: 1.4787997\n",
      "\n",
      " log_likelihoods reduce: -1.06714201\n",
      "\n",
      " elbo: 1.47439432\n",
      "\n",
      " log_likelihoods reduce: -1.06274033\n",
      "\n",
      " elbo: 1.4668231\n",
      "\n",
      " log_likelihoods reduce: -1.0551728\n",
      "\n",
      " elbo: 1.5052259\n",
      "\n",
      " log_likelihoods reduce: -1.09357929\n",
      "\n",
      " elbo: 1.4707818\n",
      "\n",
      " log_likelihoods reduce: -1.05913901\n",
      "\n",
      " elbo: 1.49147582\n",
      "\n",
      " log_likelihoods reduce: -1.07983685\n",
      "\n",
      " elbo: 1.436432\n",
      "\n",
      " log_likelihoods reduce: -1.02479672\n",
      "\n",
      " elbo: 1.4965564\n",
      "\n",
      " log_likelihoods reduce: -1.08492482\n",
      "\n",
      " elbo: 1.43882751\n",
      "\n",
      " log_likelihoods reduce: -1.02719975\n",
      "\n",
      " elbo: 1.45241094\n",
      "\n",
      " log_likelihoods reduce: -1.04078686\n",
      "\n",
      " elbo: 1.46448493\n",
      "\n",
      " log_likelihoods reduce: -1.05286455\n",
      "\n",
      " elbo: 1.46118379\n",
      "\n",
      " log_likelihoods reduce: -1.04956722\n",
      "\n",
      " elbo: 1.46107042\n",
      "\n",
      " log_likelihoods reduce: -1.04945755\n",
      "\n",
      " elbo: 1.4593842\n",
      "\n",
      " log_likelihoods reduce: -1.04777503\n",
      "\n",
      " elbo: 1.45371628\n",
      "\n",
      " log_likelihoods reduce: -1.04211092\n",
      "\n",
      " elbo: 1.42044973\n",
      "\n",
      " log_likelihoods reduce: -1.00884807\n",
      "\n",
      " elbo: 1.50568151\n",
      "\n",
      " log_likelihoods reduce: -1.09408355\n",
      "\n",
      " elbo: 1.42875743\n",
      "\n",
      " log_likelihoods reduce: -1.01716328\n",
      "\n",
      " elbo: 1.47792649\n",
      "\n",
      " log_likelihoods reduce: -1.06633592\n",
      "\n",
      " elbo: 1.48347306\n",
      "\n",
      " log_likelihoods reduce: -1.0718863\n",
      "\n",
      " elbo: 1.4742502\n",
      "\n",
      " log_likelihoods reduce: -1.06266713\n",
      "\n",
      " elbo: 1.45908952\n",
      "\n",
      " log_likelihoods reduce: -1.04751015\n",
      "\n",
      " elbo: 1.48462558\n",
      "\n",
      " log_likelihoods reduce: -1.0730499\n",
      "\n",
      " elbo: 1.47198069\n",
      "\n",
      " log_likelihoods reduce: -1.06040883\n",
      "\n",
      " elbo: 1.44810987\n",
      "\n",
      " log_likelihoods reduce: -1.03654182\n",
      "\n",
      " elbo: 1.42863679\n",
      "\n",
      " log_likelihoods reduce: -1.01707232\n",
      "\n",
      " elbo: 1.40739584\n",
      "\n",
      " log_likelihoods reduce: -0.995835125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 14\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[1;32m     10\u001b[0m     \n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Update weights each batch\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x_data, y_data \u001b[38;5;129;01min\u001b[39;00m data_train:\n\u001b[0;32m---> 14\u001b[0m         elbo2[epoch] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Evaluate performance on validation data\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x_data, y_data \u001b[38;5;129;01min\u001b[39;00m data_val:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model2 = BayesianNN2Heads([7, 256, 128], [64, 32, 1])\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=L_RATE)\n",
    "\n",
    "# Fit the model\n",
    "elbo2 = np.zeros(EPOCHS)\n",
    "mae2 = np.zeros(EPOCHS)\n",
    "N = x_train.shape[0]\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    # Update weights each batch\n",
    "    for x_data, y_data in data_train:\n",
    "        \n",
    "        elbo2[epoch] += model2._train_evaluate(x_data, y_data, optimizer, N)\n",
    "        \n",
    "    # Evaluate performance on validation data\n",
    "    for x_data, y_data in data_val:\n",
    "        y_pred = model2(x_data, sampling=False)[:, 0]\n",
    "        mae2[epoch] = mean_absolute_error(y_pred, y_data)\n",
    "       \n",
    "    # Print ELBO and MAE for each epoch\n",
    "    print(f\"Epoch {epoch+1}: Train_ELBO = {elbo2[epoch]}, Val_MAE = {mae2[epoch]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train_ELBO = 2168.479736328125, Val_MAE = 0.5565748661878602\n",
      "Epoch 2: Train_ELBO = 1600.227294921875, Val_MAE = 0.5023895100605886\n",
      "Epoch 3: Train_ELBO = 1520.8216552734375, Val_MAE = 0.4806039760676875\n",
      "Epoch 4: Train_ELBO = 1473.541015625, Val_MAE = 0.4642520415279358\n",
      "Epoch 5: Train_ELBO = 1428.809814453125, Val_MAE = 0.44642864638525886\n",
      "Epoch 6: Train_ELBO = 1381.8846435546875, Val_MAE = 0.4288172689614309\n",
      "Epoch 7: Train_ELBO = 1341.20556640625, Val_MAE = 0.417435010216756\n",
      "Epoch 8: Train_ELBO = 1311.936279296875, Val_MAE = 0.4106307903938584\n",
      "Epoch 9: Train_ELBO = 1291.057861328125, Val_MAE = 0.40512906605402216\n",
      "Epoch 10: Train_ELBO = 1274.720703125, Val_MAE = 0.4014816639339142\n",
      "Epoch 11: Train_ELBO = 1261.460205078125, Val_MAE = 0.39916296444503147\n",
      "Epoch 12: Train_ELBO = 1250.4658203125, Val_MAE = 0.3965053077902231\n",
      "Epoch 13: Train_ELBO = 1240.7032470703125, Val_MAE = 0.39481070474915686\n",
      "Epoch 14: Train_ELBO = 1232.4910888671875, Val_MAE = 0.3942140658132454\n",
      "Epoch 15: Train_ELBO = 1225.35009765625, Val_MAE = 0.39255607029818534\n",
      "Epoch 16: Train_ELBO = 1219.2666015625, Val_MAE = 0.3912628150303837\n",
      "Epoch 17: Train_ELBO = 1213.3223876953125, Val_MAE = 0.3907168726746301\n",
      "Epoch 18: Train_ELBO = 1207.89453125, Val_MAE = 0.39048490856222545\n",
      "Epoch 19: Train_ELBO = 1202.9705810546875, Val_MAE = 0.39007810755560074\n",
      "Epoch 20: Train_ELBO = 1198.50927734375, Val_MAE = 0.38923687251893446\n",
      "Epoch 21: Train_ELBO = 1194.2288818359375, Val_MAE = 0.38871623234466895\n",
      "Epoch 22: Train_ELBO = 1189.7952880859375, Val_MAE = 0.3881232759185615\n",
      "Epoch 23: Train_ELBO = 1185.85302734375, Val_MAE = 0.38756865240376254\n",
      "Epoch 24: Train_ELBO = 1182.2451171875, Val_MAE = 0.3877820247117969\n",
      "Epoch 25: Train_ELBO = 1178.4761962890625, Val_MAE = 0.38750288553700873\n",
      "Epoch 26: Train_ELBO = 1175.0172119140625, Val_MAE = 0.3867493151578306\n",
      "Epoch 27: Train_ELBO = 1171.857421875, Val_MAE = 0.3868271491347229\n",
      "Epoch 28: Train_ELBO = 1168.3690185546875, Val_MAE = 0.3866190574049521\n",
      "Epoch 29: Train_ELBO = 1165.2431640625, Val_MAE = 0.38668191259311757\n",
      "Epoch 30: Train_ELBO = 1162.102783203125, Val_MAE = 0.38636393441153005\n",
      "Epoch 31: Train_ELBO = 1158.926513671875, Val_MAE = 0.3864141036367634\n",
      "Epoch 32: Train_ELBO = 1156.6171875, Val_MAE = 0.3858664677620566\n",
      "Epoch 33: Train_ELBO = 1153.5267333984375, Val_MAE = 0.38522785571932266\n",
      "Epoch 34: Train_ELBO = 1151.1507568359375, Val_MAE = 0.3872273338377849\n",
      "Epoch 35: Train_ELBO = 1148.3013916015625, Val_MAE = 0.3855458518876217\n",
      "Epoch 36: Train_ELBO = 1145.8768310546875, Val_MAE = 0.3847717865778254\n",
      "Epoch 37: Train_ELBO = 1143.413818359375, Val_MAE = 0.38442731252717094\n",
      "Epoch 38: Train_ELBO = 1141.29638671875, Val_MAE = 0.3854922819623284\n",
      "Epoch 39: Train_ELBO = 1138.8935546875, Val_MAE = 0.3845538611429618\n",
      "Epoch 40: Train_ELBO = 1136.588134765625, Val_MAE = 0.3843152925496412\n",
      "Epoch 41: Train_ELBO = 1134.455078125, Val_MAE = 0.38504789862527744\n",
      "Epoch 42: Train_ELBO = 1132.26171875, Val_MAE = 0.38443122193279644\n",
      "Epoch 43: Train_ELBO = 1129.9813232421875, Val_MAE = 0.3849546562074699\n",
      "Epoch 44: Train_ELBO = 1127.916015625, Val_MAE = 0.38383709304168995\n",
      "Epoch 45: Train_ELBO = 1125.913330078125, Val_MAE = 0.38372669735265136\n",
      "Epoch 46: Train_ELBO = 1124.354736328125, Val_MAE = 0.3831326799668482\n",
      "Epoch 47: Train_ELBO = 1122.009033203125, Val_MAE = 0.3834987134024586\n",
      "Epoch 48: Train_ELBO = 1120.1207275390625, Val_MAE = 0.3827406545117805\n",
      "Epoch 49: Train_ELBO = 1118.38134765625, Val_MAE = 0.3825168894370891\n",
      "Epoch 50: Train_ELBO = 1116.4666748046875, Val_MAE = 0.38267551176691333\n",
      "Epoch 51: Train_ELBO = 1114.4342041015625, Val_MAE = 0.3822828961682438\n",
      "Epoch 52: Train_ELBO = 1112.80322265625, Val_MAE = 0.38190036469614996\n",
      "Epoch 53: Train_ELBO = 1110.9129638671875, Val_MAE = 0.3821375818652329\n",
      "Epoch 54: Train_ELBO = 1109.50439453125, Val_MAE = 0.38381555138642814\n",
      "Epoch 55: Train_ELBO = 1107.6512451171875, Val_MAE = 0.3820062104797696\n",
      "Epoch 56: Train_ELBO = 1106.1280517578125, Val_MAE = 0.3825459001622842\n",
      "Epoch 57: Train_ELBO = 1104.3963623046875, Val_MAE = 0.3816678953955521\n",
      "Epoch 58: Train_ELBO = 1102.9434814453125, Val_MAE = 0.38130159099511296\n",
      "Epoch 59: Train_ELBO = 1101.19580078125, Val_MAE = 0.38153382899635974\n",
      "Epoch 60: Train_ELBO = 1099.7022705078125, Val_MAE = 0.38151074698582366\n",
      "Epoch 61: Train_ELBO = 1098.2442626953125, Val_MAE = 0.38149533187437273\n",
      "Epoch 62: Train_ELBO = 1096.4793701171875, Val_MAE = 0.3811930934751726\n",
      "Epoch 63: Train_ELBO = 1095.2947998046875, Val_MAE = 0.3812027829516264\n",
      "Epoch 64: Train_ELBO = 1093.67529296875, Val_MAE = 0.3816464348219478\n",
      "Epoch 65: Train_ELBO = 1092.123291015625, Val_MAE = 0.380510277153322\n",
      "Epoch 66: Train_ELBO = 1090.7991943359375, Val_MAE = 0.3801117922578494\n",
      "Epoch 67: Train_ELBO = 1089.24560546875, Val_MAE = 0.38097005018803076\n",
      "Epoch 68: Train_ELBO = 1087.9007568359375, Val_MAE = 0.3805796368864233\n",
      "Epoch 69: Train_ELBO = 1086.3990478515625, Val_MAE = 0.37981498066319874\n",
      "Epoch 70: Train_ELBO = 1084.73388671875, Val_MAE = 0.3797633491879538\n",
      "Epoch 71: Train_ELBO = 1083.4306640625, Val_MAE = 0.37981842052551745\n",
      "Epoch 72: Train_ELBO = 1082.007080078125, Val_MAE = 0.3798305939467933\n",
      "Epoch 73: Train_ELBO = 1080.5419921875, Val_MAE = 0.37935753931119054\n",
      "Epoch 74: Train_ELBO = 1078.773681640625, Val_MAE = 0.3798452675618579\n",
      "Epoch 75: Train_ELBO = 1077.1956787109375, Val_MAE = 0.3788280400420825\n",
      "Epoch 76: Train_ELBO = 1075.8084716796875, Val_MAE = 0.37889908055326343\n",
      "Epoch 77: Train_ELBO = 1073.895751953125, Val_MAE = 0.3783306082625398\n",
      "Epoch 78: Train_ELBO = 1072.178466796875, Val_MAE = 0.3779603092204659\n",
      "Epoch 79: Train_ELBO = 1070.588623046875, Val_MAE = 0.37771949022776924\n",
      "Epoch 80: Train_ELBO = 1068.68115234375, Val_MAE = 0.3774501971411923\n",
      "Epoch 81: Train_ELBO = 1067.0093994140625, Val_MAE = 0.3770276799236644\n",
      "Epoch 82: Train_ELBO = 1064.9730224609375, Val_MAE = 0.3765556148524866\n",
      "Epoch 83: Train_ELBO = 1063.421630859375, Val_MAE = 0.37659814758549975\n",
      "Epoch 84: Train_ELBO = 1061.4306640625, Val_MAE = 0.3760310624144318\n",
      "Epoch 85: Train_ELBO = 1059.579833984375, Val_MAE = 0.37559167710443647\n",
      "Epoch 86: Train_ELBO = 1057.859130859375, Val_MAE = 0.3752860750135172\n",
      "Epoch 87: Train_ELBO = 1056.0836181640625, Val_MAE = 0.37490808706410506\n",
      "Epoch 88: Train_ELBO = 1054.3385009765625, Val_MAE = 0.37465280191921363\n",
      "Epoch 89: Train_ELBO = 1052.687744140625, Val_MAE = 0.37409527648822105\n",
      "Epoch 90: Train_ELBO = 1051.1397705078125, Val_MAE = 0.37400868478683635\n",
      "Epoch 91: Train_ELBO = 1049.3297119140625, Val_MAE = 0.37398977566726915\n",
      "Epoch 92: Train_ELBO = 1047.850830078125, Val_MAE = 0.37362538342961277\n",
      "Epoch 93: Train_ELBO = 1046.5540771484375, Val_MAE = 0.373486951326664\n",
      "Epoch 94: Train_ELBO = 1045.2711181640625, Val_MAE = 0.3732037854453472\n",
      "Epoch 95: Train_ELBO = 1043.28271484375, Val_MAE = 0.3725666649729207\n",
      "Epoch 96: Train_ELBO = 1042.070556640625, Val_MAE = 0.3726403468951481\n",
      "Epoch 97: Train_ELBO = 1040.6851806640625, Val_MAE = 0.3722143286117516\n",
      "Epoch 98: Train_ELBO = 1039.309326171875, Val_MAE = 0.3725562530855851\n",
      "Epoch 99: Train_ELBO = 1037.8662109375, Val_MAE = 0.3721630101657127\n",
      "Epoch 100: Train_ELBO = 1036.853515625, Val_MAE = 0.3718222922423165\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model2 = BayesianNN2Heads([7, 256, 128], [64, 32, 1])\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=L_RATE)\n",
    "\n",
    "# Fit the model\n",
    "elbo2 = np.zeros(EPOCHS)\n",
    "mae2 = np.zeros(EPOCHS)\n",
    "N = x_train.shape[0]\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    # Update weights each batch\n",
    "    for x_data, y_data in data_train:\n",
    "        \n",
    "        elbo2[epoch] += model2._train_evaluate(x_data, y_data, optimizer, N)\n",
    "        \n",
    "    # Evaluate performance on validation data\n",
    "    for x_data, y_data in data_val:\n",
    "        y_pred = model2(x_data, sampling=False)[:, 0]\n",
    "        mae2[epoch] = mean_absolute_error(y_pred, y_data)\n",
    "       \n",
    "    # Print ELBO and MAE for each epoch\n",
    "    print(f\"Epoch {epoch+1}: Train_ELBO = {elbo2[epoch]}, Val_MAE = {mae2[epoch]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1144/1144 [==============================] - ETA: 0s - elbo: 475.9804"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/marcos/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2042, in test_function  *\n        return step_function(self, iterator)\n    File \"/tmp/ipykernel_71722/2685351279.py\", line 53, in test_step  *\n        mae = MeanAbsoluteError()\n    File \"/home/marcos/.local/lib/python3.10/site-packages/keras/src/dtensor/utils.py\", line 144, in _wrap_function  **\n        init_method(instance, *args, **kwargs)\n    File \"/home/marcos/.local/lib/python3.10/site-packages/keras/src/metrics/regression_metrics.py\", line 210, in __init__\n        super().__init__(mean_absolute_error, name, dtype=dtype)\n    File \"/home/marcos/.local/lib/python3.10/site-packages/keras/src/dtensor/utils.py\", line 144, in _wrap_function\n        init_method(instance, *args, **kwargs)\n    File \"/home/marcos/.local/lib/python3.10/site-packages/keras/src/metrics/base_metric.py\", line 682, in __init__\n        super().__init__(name=name, dtype=dtype)\n    File \"/home/marcos/.local/lib/python3.10/site-packages/keras/src/dtensor/utils.py\", line 144, in _wrap_function\n        init_method(instance, *args, **kwargs)\n    File \"/home/marcos/.local/lib/python3.10/site-packages/keras/src/metrics/base_metric.py\", line 645, in __init__\n        super().__init__(\n    File \"/home/marcos/.local/lib/python3.10/site-packages/keras/src/metrics/base_metric.py\", line 462, in __init__\n        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n    File \"/home/marcos/.local/lib/python3.10/site-packages/keras/src/metrics/base_metric.py\", line 398, in add_weight\n        return super().add_weight(\n    File \"/home/marcos/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 712, in add_weight\n        variable = self._add_variable_with_custom_getter(\n    File \"/home/marcos/.local/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py\", line 137, in make_variable\n        return tf1.Variable(\n\n    ValueError: tf.function only supports singleton tf.Variables created on the first call. Make sure the tf.Variable is only created once or created outside tf.function. See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Train the model using the manually created datasets\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_files36pof3r.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file_wvzf1tg.py:14\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     12\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcast, (ag__\u001b[38;5;241m.\u001b[39mld(y_pred), ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mfloat32), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m y_true \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcast, (ag__\u001b[38;5;241m.\u001b[39mld(y)[:, \u001b[38;5;241m0\u001b[39m], ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mfloat32), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 14\u001b[0m mae \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMeanAbsoluteError\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mval_mae\u001b[38;5;241m.\u001b[39mupdate_state, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(mae), (ag__\u001b[38;5;241m.\u001b[39mld(y_true), ag__\u001b[38;5;241m.\u001b[39mld(y_pred)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/marcos/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2042, in test_function  *\n        return step_function(self, iterator)\n    File \"/tmp/ipykernel_71722/2685351279.py\", line 53, in test_step  *\n        mae = MeanAbsoluteError()\n    File \"/home/marcos/.local/lib/python3.10/site-packages/keras/src/dtensor/utils.py\", line 144, in _wrap_function  **\n        init_method(instance, *args, **kwargs)\n    File \"/home/marcos/.local/lib/python3.10/site-packages/keras/src/metrics/regression_metrics.py\", line 210, in __init__\n        super().__init__(mean_absolute_error, name, dtype=dtype)\n    File \"/home/marcos/.local/lib/python3.10/site-packages/keras/src/dtensor/utils.py\", line 144, in _wrap_function\n        init_method(instance, *args, **kwargs)\n    File \"/home/marcos/.local/lib/python3.10/site-packages/keras/src/metrics/base_metric.py\", line 682, in __init__\n        super().__init__(name=name, dtype=dtype)\n    File \"/home/marcos/.local/lib/python3.10/site-packages/keras/src/dtensor/utils.py\", line 144, in _wrap_function\n        init_method(instance, *args, **kwargs)\n    File \"/home/marcos/.local/lib/python3.10/site-packages/keras/src/metrics/base_metric.py\", line 645, in __init__\n        super().__init__(\n    File \"/home/marcos/.local/lib/python3.10/site-packages/keras/src/metrics/base_metric.py\", line 462, in __init__\n        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n    File \"/home/marcos/.local/lib/python3.10/site-packages/keras/src/metrics/base_metric.py\", line 398, in add_weight\n        return super().add_weight(\n    File \"/home/marcos/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 712, in add_weight\n        variable = self._add_variable_with_custom_getter(\n    File \"/home/marcos/.local/lib/python3.10/site-packages/keras/src/engine/base_layer_utils.py\", line 137, in make_variable\n        return tf1.Variable(\n\n    ValueError: tf.function only supports singleton tf.Variables created on the first call. Make sure the tf.Variable is only created once or created outside tf.function. See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.\n"
     ]
    }
   ],
   "source": [
    "# Initialize and compile the model\n",
    "model = BayesianNN2Heads([7, 256, 128], [64, 32, 1])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))\n",
    "\n",
    "# Train the model using the manually created datasets\n",
    "history = model.fit(data_train, validation_data=data_val, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAGwCAYAAABIC3rIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABLYElEQVR4nO3deXhTZd4+8Dttli5p0o00LbRQFoECVgSBijLw2qFAdQbBdwasWEeUF6egwPwQGRWXdxwUHR11FMYZR5xXGBQdkEXRylJEylYsO2WrtFDSPUmTtknanN8faY5kKNJCmpM29+e6cmHOeZp8z1HpfT3ne54jEwRBABEREVEAC5K6ACIiIiKpMRARERFRwGMgIiIiooDHQEREREQBj4GIiIiIAh4DEREREQU8BiIiIiIKeHKpC+gsnE4nysrKEBERAZlMJnU5RERE1AaCIKCurg4JCQkICrr6PBADURuVlZUhMTFR6jKIiIjoOpSWlqJHjx5X3c9A1EYREREAXCdUo9FIXA0RERG1hdlsRmJiovh7/GoYiNrIfZlMo9EwEBEREXUy12p3YVM1ERERBTwGIiIiIgp4DEREREQU8BiIiIiIKOAxEBEREVHAYyAiIiKigMdARERERAGPgYiIiIgCHgMRERERBTwGIiIiIgp4DEREREQU8BiIiIiIKOBJGoiWLl2K2267DREREdDpdJg8eTKKiorE/TU1NZg7dy769++P0NBQJCUl4fHHH4fJZPL4nJKSEmRmZiIsLAw6nQ4LFy5EU1OTx5gdO3bg1ltvhUqlQt++fbFy5UpfHOI1GUyNOF9tRVOzU+pSiIiIApakgSgvLw85OTnYs2cPcnNz4XA4MH78eFitVgBAWVkZysrK8Nprr+Ho0aNYuXIltmzZgpkzZ4qf0dzcjMzMTNjtduzevRsffvghVq5ciSVLlohjiouLkZmZiXHjxqGwsBDz5s3DI488gq+++srnx/yfRr+yDT97dQeqrXapSyEiIgpYMkEQBKmLcKusrIROp0NeXh7GjBnT6pi1a9figQcegNVqhVwux5dffom7774bZWVliIuLAwCsWLECixYtQmVlJZRKJRYtWoTNmzfj6NGj4udMmzYNRqMRW7ZsafV7bDYbbDab+N5sNiMxMREmkwkajcZrxzzw2S1ocDTj2yfHITE6zGufS0RERK7f31qt9pq/v/2qh8h9KSw6Ovonx2g0GsjlcgBAfn4+hgwZIoYhAMjIyIDZbMaxY8fEMenp6R6fk5GRgfz8/Kt+z9KlS6HVasVXYmLidR/XT1HKXf8KbE28ZEZERCQVvwlETqcT8+bNw+jRozF48OBWx1RVVeF///d/MWvWLHGbwWDwCEMAxPcGg+Enx5jNZjQ0NLT6XYsXL4bJZBJfpaWl131sP0UR7PpXYGcgIiIikoxc6gLccnJycPToUezatavV/WazGZmZmUhJScHzzz/f4fWoVCqoVKqO/56WGSIHm6qJiIgk4xczRHPmzMGmTZuwfft29OjR44r9dXV1mDBhAiIiIrBu3TooFApxn16vR3l5ucd493u9Xv+TYzQaDUJDQ719OO3ivmRmZyAiIiKSjKSBSBAEzJkzB+vWrcO2bduQnJx8xRiz2Yzx48dDqVRiw4YNCAkJ8diflpaGI0eOoKKiQtyWm5sLjUaDlJQUcczWrVs9fi43NxdpaWkdcFTto+QlMyIiIslJGohycnLw0UcfYfXq1YiIiIDBYIDBYBD7etxhyGq14v3334fZbBbHNDc3AwDGjx+PlJQUzJgxA4cOHcJXX32FZ555Bjk5OeIlr9mzZ+PcuXN48skncfLkSbz77rv45JNPMH/+fMmO3U0hlwFgICIiIpKSpD1Ey5cvBwCMHTvWY/sHH3yAhx56CAcPHsTevXsBAH379vUYU1xcjF69eiE4OBibNm3CY489hrS0NISHhyM7OxsvvviiODY5ORmbN2/G/Pnz8eabb6JHjx74+9//joyMjI49wDYQZ4h4yYyIiEgykgaiay2BNHbs2GuOAYCePXviiy++uOZnff/99+2qzxfEHiLOEBEREUnGL5qqA5lSHgyAgYiIiEhKDEQSUwa39BDxkhkREZFkGIgkpuQ6RERERJJjIJIYb7snIiKSHgORxPgsMyIiIukxEEmMzzIjIiKSHgORxNhDREREJD0GIolxHSIiIiLpMRBJTMWVqomIiCTHQCQx9hARERFJj4FIYuIlM84QERERSYaBSGLsISIiIpIeA5HEGIiIiIikx0AkMQWbqomIiCTHQCQxFdchIiIikhwDkcT4LDMiIiLpMRBJjD1ERERE0mMgkpi7h4gPdyUiIpIOA5HE+CwzIiIi6TEQSYwLMxIREUmPgUhibKomIiKSHgORxNhUTUREJD0GIom5Z4gczYLElRAREQUuBiKJcYaIiIhIegxEEru8qVoQOEtEREQkBQYiibnXIQJ4pxkREZFUGIgk5n6WGcA+IiIiIqkwEElMefkMEfuIiIiIJMFAJLGgIBnkQTIADERERERSYSDyAwouzkhERCQpBiI/wMd3EBERSYuByA9wLSIiIiJpMRD5AfF5ZpwhIiIikgQDkR/gDBEREZG0GIj8wI/PM2MgIiIikgIDkR/gDBEREZG0GIj8gDsQ2RiIiIiIJMFA5AcUwS0LM/KSGRERkSQYiPyAUh4MgJfMiIiIpMJA5AfYVE1ERCQtBiI/oGJTNRERkaQYiPyA2EPEQERERCQJBiI/wGeZERERSYuByA9wHSIiIiJpMRD5AWVwy11mnCEiIiKSBAORH+AMERERkbQkDURLly7FbbfdhoiICOh0OkyePBlFRUUeYxobG5GTk4OYmBio1WpMnToV5eXlHmNKSkqQmZmJsLAw6HQ6LFy4EE1NTR5jduzYgVtvvRUqlQp9+/bFypUrO/rw2kzJpmoiIiJJSRqI8vLykJOTgz179iA3NxcOhwPjx4+H1WoVx8yfPx8bN27E2rVrkZeXh7KyMkyZMkXc39zcjMzMTNjtduzevRsffvghVq5ciSVLlohjiouLkZmZiXHjxqGwsBDz5s3DI488gq+++sqnx3s17hkirkNEREQkDZkgCILURbhVVlZCp9MhLy8PY8aMgclkQrdu3bB69Wrcd999AICTJ09i4MCByM/Px6hRo/Dll1/i7rvvRllZGeLi4gAAK1aswKJFi1BZWQmlUolFixZh8+bNOHr0qPhd06ZNg9FoxJYtW9pUm9lshlarhclkgkaj8epxv7fzLP74xUlMGdodr//6Fq9+NhERUSBr6+9vv+ohMplMAIDo6GgAQEFBARwOB9LT08UxAwYMQFJSEvLz8wEA+fn5GDJkiBiGACAjIwNmsxnHjh0Tx1z+Ge4x7s9ojc1mg9ls9nh1FPdK1TbOEBEREUnCbwKR0+nEvHnzMHr0aAwePBgAYDAYoFQqERkZ6TE2Li4OBoNBHHN5GHLvd+/7qTFmsxkNDQ2t1rN06VJotVrxlZiYeMPHeDUKNlUTERFJym8CUU5ODo4ePYo1a9ZIXQoAYPHixTCZTOKrtLS0w76LzzIjIiKSllzqAgBgzpw52LRpE3bu3IkePXqI2/V6Pex2O4xGo8csUXl5OfR6vThm3759Hp/nvgvt8jH/eWdaeXk5NBoNQkNDW61JpVJBpVLd8LG1BW+7JyIikpakM0SCIGDOnDlYt24dtm3bhuTkZI/9w4YNg0KhwNatW8VtRUVFKCkpQVpaGgAgLS0NR44cQUVFhTgmNzcXGo0GKSkp4pjLP8M9xv0ZUuPDXYmIiKQl6QxRTk4OVq9ejc8//xwRERFiz49Wq0VoaCi0Wi1mzpyJBQsWIDo6GhqNBnPnzkVaWhpGjRoFABg/fjxSUlIwY8YMLFu2DAaDAc888wxycnLEGZ7Zs2fjL3/5C5588kk8/PDD2LZtGz755BNs3rxZsmO/nCKYzzIjIiKSkqQzRMuXL4fJZMLYsWMRHx8vvj7++GNxzBtvvIG7774bU6dOxZgxY6DX6/Hvf/9b3B8cHIxNmzYhODgYaWlpeOCBB/Dggw/ixRdfFMckJydj8+bNyM3NRWpqKv70pz/h73//OzIyMnx6vFfDS2ZERETS8qt1iPxZR65DtPdcNX793h707haObb8b69XPJiIiCmSdch2iQMUZIiIiImkxEPkBsYeIgYiIiEgSDER+QMVnmREREUmKgcgP8JIZERGRtBiI/IAYiDhDREREJAkGIj+gEB/dIcDp5E1/REREvsZA5AfcM0QA4HByloiIiMjXGIj8gPvhrgD7iIiIiKTAQOQHGIiIiIikxUDkB4KCZJAHyQCwsZqIiEgKDER+wt1H5GhiUzUREZGvMRD5iR9vvW+WuBIiIqLAw0DkJ9x9RDb2EBEREfkcA5Gf4PPMiIiIpMNA5Cd+fJ4Ze4iIiIh8jYHIT/B5ZkRERNJhIPITbKomIiKSDgORn2APERERkXQYiPyE+y4zO3uIiIiIfI6ByE+wh4iIiEg6DER+goGIiIhIOgxEfkK8ZNbEpmoiIiJfYyDyE0quQ0RERCQZBiI/8WNTNS+ZERER+RoDkZ9wzxDxWWZERES+x0DkJ7gOERERkXQYiPwE7zIjIiKSDgORn/ixqZqBiIiIyNcYiPyEijNEREREkmEg8hOKYBkA3mVGREQkBQYiP6FkUzUREZFkGIj8hFIeDIAzRERERFJgIPITvMuMiIhIOgxEfkLsIWIgIiIi8jkGIj8h3mXGS2ZEREQ+x0DkJ7gOERERkXQYiPyEMrilqZqXzIiIiHyOgchPsIeIiIhIOgxEfoJPuyciIpIOA5GfYA8RERGRdBiI/ATvMiMiIpIOA5GfUPDRHURERJJhIPITXKmaiIhIOgxEfsL9cNcmpwCnU5C4GiIiosDCQOQn3DNEAPuIiIiIfI2ByE+4e4gABiIiIiJfkzQQ7dy5E/fccw8SEhIgk8mwfv16j/0WiwVz5sxBjx49EBoaipSUFKxYscJjTGNjI3JychATEwO1Wo2pU6eivLzcY0xJSQkyMzMRFhYGnU6HhQsXoqmpqaMPr12Ulwci9hERERH5lKSByGq1IjU1Fe+8806r+xcsWIAtW7bgo48+wokTJzBv3jzMmTMHGzZsEMfMnz8fGzduxNq1a5GXl4eysjJMmTJF3N/c3IzMzEzY7Xbs3r0bH374IVauXIklS5Z0+PG1R1CQTFytmmsRERER+ZZMEAS/6OCVyWRYt24dJk+eLG4bPHgwfv3rX+PZZ58Vtw0bNgwTJ07EH/7wB5hMJnTr1g2rV6/GfffdBwA4efIkBg4ciPz8fIwaNQpffvkl7r77bpSVlSEuLg4AsGLFCixatAiVlZVQKpVtqs9sNkOr1cJkMkGj0XjvwC8zaMkWWO3NyFs4Fj1jwjvkO4iIiAJJW39/+3UP0e23344NGzbg4sWLEAQB27dvx6lTpzB+/HgAQEFBARwOB9LT08WfGTBgAJKSkpCfnw8AyM/Px5AhQ8QwBAAZGRkwm804duzYVb/bZrPBbDZ7vDqagrfeExERScKvA9Hbb7+NlJQU9OjRA0qlEhMmTMA777yDMWPGAAAMBgOUSiUiIyM9fi4uLg4Gg0Ecc3kYcu9377uapUuXQqvViq/ExEQvHlnr3H1EfJ4ZERGRb/l9INqzZw82bNiAgoIC/OlPf0JOTg6++eabDv/uxYsXw2Qyia/S0tIO/04+z4yIiEgacqkLuJqGhgb8/ve/x7p165CZmQkAuPnmm1FYWIjXXnsN6enp0Ov1sNvtMBqNHrNE5eXl0Ov1AAC9Xo99+/Z5fLb7LjT3mNaoVCqoVCovH9VP42rVRERE0vDbGSKHwwGHw4GgIM8Sg4OD4XS6AsOwYcOgUCiwdetWcX9RURFKSkqQlpYGAEhLS8ORI0dQUVEhjsnNzYVGo0FKSooPjqTt3JfMuA4RERGRb0k6Q2SxWHDmzBnxfXFxMQoLCxEdHY2kpCT87Gc/w8KFCxEaGoqePXsiLy8P//znP/H6668DALRaLWbOnIkFCxYgOjoaGo0Gc+fORVpaGkaNGgUAGD9+PFJSUjBjxgwsW7YMBoMBzzzzDHJycnw+A3QtnCEiIiKShqSB6MCBAxg3bpz4fsGCBQCA7OxsrFy5EmvWrMHixYuRlZWFmpoa9OzZEy+99BJmz54t/swbb7yBoKAgTJ06FTabDRkZGXj33XfF/cHBwdi0aRMee+wxpKWlITw8HNnZ2XjxxRd9d6Bt5J4hYg8RERGRb/nNOkT+zhfrEN3/tz3YfbYab067Bb+8pXuHfAcREVEg6RLrEAUa9/PMeMmMiIjItxiI/IjYQ8RLZkRERD7FQORHxHWIOENERETkUwxEfkTF2+6JiIgkwUDkR9hDREREJA0GIj/CdYiIiIikwUDkR35squZKCERERL7EQORHOENEREQkDQYiPyL2EDU3S1wJERFRYGEg8iMqzhARERFJgoHIj/z4LDP2EBEREflSuwPRwYMHceTIEfH9559/jsmTJ+P3v/897Ha7V4sLNOwhIiIikka7A9H//M//4NSpUwCAc+fOYdq0aQgLC8PatWvx5JNPer3AQOLuIbIxEBEREflUuwPRqVOncMsttwAA1q5dizFjxmD16tVYuXIlPvvsM2/XF1D4LDMiIiJptDsQCYIAp9P1C/ubb77BpEmTAACJiYmoqqrybnUB5sdLZrzLjIiIyJfaHYiGDx+OP/zhD/i///s/5OXlITMzEwBQXFyMuLg4rxcYSNhUTUREJI12B6I///nPOHjwIObMmYOnn34affv2BQB8+umnuP32271eYCBRymUA2FRNRETka/L2/sDNN9/scZeZ26uvvorg4GCvFBWolC3nj4GIiIjIt9o9Q1RaWooLFy6I7/ft24d58+bhn//8JxQKhVeLCzRsqiYiIpJGuwPR/fffj+3btwMADAYDfv7zn2Pfvn14+umn8eKLL3q9wEDCdYiIiIik0e5AdPToUYwYMQIA8Mknn2Dw4MHYvXs3Vq1ahZUrV3q7voCiDOYMERERkRTaHYgcDgdUKhUA1233v/jFLwAAAwYMwKVLl7xbXYBhUzUREZE02h2IBg0ahBUrVuDbb79Fbm4uJkyYAAAoKytDTEyM1wsMJGyqJiIikka7A9Err7yCv/71rxg7diymT5+O1NRUAMCGDRvES2l0fdw9RA5eMiMiIvKpdt92P3bsWFRVVcFsNiMqKkrcPmvWLISFhXm1uEDjDkRNTgFOp4CgIJnEFREREQWGdgciAAgODkZTUxN27doFAOjfvz969erlzboCkiL4xwBkb3YiJIjrOhEREflCuy+ZWa1WPPzww4iPj8eYMWMwZswYJCQkYObMmaivr++IGgOGe4YI4BPviYiIfKndgWjBggXIy8vDxo0bYTQaYTQa8fnnnyMvLw+/+93vOqLGgOG+7R5gHxEREZEvtfuS2WeffYZPP/0UY8eOFbdNmjQJoaGh+NWvfoXly5d7s76AIpPJoAwOgr3ZyTvNiIiIfKjdM0T19fWtPtVep9PxkpkXuPuIGIiIiIh8p92BKC0tDc899xwaGxvFbQ0NDXjhhReQlpbm1eICEZ9nRkRE5HvtvmT25ptvIiMjAz169BDXIDp06BBUKhW+/vprrxcYaPg8MyIiIt9rdyAaPHgwTp8+jVWrVuHkyZMAgOnTpyMrKwuhoaFeLzDQcIaIiIjI965rHaKwsDA8+uijHtvOnTuH2bNnc5boBimCOUNERETka+3uIbqauro6bN261VsfF7CUDEREREQ+57VARN6h4vPMiIiIfI6ByM+wqZqIiMj3GIj8jNhDxBkiIiIin2lzU/XQoUMhk1396etclNE73DNEfJYZERGR77Q5EE2ePLkDyyA3d1M1e4iIiIh8p82B6LnnnuvIOqgFe4iIiIh8jz1Efoa33RMREfkeA5Gf4QwRERGR7zEQ+Rkl1yEiIiLyOQYiP+O+ZGZjICIiIvIZBiI/o+AlMyIiIp9rVyBqamrCq6++iltvvRVqtRpqtRq33norXnvtNTgcjnZ/+c6dO3HPPfcgISEBMpkM69evv2LMiRMn8Itf/AJarRbh4eG47bbbUFJSIu5vbGxETk4OYmJioFarMXXqVJSXl3t8RklJCTIzMxEWFgadToeFCxeiqamp3fX6ApuqiYiIfK/NgaihoQFjx47FU089hW7duuGRRx7BI488gm7dumHRokW466670NjY2K4vt1qtSE1NxTvvvNPq/rNnz+KOO+7AgAEDsGPHDhw+fBjPPvssQkJCxDHz58/Hxo0bsXbtWuTl5aGsrAxTpkwR9zc3NyMzMxN2ux27d+/Ghx9+iJUrV2LJkiXtqtVX2ENEREQkAaGNlixZIiQlJQmHDh26Yl9hYaGQlJQkPPfcc239uCsAENatW+ex7de//rXwwAMPXPVnjEajoFAohLVr14rbTpw4IQAQ8vPzBUEQhC+++EIICgoSDAaDOGb58uWCRqMRbDZbm+szmUwCAMFkMrX5Z67H33aeFXou2iQ88a+DHfo9REREgaCtv7/bPEO0Zs0avP7667j55puv2JeamorXXnsNq1ev9lpQczqd2Lx5M2666SZkZGRAp9Nh5MiRHpfVCgoK4HA4kJ6eLm4bMGAAkpKSkJ+fDwDIz8/HkCFDEBcXJ47JyMiA2WzGsWPHrvr9NpsNZrPZ4+UL7qfdW+3NPvk+IiIiascls/Pnz2PEiBFX3T9q1CiP3p4bVVFRAYvFgpdffhkTJkzA119/jXvvvRdTpkxBXl4eAMBgMECpVCIyMtLjZ+Pi4mAwGMQxl4ch9373vqtZunQptFqt+EpMTPTasf2UpJhwAEBxldUn30dERETtCEQajQYVFRVX3W8wGBAREeGVogDXDBEA/PKXv8T8+fNxyy234KmnnsLdd9+NFStWeO17rmbx4sUwmUziq7S0tMO/EwD66dQAgB+qrGysJiIi8pE2B6Jx48bhj3/841X3v/zyyxg3bpxXigKA2NhYyOVypKSkeGwfOHCgOBOl1+tht9thNBo9xpSXl0Ov14tj/vOuM/d795jWqFQqaDQaj5cvxGtDEKGSo8kp4IdqzhIRERH5QpsD0XPPPYevv/4ao0aNwieffILDhw/j0KFDWLNmDUaOHImvv/7aqw+AVSqVuO2221BUVOSx/dSpU+jZsycAYNiwYVAoFNi6dau4v6ioCCUlJUhLSwMApKWl4ciRIx6zW7m5udBoNFeELX8gk8nQN841S3SqvE7iaoiIiAJDm592n5KSgtzcXMycORPTpk2DTCYDAAiCgAEDBuDrr7/GoEGD2vXlFosFZ86cEd8XFxejsLAQ0dHRSEpKwsKFC/HrX/8aY8aMwbhx47BlyxZs3LgRO3bsAABotVrMnDkTCxYsQHR0NDQaDebOnYu0tDSMGjUKADB+/HikpKRgxowZWLZsGQwGA5555hnk5ORApVK1q15f6adT4/sSI06XW6QuhYiIKCC0ORABrsbpY8eOobCwEKdOnQIA3HTTTbjllluu68sPHDjgcZltwYIFAIDs7GysXLkS9957L1asWIGlS5fi8ccfR//+/fHZZ5/hjjvuEH/mjTfeQFBQEKZOnQqbzYaMjAy8++674v7g4GBs2rQJjz32GNLS0hAeHo7s7Gy8+OKL11WzL9wU5+rFOl3BGSIiIiJfkAmCINzIB9jtdtjtdqjVam/V5JfMZjO0Wi1MJlOH9xPtKKrAQx/sRz+dGrkLftah30VERNSVtfX3d7se3fHBBx9g7ty5WLVqFQDg97//PSIiIqDVavHzn/8c1dXVN1Y1AfhxhqiYd5oRERH5RJsD0UsvvYScnBycPHkSjz/+OB577DF88MEHePHFF/Hyyy/j5MmTeOaZZzqy1oARrw2BmneaERER+Uybe4hWrlyJ999/H9OnT8eBAwcwcuRIfPLJJ5g6dSoAYPDgwZg9e3aHFRpIZDIZ+urUKCx1NVa7Z4yIiIioY7R5hqikpERsZh4+fDjkcjkGDx4s7r/55ptx6dIl71cYoG7irfdEREQ+0+ZA5HA4PG5TVyqVUCgU4nu5XI7mZj5/y1v66VyzQmcqeOs9ERFRR2vXbffHjx8Xn/8lCAJOnjwJi8X1C7uqqsr71QWwfpwhIiIi8pl2BaK77roLl9+lf/fddwNw9bwIgiAu1kg3rt9/3GmmlLfrhkAiIiJqhzYHouLi4o6sg/5DgjYE4cpgWO3NOF9tFQMSEREReV+bA5H7+WFXYzQa8cUXX1xzHLWN65lmEThUasSpcgsDERERUQfy2nWY8+fPY8aMGd76OAJwk87VR8RHeBAREXUsNqb4MfGZZnzIKxERUYdiIPJjfeM4Q0REROQLDER+7PJnmjma+UwzIiKijtLmpuq33nrrJ/dfvHjxhoshT5ffafZDFe80IyIi6ihtDkRvvPHGNcckJSXdUDHk6fI7zU5X8E4zIiKijsJ1iPxcP5265db7OkwaEi91OURERF0Se4j83E1iYzXvNCMiIuoobQ5EkyZNgslkEt+//PLLMBqN4vvq6mqkpKR4tTj68REep/lMMyIiog7T5kD01VdfwWazie//+Mc/oqamRnzf1NSEoqIi71ZH6NeyOCPvNCMiIuo4bQ5Elz/UtbX31DG6R4YiXBkMR7OAH6qsUpdDRETUJbGHyM/JZDKkJGgAAAdLaiWuhoiIqGtqcyCSyWSQyWRXbKOONzI5BgCw91zNNUYSERHR9WjzbfeCIOChhx6CSqUCADQ2NmL27NkIDw8HAI/+IvKukb2j8ZftwN5iBiIiIqKO0OZAlJ2d7fH+gQceuGLMgw8+eOMV0RWG9YyCPEiGi8YGlNbUIzE6TOqSiIiIupQ2B6IPPvigI+ugnxCmlGNIDy2+LzFib3ENAxEREZGXsam6k/ixj6ha4kqIiIi6HgaiTmJk72gA7CMiIiLqCAxEncTwnlEIkgElNfW4ZGqQuhwiIqIuhYGok4gIUWBQghYAb78nIiLyNgaiTmRksvuyGfuIiIiIvImBqBMZ2bulsZp9RERERF7FQNSJjOgVDZkMOFdpRUVdo9TlEBERdRkMRJ2INkyBAXrXc832cZaIiIjIaxiIOhmxj4iN1URERF7DQNTJjOrNxmoiIiJvYyDqZEa0rFh9qtyCGqtd4mqIiIi6BgaiTiY6XImb4tQAgH2cJSIiIvIKBqJOyP1csz3sIyIiIvIKBqJOyP1csz180CsREZFXMBB1QmktCzSeNNShymKTuBoiIqLOj4GoE4pRqzAw3rUe0e6znCUiIiK6UQxEndToPq5Zot1nqiSuhIiIqPNjIOqkRveLBQB8e7oKgiBIXA0REVHnxkDUSY3oFQ15kAwXjQ0oqamXuhwiIqJOjYGokwpXyXFrUhQA4Lsz7CMiIiK6EQxEndjtfV19RN+xj4iIiOiGSBqIdu7ciXvuuQcJCQmQyWRYv379VcfOnj0bMpkMf/7znz2219TUICsrCxqNBpGRkZg5cyYsFovHmMOHD+POO+9ESEgIEhMTsWzZsg44Gt+7o6+rj2j32So4newjIiIiul6SBiKr1YrU1FS88847Pzlu3bp12LNnDxISEq7Yl5WVhWPHjiE3NxebNm3Czp07MWvWLHG/2WzG+PHj0bNnTxQUFODVV1/F888/j/fee8/rx+NrqYmRCFcGo7begeOXzFKXQ0RE1GnJpfzyiRMnYuLEiT855uLFi5g7dy6++uorZGZmeuw7ceIEtmzZgv3792P48OEAgLfffhuTJk3Ca6+9hoSEBKxatQp2ux3/+Mc/oFQqMWjQIBQWFuL111/3CE6dkSI4CCN7x2DbyQrsPluFwd21UpdERETUKfl1D5HT6cSMGTOwcOFCDBo06Ir9+fn5iIyMFMMQAKSnpyMoKAh79+4Vx4wZMwZKpVIck5GRgaKiItTW1l71u202G8xms8fLH93esh7RLjZWExERXTe/DkSvvPIK5HI5Hn/88Vb3GwwG6HQ6j21yuRzR0dEwGAzimLi4OI8x7vfuMa1ZunQptFqt+EpMTLyRQ+kwd7SsR7S/uAa2pmaJqyEiIuqc/DYQFRQU4M0338TKlSshk8l8/v2LFy+GyWQSX6WlpT6voS36x0UgVq1Eg6MZ35cYpS6HiIioU/LbQPTtt9+ioqICSUlJkMvlkMvlOH/+PH73u9+hV69eAAC9Xo+KigqPn2tqakJNTQ30er04pry83GOM+717TGtUKhU0Go3Hyx/JZDLc3qflbjPefk9ERHRd/DYQzZgxA4cPH0ZhYaH4SkhIwMKFC/HVV18BANLS0mA0GlFQUCD+3LZt2+B0OjFy5EhxzM6dO+FwOMQxubm56N+/P6Kionx7UB1kdF93HxEDERER0fWQ9C4zi8WCM2fOiO+Li4tRWFiI6OhoJCUlISYmxmO8QqGAXq9H//79AQADBw7EhAkT8Oijj2LFihVwOByYM2cOpk2bJt6if//99+OFF17AzJkzsWjRIhw9ehRvvvkm3njjDd8daAcb3bIe0aELJtQ1OhARopC4IiIios5F0hmiAwcOYOjQoRg6dCgAYMGCBRg6dCiWLFnS5s9YtWoVBgwYgLvuuguTJk3CHXfc4bHGkFarxddff43i4mIMGzYMv/vd77BkyZJOf8v95XpEhaFnTBianQJ2neYsERERUXvJBD4qvU3MZjO0Wi1MJpNf9hMt/eIE/rrzHP5rgA7/eOg2qcshIiLyC239/e23PUTUPr+6zbUswI6iClwyNUhcDRERUefCQNRF9OmmxojkaDgFYO2BC1KXQ0RE1KkwEHUh00e4Zok+3l/Kh70SERG1AwNRFzJxcDw0IXJcNDbgW96CT0RE1GYMRF1IiCIY9w7tDgD4eH+JxNUQERF1HgxEXcy0EUkAgNzj5aiy2CSuhoiIqHNgIOpiBsZrkJoYCUezgM8K2FxNRETUFgxEXdD0235sruYyU0RERNfGQNQF3ZOagHBlMM5VWbGvuEbqcoiIiPweA1EXFK6S455U17Pc/rWPzdVERETXwkDURU1vaa7ecKgMhaVGaYshIiLycwxEXVRqYiTuHdodTgF48tNDsDU1S10SERGR32Ig6sKW3J2CWLUSp8oteGfbGanLISIi8lsMRF1YVLgSL/5yMADg3R1ncbzMLHFFRERE/omBqIubNCQeEwbp0eQU8ORnh9DU7JS6JCIiIr/DQBQAXpw8CNpQBY5eNOO9b89JXQ4REZHfYSAKALqIECy5OwUA8OdvTuOkgZfOiIiILsdAFCCm3NodY/t3g73JiQff34fz1VapSyIiIvIbDEQBQiaT4Y1f3YL+cRGoqLPh/r/txSVTg9RlERER+QUGogASFa7E/z0yAr1iwnDR2ICsv+9FlcUmdVlERESSYyAKMLqIEHz0yEgkaENwrtKKGe/vg6neIXVZREREkmIgCkA9osKw6tFRiFWrcOKSGQ/+Yy+qOVNEREQBjIEoQCXHhuOjR0YgMkyBQxdMmLp8NxutiYgoYDEQBbABeg0+nX07ukeG4ofqekx5dzcO8UGwREQUgBiIAlxfnRrrfns7BiVoUG21Y9p7e7D1RLnUZREREfkUAxFBpwnBx/+ThjE3dUODoxmP/vMA/pp3Fk6nIHVpREREPsFARAAAtUqO97OH47+H9YBTAJZ+eRIz/rEXBlOj1KURERF1OAYiEimCg7Dsvpvx8pQhCFUE47sz1Zjw5k5sOWqQujQiIqIOxUBEHmQyGaaNSMKmx+/A4O4aGOsdmP1RAZ767DAstiapyyMiIuoQDETUqj7d1Pj3Y6PxPz/rDZkMWLO/FBP+vBO7z1ZJXRoREZHXMRDRVSnlQVg8cSBWPzIKPaJCcaG2Aff/bS+e+/wo6u2cLSIioq6DgYiuKa1PDLbMG4OskUkAgA/zz2PCn7/F7jOcLSIioq6BgYjaRK2S46V7h+D/Zo5AgjYEJTX1uP/ve/HYRwW4UFsvdXlEREQ3hIGI2uXOft2wZf4YZKf1RJAM+PKoAXf9KQ9//uYUGh3NUpdHRER0XWSCIHD1vTYwm83QarUwmUzQaDRSl+MXTlwy44WNx7DnXA0AoHtkKBb8/CZMHtodwUEyiasjIiJq++9vBqI2YiBqnSAI+OKIAS9tPo6ylkUcb4pT43fj+2N8ShxkMgYjIiKSDgORlzEQ/bQGezM+zP8By3echanBAQC4JTES89L74Wc3dWMwIiIiSTAQeRkDUduYGhx4b+dZ/GPXD2ho6SkaoI/Ao3f2xj2pCVDK2bZGRES+w0DkZQxE7VNR14gVO85hzf4S1NtdwUivCcFDo3vhvmE9EKtWSVwhEREFAgYiL2Mguj6megdW7TuPD777AZV1NgCAPEiGcQN0uG9YD/zXAB0UwZw1IiKijsFA5GUMRDfG1tSMz78vw6p9JThUahS3x4QrMeXW7ngwrRcSo8OkK5CIiLokBiIvYyDynlPldfis4AL+/f1FcdZIJgPuGhCH34zuhdv7xLAJm4iIvIKByMsYiLyvqdmJHUWV+DD/B3x7+sfHgPTVqXHv0O64++Z49IwJl7BCIiLq7BiIvIyBqGOdqbDgn/k/4NOCC2ITNgAM6a7F3TfHY9KQeF5SIyKidmMg8jIGIt8wNzqw+fAlbD58CbvPVsF52X+dQ7prMWGwHhMH69G7m1q6IomIqNNgIPIyBiLfq7LYsOWoAZsOl2FfcY1HOOofF4GxA7rhzr7dMLxXFEIUwdIVSkREfqutv78lvd95586duOeee5CQkACZTIb169eL+xwOBxYtWoQhQ4YgPDwcCQkJePDBB1FWVubxGTU1NcjKyoJGo0FkZCRmzpwJi8XiMebw4cO48847ERISgsTERCxbtswXh0c3KFatwgOjemLNrDTsezodS6cMwZ39YiEPkqGovA5/zTuHB97fi9QXvsaM9/fi79+ew4XaeqnLJiKiTkgu5ZdbrVakpqbi4YcfxpQpUzz21dfX4+DBg3j22WeRmpqK2tpaPPHEE/jFL36BAwcOiOOysrJw6dIl5ObmwuFw4De/+Q1mzZqF1atXA3Alw/HjxyM9PR0rVqzAkSNH8PDDDyMyMhKzZs3y6fHS9YtVqzB9RBKmj0iCsd6OHUWV+PZ0FXadqUS52YZvT1fh29NV+MPmE0hNjMSkwXr2HRERUZv5zSUzmUyGdevWYfLkyVcds3//fowYMQLnz59HUlISTpw4gZSUFOzfvx/Dhw8HAGzZsgWTJk3ChQsXkJCQgOXLl+Ppp5+GwWCAUqkEADz11FNYv349Tp482eb6eMnMPwmCgDMVFuw8XYWvjxmw74caXP5fdF+dGrf3icHtfWIwqncMIsOU0hVLREQ+19bf35LOELWXyWSCTCZDZGQkACA/Px+RkZFiGAKA9PR0BAUFYe/evbj33nuRn5+PMWPGiGEIADIyMvDKK6+gtrYWUVFRrX6XzWaDzWYT35vN5o45KLohMpkM/eIi0C8uAjPvSEZFXSO+OlaOLw5fwt7iapypsLTcwXYeMhkwKEGD0X1j2XtEREQeOk0gamxsxKJFizB9+nQx4RkMBuh0Oo9xcrkc0dHRMBgM4pjk5GSPMXFxceK+qwWipUuX4oUXXvD2YVAH00WEYMaonpgxqieM9XbsOVeD/LNV+O6sKxwdvWjG0Ytm/DXvHJTyINzWK0oMSIMSNAgK4oKQRESBqFMEIofDgV/96lcQBAHLly/3yXcuXrwYCxYsEN+bzWYkJib65LvJOyLDlJgwWI8Jg/UAgApzI3afrcauM1XYdboKBnMjvjtTje/OVGMZihAZpsDoPrG4vW8MRiZHo3esmgGJiChA+H0gcoeh8+fPY9u2bR7X//R6PSoqKjzGNzU1oaamBnq9XhxTXl7uMcb93j2mNSqVCioVn8jeleg0IZg8tDsmD+0OQRBwttKKXacrsetMNfacq4ax3oHNRy5h85FLAIDIMAWG94zCsJ7RGJEchSHdI6GU80G0RERdkV8HIncYOn36NLZv346YmBiP/WlpaTAajSgoKMCwYcMAANu2bYPT6cTIkSPFMU8//TQcDgcUCgUAIDc3F/3797/q5TLq+mQyGfrq1OirU+Oh0cloanbi0AUTdp2uQv65KhSWGmGsd+CbExX45oQrdIcogjA0MQojkqMxMjkaqYmRCFf59f9CRETURpLeZWaxWHDmzBkAwNChQ/H6669j3LhxiI6ORnx8PO677z4cPHgQmzZtEvt+ACA6Olpskp44cSLKy8uxYsUK8bb74cOHi7fdm0wm9O/fH+PHj8eiRYtw9OhRPPzww3jjjTfadds97zILLI5mJ46VmXHghxrs/6EG+3+oRY3V7jEmOEiGgfERGJYUhVt7RmFYzyh0jwzlg2mJiPxIp1ipeseOHRg3btwV27Ozs/H8889f0Qzttn37dowdOxaAa2HGOXPmYOPGjQgKCsLUqVPx1ltvQa3+8dEOhw8fRk5ODvbv34/Y2FjMnTsXixYtaletDESBzXWJzYK9xTXY1/K6ZGq8YlycRoVhLZfZhvWMwsD4CKjkvJONiEgqnSIQdSYMRPSfyowNOFhSi4LztTh4vhbHysxocnr+76QMDsLA+AikJkYitUckbkmKRO/YcM4iERH5CAORlzEQ0bU02Jtx+IIRB1oC0sGSWtTWO64YFxWmwLCeLZfZkqJwc49IhCo5i0RE1BEYiLyMgYjaSxAElNY0oPCCEYdLjSgsNeLIRRNsTU6PccFBMvTTqXFLYiRSEyMxpLsWfbqpGZKIiLyAgcjLGIjIG+xNThwrM7kus5XU4sAPtaios10xTiYDEqPC0E+nRt84NVLiNRiUoEVybDiCuTYSEVGbMRB5GQMRdRSDqRGFpUYcumDEoVIjjl8yw9jKpTYACFMGY1CCKxwN7q5tmU0KhzyY6yMREbWGgcjLGIjIVwRBQLXVjjMVFpyusOB0eR2OlZlxvMyMBkfzFeNDFEEYGK/BoAQNBug1GKCPQH99BCJCFBJUT0TkXxiIvIyBiKTW7BRwrtKCo2UmHLlgxtEyE45dNMFqvzIkAUD3yFD0i1OjTzf3Kxw3xUUgKlzZ6ngioq6IgcjLGIjIHzmdAoqrrTh60YQTl+pQZDDjpKGu1TWS3PSaEAyMj8DAeA0GxrtmlHrFhkPBy25E1AUxEHkZAxF1JsZ6O4oMdThbacXZSgvOVlpwpsKCC7UNrY5XBMvQp5sa/fUR6NNNjZ4xYUiKDkPPmHBEhSm4bhIRdVoMRF7GQERdQV2jA0WGOpy4ZMbxS64/T5fXXfWyGwBEhMhxU1wEBujds0oRuCmOPUpE1DkwEHkZAxF1VU6ngIvGBpwqr8NJQx1+qLLifE09SqrrYTD/9KU39wNy+3QLR59uaiR3C4deE8IZJSLyGwxEXsZARIGo0dGMkpp6nLjk6k06ccmME5fMKDdfuXaSW6giGMmx4ejdLRy9Y8OR3C0cybFqJMeEQxvGWSUi8i0GIi9jICL6kanegTOVFpyt+LE/qbhlZqnZefW/UmLVSvTTReCmODX6xkXgJp0avbupEatWclaJiDoEA5GXMRARXZuj2YnSmnoUV1lxrtKKc1VWFFe5wtJPzSpFhMjRu5safWLD0UenRv8411pK3SNDEcSVuYnoBjAQeRkDEdGNsdiacLbCglPldTjT8ufpCgsuGhtwtb+FwpTB6KdTo1+ca1apny4C/eLUSNAyKBFR2zAQeRkDEVHHaHQ043x1Pc5VWnCuyorT5XUoKnddjrM3O1v9mQiVHAMTNBicoMXg7q5HmfARJkTUGgYiL2MgIvKtpmYnfqiux6nyOnE26XR5HYqrrHA0X/nXljI4CH10avHRJQP0EUhJ0EAXESJB9UTkLxiIvIyBiMg/OJqdOFtpwdGLZhwrM+FYy59XW0spVq3CoAQNUlpmlIZ01yIxOpRN3EQBgoHIyxiIiPyXey2lk4YfH19y0lCHc5UWtHbTmzZUgSHdtRjUcrktJV6D5NhwBLMviajLYSDyMgYios6nwd6MkwYzjl8yizNKJy/VtdqbFKoIxoD4CAxK0LjCUoIWN8VFQClnXxJRZ8ZA5GUMRERdg73JiVPldThy0YSjF004fsmMk5fq0OC48pKbMjgIN+nV6NNNjd6xavTuFi4uOhmmlEtQPRG1FwORlzEQEXVdzU4BxVVWV09SmRlHW8KSubHpqj8Trw1pWY3bFZR6xYYjOSYcPaJCebcbkR9hIPIyBiKiwCIIAkprGnD8khnnqiw4V2ltWXDSgtp6x1V/Th4kQ4+oUCTHup7v1lenRh+da5YpOlzpwyMgIoCByOsYiIjIrdZqF0PSuZaQdL66Hj9UW9HoaH3tJACIClOgTzdXOOqjC0dSdDi6Raigi1AhVq1CqDLYh0dBFBgYiLyMgYiIrsXpFFBe14jiKtds0tkKq/ist4vGhmv+vFolR4+oUCRFh6FnTBh6xoSjV4zrAbnxmhCuzk10HRiIvIyBiIhuRIO9GeeqLDhbacXZCteq3KU19aiy2FBZZ4Ot6eozS4DrLjh3Q3fPmDAkRoUhMToMPaJCkRAZCgX7lohaxUDkZQxERNRRBEGAxdaEcrMNpbX1KKmux/nqepyvtqK42oqS6no0tbagUosgGRCvDUWPqFAkRochKToMCZGh0GtCoNe6XmoV74qjwNTW39/8P4SISGIymQwRIQpEhCjQV6e+Yr+j2YnSmvqWniULSmsaUFpbj9KaelyobYCtyYmLxgZcNDZgb3FNq98RoZIjIdIVmrpHhaJ7ZCjiI0PRTa1CtwjXSxMi5wreFLAYiIiI/JwiOAi9u6nRu5saQJzHPkEQUFlnawlIDSitqUdpbT0umRpxydSIclMj6mxNqLM1oai8DkXldVf9HpU8CN2jQtGzZZYpseWVoA2FXhuCmHAl+5ioy2IgIiLqxGQyGXSaEOg0IRjWs/UxVlsTLpkaXbNItQ24UOuaWSo3N6KypYeprrEJtianaxaq0trq5yiCZYjThIh3xcW2/KmLUKFHVCh6RLl6mkIUvFuOOh8GIiKiLi5cJUdfnbrVy3FujY5mVLh7mGpcPUwlNVZcrG3AJZMrODmaBVyobcCF2p++Y65bhApxGhViwlWIUSsRq1YhJlyJOE0I4tx9TZoQLjNAfoWBiIiIEKIIRlJMGJJiwjC6lf2OZicq6my4ZGxw3RlnsaOqzoYqiw3l5kZcqHVdrrPam1FZ55p1uhZtqAIJkaHoHhmChMhQxGtDEadRQRcRIv6pCWVfE/kGAxEREV2TIjgI3SNdzdhXIwgCTA0OlNY0oNLSiGqLHdVWO6pbLsuVm13hyWBuRL29GaYGB0wNDpy4ZL7qZyrlQYgNVyJGrUJsy2yTuwm8W4QK3dQq6DSuAMXny9GN4H89RETkFTKZDJFhSkSGKQForzpOEATU2ZpgaOlrKmt5XTI2oqLOFZoq6mwwNThgb3KizNSIMlPjNb8/IkQuLjUQ0xKiosOV4j/HqpXo1tL3xD4n+k8MRERE5FMymQyaEAU0IQrcFBdx1XGNjmZUWWyosrhmmdz/7L4kV1lnQ6XFBoOpEQ2OZtQ1NqGu0YLTFZZr1hChkiNGrUR0uBLR4aqW0KSELkLlahxvmXWKCVchRBHEy3YBgIGIiIj8UogiuOXOtbCfHOeecaowN8JgssFgbkSN1SZesquxugOVHZUWG+xNTnEpgh+q669ZhzI4CJpQOTQhCmjDFGJoct9xp9OEtFy6UyE6jEsTdFYMRERE1KldPuPUV3f1GSfAFZ7MjU2orLOhxmp3BSerHTUt4amirlHsdaow22BvdsLe7ESVxY4qi/2atQQHyRCrds06RYcrxNmn6JYZqNiWS3cx4SpEhSkRESJngPITDERERBQwZDIZtKEKaEMV1xwrCIJH87epwQFjvd2jQby8zoYKcyOqLK5g1ewUWvZd+y47wPXYlcgwJSJDFYgKV4qN4+51njQhcqhVcoQpXX9GhLgu9alVvPvO2xiIiIiIWiGTyRCukiO85bEn1+JodqLGakeF2YaaetfsU43VIV6+q7LYUW119UJVW+yotzfDKaBlpsoOVLW+IGZrQhRBYoN4dJgS2jBXyIsMVUIbKkdUy6xUVNiPf3Ldp5/GQEREROQFiuAgsbeoLRodzTA3OFBb75p5qrHaf1zjyWJDVcsK4lZ7Eyy2JtTbmmFudKDe3oxGh7PlUS0/vUjm5VTyIESGuUJTZJgC3SJcaz3pNK7VxmPUKnH2TBuqgCZEDnlw0PWejk6HgYiIiEgCIYpghCiCoWtjgHKz2ppa7rhz3WlXW+++nOe+tGdHrdWB2paQVVtvh6NZgK3J2a7LeYBrKYPLQ5T78p42VIHIMAU0oa7erYiQHy/paUIVnbK5nIGIiIioE3FfxusZE96m8YIgwGJrgrHeFZqMDa6g5F66oKLOhoo610Ka5pZeKau9GQBaljJoQinaPhMF/Nhcrotw3YmnDVUgTBWMMKUcoYpghKuCxZAVFa5EVEvYkjJIMRARERF1YTKZDBEhCkSEKJAY3bafcTQ7YW5wwNgy82Sst8NY75p1cocm9z6LrQmWxibUNTpQZ3Nd3mtvc7nb4efHQxNy7Yb3jsBARERERB4UwUGIUbv6itqrqWWZgoo619IFFXU2sfepwd6EenszrLYmGC/rn6q12tHgaEaESrpYwkBEREREXiMPDoJe63qESns0OwVJlxIInPZxIiIi8lvBEjdhMxARERFRwJM0EO3cuRP33HMPEhISIJPJsH79eo/9giBgyZIliI+PR2hoKNLT03H69GmPMTU1NcjKyoJGo0FkZCRmzpwJi8XzwX6HDx/GnXfeiZCQECQmJmLZsmUdfWhERETUiUgaiKxWK1JTU/HOO++0un/ZsmV46623sGLFCuzduxfh4eHIyMhAY2OjOCYrKwvHjh1Dbm4uNm3ahJ07d2LWrFnifrPZjPHjx6Nnz54oKCjAq6++iueffx7vvfdehx8fERERdRKCnwAgrFu3TnzvdDoFvV4vvPrqq+I2o9EoqFQq4V//+pcgCIJw/PhxAYCwf/9+ccyXX34pyGQy4eLFi4IgCMK7774rREVFCTabTRyzaNEioX///u2qz2QyCQAEk8l0PYdHREREEmjr72+/7SEqLi6GwWBAenq6uE2r1WLkyJHIz88HAOTn5yMyMhLDhw8Xx6SnpyMoKAh79+4Vx4wZMwZKpVIck5GRgaKiItTW1l71+202G8xms8eLiIiIuia/DUQGgwEAEBcX57E9Li5O3GcwGKDT6Tz2y+VyREdHe4xp7TMu/47WLF26FFqtVnwlJibe2AERERGR3/LbQCS1xYsXw2Qyia/S0lKpSyIiIqIO4reBSK/XAwDKy8s9tpeXl4v79Ho9KioqPPY3NTWhpqbGY0xrn3H5d7RGpVJBo9F4vIiIiKhr8ttAlJycDL1ej61bt4rbzGYz9u7di7S0NABAWloajEYjCgoKxDHbtm2D0+nEyJEjxTE7d+6Ew+EQx+Tm5qJ///6Iiory0dEQERGRP5M0EFksFhQWFqKwsBCAq5G6sLAQJSUlkMlkmDdvHv7whz9gw4YNOHLkCB588EEkJCRg8uTJAICBAwdiwoQJePTRR7Fv3z589913mDNnDqZNm4aEhAQAwP333w+lUomZM2fi2LFj+Pjjj/Hmm29iwYIFEh01ERER+R0f3fXWqu3btwsArnhlZ2cLguC69f7ZZ58V4uLiBJVKJdx1111CUVGRx2dUV1cL06dPF9RqtaDRaITf/OY3Ql1dnceYQ4cOCXfccYegUqmE7t27Cy+//HK7a+Vt90RERJ1PW39/ywRBECTMY52G2WyGVquFyWRiPxEREVEn0dbf337bQ0RERETkK3KpC+gs3BNpXKCRiIio83D/3r7WBTEGojaqq6sDAC7QSERE1AnV1dVBq9VedT97iNrI6XSirKwMERERkMlkXvtcs9mMxMRElJaWsjepg/Fc+w7Pte/wXPsOz7Vveet8C4KAuro6JCQkICjo6p1CnCFqo6CgIPTo0aPDPp+LP/oOz7Xv8Fz7Ds+17/Bc+5Y3zvdPzQy5samaiIiIAh4DEREREQU8BiKJqVQqPPfcc1CpVFKX0uXxXPsOz7Xv8Fz7Ds+1b/n6fLOpmoiIiAIeZ4iIiIgo4DEQERERUcBjICIiIqKAx0BEREREAY+BSGLvvPMOevXqhZCQEIwcORL79u2TuqRObenSpbjtttsQEREBnU6HyZMno6ioyGNMY2MjcnJyEBMTA7VajalTp6K8vFyiiruOl19+GTKZDPPmzRO38Vx718WLF/HAAw8gJiYGoaGhGDJkCA4cOCDuFwQBS5YsQXx8PEJDQ5Geno7Tp09LWHHn1NzcjGeffRbJyckIDQ1Fnz598L//+78ez8Liub4+O3fuxD333IOEhATIZDKsX7/eY39bzmtNTQ2ysrKg0WgQGRmJmTNnwmKx3HBtDEQS+vjjj7FgwQI899xzOHjwIFJTU5GRkYGKigqpS+u08vLykJOTgz179iA3NxcOhwPjx4+H1WoVx8yfPx8bN27E2rVrkZeXh7KyMkyZMkXCqju//fv3469//Stuvvlmj+08195TW1uL0aNHQ6FQ4Msvv8Tx48fxpz/9CVFRUeKYZcuW4a233sKKFSuwd+9ehIeHIyMjA42NjRJW3vm88sorWL58Of7yl7/gxIkTeOWVV7Bs2TK8/fbb4hie6+tjtVqRmpqKd955p9X9bTmvWVlZOHbsGHJzc7Fp0ybs3LkTs2bNuvHiBJLMiBEjhJycHPF9c3OzkJCQICxdulTCqrqWiooKAYCQl5cnCIIgGI1GQaFQCGvXrhXHnDhxQgAg5OfnS1Vmp1ZXVyf069dPyM3NFX72s58JTzzxhCAIPNfetmjRIuGOO+646n6n0yno9Xrh1VdfFbcZjUZBpVIJ//rXv3xRYpeRmZkpPPzwwx7bpkyZImRlZQmCwHPtLQCEdevWie/bcl6PHz8uABD2798vjvnyyy8FmUwmXLx48Ybq4QyRROx2OwoKCpCeni5uCwoKQnp6OvLz8yWsrGsxmUwAgOjoaABAQUEBHA6Hx3kfMGAAkpKSeN6vU05ODjIzMz3OKcBz7W0bNmzA8OHD8d///d/Q6XQYOnQo/va3v4n7i4uLYTAYPM63VqvFyJEjeb7b6fbbb8fWrVtx6tQpAMChQ4ewa9cuTJw4EQDPdUdpy3nNz89HZGQkhg8fLo5JT09HUFAQ9u7de0Pfz4e7SqSqqgrNzc2Ii4vz2B4XF4eTJ09KVFXX4nQ6MW/ePIwePRqDBw8GABgMBiiVSkRGRnqMjYuLg8FgkKDKzm3NmjU4ePAg9u/ff8U+nmvvOnfuHJYvX44FCxbg97//Pfbv34/HH38cSqUS2dnZ4jlt7e8Unu/2eeqpp2A2mzFgwAAEBwejubkZL730ErKysgCA57qDtOW8GgwG6HQ6j/1yuRzR0dE3fO4ZiKjLysnJwdGjR7Fr1y6pS+mSSktL8cQTTyA3NxchISFSl9PlOZ1ODB8+HH/84x8BAEOHDsXRo0exYsUKZGdnS1xd1/LJJ59g1apVWL16NQYNGoTCwkLMmzcPCQkJPNddGC+ZSSQ2NhbBwcFX3HFTXl4OvV4vUVVdx5w5c7Bp0yZs374dPXr0ELfr9XrY7XYYjUaP8Tzv7VdQUICKigrceuutkMvlkMvlyMvLw1tvvQW5XI64uDieay+Kj49HSkqKx7aBAweipKQEAMRzyr9TbtzChQvx1FNPYdq0aRgyZAhmzJiB+fPnY+nSpQB4rjtKW86rXq+/4sajpqYm1NTU3PC5ZyCSiFKpxLBhw7B161Zxm9PpxNatW5GWliZhZZ2bIAiYM2cO1q1bh23btiE5Odlj/7Bhw6BQKDzOe1FREUpKSnje2+muu+7CkSNHUFhYKL6GDx+OrKws8Z95rr1n9OjRVywhcerUKfTs2RMAkJycDL1e73G+zWYz9u7dy/PdTvX19QgK8vz1GBwcDKfTCYDnuqO05bympaXBaDSioKBAHLNt2zY4nU6MHDnyxgq4oZZsuiFr1qwRVCqVsHLlSuH48ePCrFmzhMjISMFgMEhdWqf12GOPCVqtVtixY4dw6dIl8VVfXy+OmT17tpCUlCRs27ZNOHDggJCWliakpaVJWHXXcfldZoLAc+1N+/btE+RyufDSSy8Jp0+fFlatWiWEhYUJH330kTjm5ZdfFiIjI4XPP/9cOHz4sPDLX/5SSE5OFhoaGiSsvPPJzs4WunfvLmzatEkoLi4W/v3vfwuxsbHCk08+KY7hub4+dXV1wvfffy98//33AgDh9ddfF77//nvh/PnzgiC07bxOmDBBGDp0qLB3715h165dQr9+/YTp06ffcG0MRBJ7++23haSkJEGpVAojRowQ9uzZI3VJnRqAVl8ffPCBOKahoUH47W9/K0RFRQlhYWHCvffeK1y6dEm6oruQ/wxEPNfetXHjRmHw4MGCSqUSBgwYILz33nse+51Op/Dss88KcXFxgkqlEu666y6hqKhIomo7L7PZLDzxxBNCUlKSEBISIvTu3Vt4+umnBZvNJo7hub4+27dvb/Xv6OzsbEEQ2nZeq6urhenTpwtqtVrQaDTCb37zG6Guru6Ga5MJwmVLbxIREREFIPYQERERUcBjICIiIqKAx0BEREREAY+BiIiIiAIeAxEREREFPAYiIiIiCngMRERERBTwGIiIiIgo4DEQERFdJ5lMhvXr10tdBhF5AQMREXVKDz30EGQy2RWvCRMmSF0aEXVCcqkLICK6XhMmTMAHH3zgsU2lUklUDRF1ZpwhIqJOS6VSQa/Xe7yioqIAuC5nLV++HBMnTkRoaCh69+6NTz/91OPnjxw5gv/6r/9CaGgoYmJiMGvWLFgsFo8x//jHPzBo0CCoVCrEx8djzpw5Hvurqqpw7733IiwsDP369cOGDRs69qCJqEMwEBFRl/Xss89i6tSpOHToELKysjBt2jScOHECAGC1WpGRkYGoqCjs378fa9euxTfffOMReJYvX46cnBzMmjULR44cwYYNG9C3b1+P73jhhRfwq1/9CocPH8akSZOQlZWFmpoanx4nEXmBQETUCWVnZwvBwcFCeHi4x+ull14SBEEQAAizZ8/2+JmRI0cKjz32mCAIgvDee+8JUVFRgsViEfdv3rxZCAoKEgwGgyAIgpCQkCA8/fTTV60BgPDMM8+I7y0WiwBA+PLLL712nETkG+whIqJOa9y4cVi+fLnHtujoaPGf09LSPPalpaWhsLAQAHDixAmkpqYiPDxc3D969Gg4nU4UFRVBJpOhrKwMd91110/WcPPNN4v/HB4eDo1Gg4qKius9JCKSCAMREXVa4eHhV1zC8pbQ0NA2jVMoFB7vZTIZnE5nR5RERB2IPURE1GXt2bPnivcDBw4EAAwcOBCHDh2C1WoV93/33XcICgpC//79ERERgV69emHr1q0+rZmIpMEZIiLqtGw2GwwGg8c2uVyO2NhYAMDatWsxfPhw3HHHHVi1ahX27duH999/HwCQlZWF5557DtnZ2Xj++edRWVmJuXPnYsaMGYiLiwMAPP/885g9ezZ0Oh0mTpyIuro6fPfdd5g7d65vD5SIOhwDERF1Wlu2bEF8fLzHtv79++PkyZMAXHeArVmzBr/97W8RHx+Pf/3rX0hJSQEAhIWF4auvvsITTzyB2267DWFhYZg6dSpef/118bOys7PR2NiIN954A//v//0/xMbG4r777vPdARKRz8gEQRCkLoKIyNtkMhnWrVuHyZMnS10KEXUC7CEiIiKigMdARERERAGPPURE1CWxG4CI2oMzRERERBTwGIiIiIgo4DEQERERUcBjICIiIqKAx0BEREREAY+BiIiIiAIeAxEREREFPAYiIiIiCnj/H818AGetD5+cAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the ELBO Loss over training\n",
    "plt.plot(elbo2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('ELBO Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot error over training\n",
    "plt.plot(mae2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Absolue Error')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
